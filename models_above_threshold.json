[
  {
    "model": "qingy2024/Benchmaxx-Llama-3.2-1B-Instruct",
    "score": 0.604
  },
  {
    "model": "internlm/internlm2_5-20b-chat",
    "score": 0.42
  },
  {
    "model": "kavonalds/BunderMaxx-1010",
    "score": 0.42
  },
  {
    "model": "IntervitensInc/internlm2_5-20b-llamafied",
    "score": 0.416
  },
  {
    "model": "MaziyarPanahi/calme-2.3-llama3.1-70b",
    "score": 0.376
  },
  {
    "model": "MaziyarPanahi/calme-2.2-llama3.1-70b",
    "score": 0.356
  },
  {
    "model": "VAGOsolutions/Llama-3.1-SauerkrautLM-70b-Instruct",
    "score": 0.356
  },
  {
    "model": "dnhkng/RYS-Llama3.1-Large",
    "score": 0.352
  },
  {
    "model": "Sao10K/70B-L3.3-Cirrus-x1",
    "score": 0.348
  },
  {
    "model": "VAGOsolutions/Llama-3-SauerkrautLM-70b-Instruct",
    "score": 0.344
  },
  {
    "model": "kavonalds/BunderMaxx-0710",
    "score": 0.344
  },
  {
    "model": "kavonalds/BunderMaxx-0710",
    "score": 0.344
  },
  {
    "model": "Tarek07/Progenitor-V1.1-LLaMa-70B",
    "score": 0.34
  },
  {
    "model": "meta-llama/Llama-3.1-70B-Instruct",
    "score": 0.34
  },
  {
    "model": "shuttleai/shuttle-3",
    "score": 0.336
  },
  {
    "model": "MaziyarPanahi/calme-3.2-instruct-78b",
    "score": 0.332
  },
  {
    "model": "Sakalti/ultiima-72B-v1.5",
    "score": 0.332
  },
  {
    "model": "Tarek07/Thalassic-Alpha-LLaMa-70B",
    "score": 0.332
  },
  {
    "model": "BenevolenceMessiah/Qwen2.5-72B-2x-Instruct-TIES-v1.0",
    "score": 0.328
  },
  {
    "model": "KSU-HW-SEC/Llama3.1-70b-SVA-FT-1000step",
    "score": 0.328
  },
  {
    "model": "MaziyarPanahi/calme-3.1-instruct-78b",
    "score": 0.328
  },
  {
    "model": "prithivMLmods/Megatron-Opus-14B-2.0",
    "score": 0.328
  },
  {
    "model": "tenyx/Llama3-TenyxChat-70B",
    "score": 0.328
  },
  {
    "model": "DreadPoor/Emu_Eggs-9B-Model_Stock",
    "score": 0.324
  },
  {
    "model": "MaziyarPanahi/calme-2.1-qwen2.5-72b",
    "score": 0.324
  },
  {
    "model": "MaziyarPanahi/calme-2.2-qwen2.5-72b",
    "score": 0.324
  },
  {
    "model": "OpenBuddy/openbuddy-nemotron-70b-v23.1-131k",
    "score": 0.324
  },
  {
    "model": "Triangle104/Gemmadevi-Stock-10B",
    "score": 0.324
  },
  {
    "model": "hotmailuser/Gemma2Crono-27B",
    "score": 0.324
  },
  {
    "model": "meta-llama/Llama-3.3-70B-Instruct",
    "score": 0.324
  },
  {
    "model": "rombodawg/Rombos-LLM-V2.6-Nemotron-70b",
    "score": 0.324
  },
  {
    "model": "sam-paech/Delirium-v1",
    "score": 0.324
  },
  {
    "model": "Qwen/Qwen2.5-72B-Instruct",
    "score": 0.32
  },
  {
    "model": "Baptiste-HUVELLE-10/LeTriomphant2.2_ECE_iLAB",
    "score": 0.32
  },
  {
    "model": "SicariusSicariiStuff/Phi-Line_14B",
    "score": 0.32
  },
  {
    "model": "allknowingroger/GemmaSlerp5-10B",
    "score": 0.32
  },
  {
    "model": "dnhkng/RYS-Llama-3-Large-Instruct",
    "score": 0.32
  },
  {
    "model": "grimjim/Gigantes-v1-gemma2-9b-it",
    "score": 0.32
  },
  {
    "model": "hotmailuser/Gemma2SimPO-27B",
    "score": 0.32
  },
  {
    "model": "nbeerbower/Llama-3.1-Nemotron-lorablated-70B",
    "score": 0.32
  },
  {
    "model": "nhyha/N3N_Delirium-v1_1030_0227",
    "score": 0.32
  },
  {
    "model": "raphgg/test-2.5-72B",
    "score": 0.32
  },
  {
    "model": "VAGOsolutions/SauerkrautLM-gemma-2-9b-it",
    "score": 0.316
  },
  {
    "model": "agentlans/Gemma2-9B-AdvancedFuse",
    "score": 0.316
  },
  {
    "model": "allknowingroger/Gemma2Slerp2-27B",
    "score": 0.316
  },
  {
    "model": "allknowingroger/Gemma2Slerp3-27B",
    "score": 0.316
  },
  {
    "model": "allknowingroger/Gemma2Slerp4-27B",
    "score": 0.316
  },
  {
    "model": "allknowingroger/GemmaStock1-27B",
    "score": 0.316
  },
  {
    "model": "hotmailuser/Gemma2atlas-27B",
    "score": 0.316
  },
  {
    "model": "zelk12/MT2-Gen4-gemma-2-9B",
    "score": 0.316
  },
  {
    "model": "Aashraf995/Gemma-Evo-10B",
    "score": 0.312
  },
  {
    "model": "DreadPoor/Casuar-9B-Model_Stock",
    "score": 0.312
  },
  {
    "model": "MaziyarPanahi/calme-2.4-rys-78b",
    "score": 0.312
  },
  {
    "model": "Saxo/Linkbricks-Horizon-AI-Korean-Superb-27B",
    "score": 0.312
  },
  {
    "model": "arcee-ai/Arcee-Nova",
    "score": 0.312
  },
  {
    "model": "bunnycore/Phi-4-ReasoningRP",
    "score": 0.312
  },
  {
    "model": "dfurman/CalmeRys-78B-Orpo-v0.1",
    "score": 0.312
  },
  {
    "model": "grimjim/Gigantes-v3-gemma2-9b-it",
    "score": 0.312
  },
  {
    "model": "lemon07r/Gemma-2-Ataraxy-v4b-9B",
    "score": 0.312
  },
  {
    "model": "nbeerbower/llama3.1-kartoffeldes-70B",
    "score": 0.312
  },
  {
    "model": "rombodawg/Rombos-LLM-V2.5-Qwen-72b",
    "score": 0.312
  },
  {
    "model": "zelk12/MT-Gen6-gemma-2-9B",
    "score": 0.312
  },
  {
    "model": "zelk12/MT1-Gen5-IF-gemma-2-S2DMv1-9B",
    "score": 0.312
  },
  {
    "model": "zelk12/MT1-Gen7-gemma-2-9B",
    "score": 0.312
  },
  {
    "model": "zelk12/MT2-Gen3-gemma-2-9B",
    "score": 0.312
  },
  {
    "model": "zelk12/MT2-Gen7-gemma-2-9B",
    "score": 0.312
  },
  {
    "model": "zelk12/MT5-Gen2-gemma-2-9B",
    "score": 0.312
  },
  {
    "model": "zelk12/MT5-Gen1-gemma-2-9B",
    "score": 0.312
  },
  {
    "model": "zelk12/Rv0.4DMv1t0.25Tt0.25-gemma-2-9B",
    "score": 0.312
  },
  {
    "model": "zelk12/recoilme-gemma-2-Ataraxy-9B-v0.1-t0.25",
    "score": 0.312
  },
  {
    "model": "AELLM/gemma-2-aeria-infinity-9b",
    "score": 0.308
  },
  {
    "model": "BAAI/Infinity-Instruct-3M-0625-Llama3-70B",
    "score": 0.308
  },
  {
    "model": "BAAI/Infinity-Instruct-3M-0613-Llama3-70B",
    "score": 0.308
  },
  {
    "model": "CombinHorizon/huihui-ai-abliterated-Qwen2.5-32B-Inst-BaseMerge-TIES",
    "score": 0.308
  },
  {
    "model": "IlyaGusev/gemma-2-9b-it-abliterated",
    "score": 0.308
  },
  {
    "model": "OpenBuddy/openbuddy-llama3.1-70b-v22.1-131k",
    "score": 0.308
  },
  {
    "model": "allknowingroger/GemmaSlerp2-9B",
    "score": 0.308
  },
  {
    "model": "cat-searcher/gemma-2-9b-it-sppo-iter-1",
    "score": 0.308
  },
  {
    "model": "cloudyu/Llama-3-70Bx2-MOE",
    "score": 0.308
  },
  {
    "model": "fluently-lm/FluentlyLM-Prinum",
    "score": 0.308
  },
  {
    "model": "grimjim/Gigantes-v2-gemma2-9b-it",
    "score": 0.308
  },
  {
    "model": "huihui-ai/Qwen2.5-72B-Instruct-abliterated",
    "score": 0.308
  },
  {
    "model": "prithivMLmods/Galactic-Qwen-14B-Exp2",
    "score": 0.308
  },
  {
    "model": "rubenroy/Gilgamesh-72B",
    "score": 0.308
  },
  {
    "model": "upstage/solar-pro-preview-instruct",
    "score": 0.308
  },
  {
    "model": "wzhouad/gemma-2-9b-it-WPO-HB",
    "score": 0.308
  },
  {
    "model": "zelk12/Gemma-2-TM-9B",
    "score": 0.308
  },
  {
    "model": "zelk12/MT-Gen1-gemma-2-9B",
    "score": 0.308
  },
  {
    "model": "zelk12/MT-Gen3-gemma-2-9B",
    "score": 0.308
  },
  {
    "model": "zelk12/MT-Max-Merge_02012025163610-gemma-2-9B",
    "score": 0.308
  },
  {
    "model": "zelk12/MT-Merge-gemma-2-9B",
    "score": 0.308
  },
  {
    "model": "zelk12/MT-Merge4-gemma-2-9B",
    "score": 0.308
  },
  {
    "model": "zelk12/MT1-Gen1-gemma-2-9B",
    "score": 0.308
  },
  {
    "model": "zelk12/MT1-Gen2-gemma-2-9B",
    "score": 0.308
  },
  {
    "model": "zelk12/MT-Merge6-gemma-2-9B",
    "score": 0.308
  },
  {
    "model": "zelk12/MT1-Gen4-gemma-2-9B",
    "score": 0.308
  },
  {
    "model": "zelk12/MT2-Gen1-gemma-2-9B",
    "score": 0.308
  },
  {
    "model": "zelk12/MT3-Gen1-gemma-2-9B",
    "score": 0.308
  },
  {
    "model": "zelk12/MT3-Gen5-gemma-2-9B_v1",
    "score": 0.308
  },
  {
    "model": "zelk12/MT3-Gen5-gemma-2-9B",
    "score": 0.308
  },
  {
    "model": "zelk12/MT4-Gen2-gemma-2-9B",
    "score": 0.308
  },
  {
    "model": "zelk12/gemma-2-S2MTM-9B",
    "score": 0.308
  },
  {
    "model": "BAAI/Infinity-Instruct-7M-Gen-Llama3_1-70B",
    "score": 0.304
  },
  {
    "model": "Gunulhona/Gemma-Ko-Merge",
    "score": 0.304
  },
  {
    "model": "JungZoona/T3Q-qwen2.5-14b-v1.0-e3",
    "score": 0.304
  },
  {
    "model": "MaziyarPanahi/calme-2.1-rys-78b",
    "score": 0.304
  },
  {
    "model": "Quazim0t0/Adamant-14B-sce",
    "score": 0.304
  },
  {
    "model": "Sakalti/ultiima-72B",
    "score": 0.304
  },
  {
    "model": "UCLA-AGI/Gemma-2-9B-It-SPPO-Iter3",
    "score": 0.304
  },
  {
    "model": "arcee-ai/Arcee-Blitz",
    "score": 0.304
  },
  {
    "model": "gmonsoon/gemma2-9b-sahabatai-v1-instruct-BaseTIES",
    "score": 0.304
  },
  {
    "model": "grimjim/Magot-v1-Gemma2-8k-9B",
    "score": 0.304
  },
  {
    "model": "ifable/gemma-2-Ifable-9B",
    "score": 0.304
  },
  {
    "model": "lemon07r/Gemma-2-Ataraxy-v4c-9B",
    "score": 0.304
  },
  {
    "model": "lemon07r/Gemma-2-Ataraxy-v4d-9B",
    "score": 0.304
  },
  {
    "model": "meta-llama/Meta-Llama-3-70B-Instruct",
    "score": 0.304
  },
  {
    "model": "pankajmathur/orca_mini_phi-4",
    "score": 0.304
  },
  {
    "model": "sam-paech/Darkest-muse-v1",
    "score": 0.304
  },
  {
    "model": "zelk12/MT-Gen6fix-gemma-2-9B",
    "score": 0.304
  },
  {
    "model": "zelk12/MT-Merge2-MU-gemma-2-MTg2MT1g2-9B",
    "score": 0.304
  },
  {
    "model": "zelk12/MT-Merge2-gemma-2-9B",
    "score": 0.304
  },
  {
    "model": "zelk12/MT1-Gen5-gemma-2-9B",
    "score": 0.304
  },
  {
    "model": "zelk12/MT1-Gen6-gemma-2-9B",
    "score": 0.304
  },
  {
    "model": "zelk12/MT3-Gen6-gemma-2-9B",
    "score": 0.304
  },
  {
    "model": "zelk12/MT4-gemma-2-9B",
    "score": 0.304
  },
  {
    "model": "zelk12/MT5-gemma-2-9B",
    "score": 0.304
  },
  {
    "model": "zelk12/MTMaMe-Merge_02012025163610-gemma-2-9B",
    "score": 0.304
  },
  {
    "model": "zelk12/T31122024203920-gemma-2-9B",
    "score": 0.304
  },
  {
    "model": "zelk12/recoilme-gemma-2-Gutenberg-Doppel-9B-v0.1",
    "score": 0.304
  },
  {
    "model": "MaziyarPanahi/calme-2.2-llama3-70b",
    "score": 0.3
  },
  {
    "model": "MaziyarPanahi/calme-2.3-rys-78b",
    "score": 0.3
  },
  {
    "model": "NLPark/Shi-Ci-Robin-Test_3AD80",
    "score": 0.3
  },
  {
    "model": "OpenBuddy/openbuddy-nemotron-70b-v23.2-131k",
    "score": 0.3
  },
  {
    "model": "Quazim0t0/Imagine-v0.5-16bit",
    "score": 0.3
  },
  {
    "model": "Quazim0t0/Oasis-14B-ties",
    "score": 0.3
  },
  {
    "model": "UCLA-AGI/Gemma-2-9B-It-SPPO-Iter2",
    "score": 0.3
  },
  {
    "model": "allknowingroger/GemmaSlerp-9B",
    "score": 0.3
  },
  {
    "model": "bunnycore/Phi-4-RStock-v0.1",
    "score": 0.3
  },
  {
    "model": "djuna/G2-BigGSHT-27B-2",
    "score": 0.3
  },
  {
    "model": "gbueno86/Brinebreath-Llama-3.1-70B",
    "score": 0.3
  },
  {
    "model": "gbueno86/Meta-LLama-3-Cat-Smaug-LLama-70b",
    "score": 0.3
  },
  {
    "model": "grimjim/Magnolia-v2-Gemma2-8k-9B",
    "score": 0.3
  },
  {
    "model": "grimjim/Magnolia-v3-Gemma2-8k-9B",
    "score": 0.3
  },
  {
    "model": "lemon07r/Gemma-2-Ataraxy-Advanced-9B",
    "score": 0.3
  },
  {
    "model": "mmnga/Llama-3-70B-japanese-suzume-vector-v0.1",
    "score": 0.3
  },
  {
    "model": "prithivMLmods/Lacerta-Opus-14B-Elite8",
    "score": 0.3
  },
  {
    "model": "zelk12/MT-Gen2-GI-gemma-2-9B",
    "score": 0.3
  },
  {
    "model": "zelk12/MT-Gen2-gemma-2-9B",
    "score": 0.3
  },
  {
    "model": "zelk12/MT-Gen4-gemma-2-9B",
    "score": 0.3
  },
  {
    "model": "zelk12/MT-Gen5-gemma-2-9B",
    "score": 0.3
  },
  {
    "model": "zelk12/MT-gemma-2-9B",
    "score": 0.3
  },
  {
    "model": "zelk12/MT1-Gen3-gemma-2-9B",
    "score": 0.3
  },
  {
    "model": "zelk12/MT1-Max-Merge_02012025163610-gemma-2-9B",
    "score": 0.3
  },
  {
    "model": "zelk12/MT2-Gen2-gemma-2-9B",
    "score": 0.3
  },
  {
    "model": "zelk12/MT2-Gen5-gemma-2-9B",
    "score": 0.3
  },
  {
    "model": "zelk12/MT3-Gen4-gemma-2-9B",
    "score": 0.3
  },
  {
    "model": "zelk12/MT3-Max-Merge_02012025163610-gemma-2-9B",
    "score": 0.3
  },
  {
    "model": "zelk12/MT3-gemma-2-9B",
    "score": 0.3
  },
  {
    "model": "zelk12/MT4-Gen3-gemma-2-9B",
    "score": 0.3
  },
  {
    "model": "zelk12/MT4-Gen4-gemma-2-9B",
    "score": 0.3
  },
  {
    "model": "zelk12/MTM-Merge-gemma-2-9B",
    "score": 0.3
  },
  {
    "model": "zelk12/Rv0.4DMv1t0.25-gemma-2-9B",
    "score": 0.3
  },
  {
    "model": "zelk12/Rv0.4MT4g2-gemma-2-9B",
    "score": 0.3
  },
  {
    "model": "Aryanne/QwentileSwap",
    "score": 0.296
  },
  {
    "model": "DavidAU/Gemma-The-Writer-9B",
    "score": 0.296
  },
  {
    "model": "DavidAU/Gemma-The-Writer-Mighty-Sword-9B",
    "score": 0.296
  },
  {
    "model": "DreadPoor/test_ALT",
    "score": 0.296
  },
  {
    "model": "MaziyarPanahi/calme-2.4-llama3-70b",
    "score": 0.296
  },
  {
    "model": "NousResearch/Hermes-3-Llama-3.1-70B",
    "score": 0.296
  },
  {
    "model": "Quazim0t0/Dyson-14b",
    "score": 0.296
  },
  {
    "model": "Quazim0t0/Fugazi14b",
    "score": 0.296
  },
  {
    "model": "Quazim0t0/Hyde-14b-sce",
    "score": 0.296
  },
  {
    "model": "Quazim0t0/Loke-14B-sce",
    "score": 0.296
  },
  {
    "model": "Quazim0t0/SZA-14B-sce",
    "score": 0.296
  },
  {
    "model": "Quazim0t0/tesseract-14b-stock",
    "score": 0.296
  },
  {
    "model": "Steelskull/L3.3-Nevoria-R1-70b",
    "score": 0.296
  },
  {
    "model": "TheDrummer/Tiger-Gemma-9B-v1",
    "score": 0.296
  },
  {
    "model": "TheDrummer/Tiger-Gemma-9B-v2",
    "score": 0.296
  },
  {
    "model": "Triangle104/Set-70b",
    "score": 0.296
  },
  {
    "model": "ValiantLabs/Llama3.1-70B-ShiningValiant2",
    "score": 0.296
  },
  {
    "model": "YOYO-AI/Qwen2.5-Coder-14B-YOYO-1010",
    "score": 0.296
  },
  {
    "model": "bunnycore/Phi-4-Model-Stock-v4",
    "score": 0.296
  },
  {
    "model": "bunnycore/Phi-4-Stock-Ex",
    "score": 0.296
  },
  {
    "model": "cat-searcher/gemma-2-9b-it-sppo-iter-1-evol-1",
    "score": 0.296
  },
  {
    "model": "grimjim/Magot-v2-Gemma2-8k-9B",
    "score": 0.296
  },
  {
    "model": "lemon07r/Gemma-2-Ataraxy-v3b-9B",
    "score": 0.296
  },
  {
    "model": "lemon07r/Gemma-2-Ataraxy-v4a-Advanced-9B",
    "score": 0.296
  },
  {
    "model": "migtissera/Llama-3-70B-Synthia-v3.5",
    "score": 0.296
  },
  {
    "model": "pankajmathur/orca_mini_v8_1_70b",
    "score": 0.296
  },
  {
    "model": "recoilme/recoilme-gemma-2-9B-v0.4",
    "score": 0.296
  },
  {
    "model": "zelk12/MT-Merge3-gemma-2-9B",
    "score": 0.296
  },
  {
    "model": "zelk12/MT-Merge5-gemma-2-9B",
    "score": 0.296
  },
  {
    "model": "zelk12/MT2-Gen6-gemma-2-9B",
    "score": 0.296
  },
  {
    "model": "zelk12/MT2-gemma-2-9B",
    "score": 0.296
  },
  {
    "model": "zelk12/MT3-Gen2-gemma-2-9B",
    "score": 0.296
  },
  {
    "model": "zelk12/MT4-Max-Merge_02012025163610-gemma-2-9B",
    "score": 0.296
  },
  {
    "model": "zelk12/MT5-Gen3-gemma-2-9B",
    "score": 0.296
  },
  {
    "model": "zelk12/MT5-Gen4-gemma-2-9B",
    "score": 0.296
  },
  {
    "model": "zelk12/MT5-Gen5-gemma-2-9B",
    "score": 0.296
  },
  {
    "model": "zelk12/MT5-Max-Merge_02012025163610-gemma-2-9B",
    "score": 0.296
  },
  {
    "model": "HelpingAI/Cipher-20B",
    "score": 0.292
  },
  {
    "model": "KSU-HW-SEC/Llama3-70b-SVA-FT-500",
    "score": 0.292
  },
  {
    "model": "MaziyarPanahi/calme-2.3-llama3-70b",
    "score": 0.292
  },
  {
    "model": "Quazim0t0/Halo-14B-sce",
    "score": 0.292
  },
  {
    "model": "Quazim0t0/MFDOOM-14B",
    "score": 0.292
  },
  {
    "model": "Quazim0t0/Rune-14b",
    "score": 0.292
  },
  {
    "model": "Quazim0t0/mocha-14B",
    "score": 0.292
  },
  {
    "model": "Saxo/Linkbricks-Horizon-AI-Korean-Avengers-V2-27B",
    "score": 0.292
  },
  {
    "model": "Skywork/Skywork-Reward-Gemma-2-27B-v0.2",
    "score": 0.292
  },
  {
    "model": "Steelskull/L3.3-MS-Nevoria-70b",
    "score": 0.292
  },
  {
    "model": "TheDrummer/Tiger-Gemma-9B-v3",
    "score": 0.292
  },
  {
    "model": "dnhkng/RYS-Llama-3-Huge-Instruct",
    "score": 0.292
  },
  {
    "model": "ehristoforu/fp4-14b-v1-fix",
    "score": 0.292
  },
  {
    "model": "failspy/llama-3-70B-Instruct-abliterated",
    "score": 0.292
  },
  {
    "model": "lemon07r/Gemma-2-Ataraxy-v2a-9B",
    "score": 0.292
  },
  {
    "model": "lemon07r/Gemma-2-Ataraxy-v3-Advanced-9B",
    "score": 0.292
  },
  {
    "model": "lemon07r/Gemma-2-Ataraxy-v4-Advanced-9B",
    "score": 0.292
  },
  {
    "model": "m42-health/Llama3-Med42-70B",
    "score": 0.292
  },
  {
    "model": "mlabonne/Hermes-3-Llama-3.1-70B-lorablated",
    "score": 0.292
  },
  {
    "model": "nisten/tqwendo-36b",
    "score": 0.292
  },
  {
    "model": "pankajmathur/orca_mini_v9_2_70b",
    "score": 0.292
  },
  {
    "model": "princeton-nlp/gemma-2-9b-it-SimPO",
    "score": 0.292
  },
  {
    "model": "princeton-nlp/gemma-2-9b-it-DPO",
    "score": 0.292
  },
  {
    "model": "recoilme/recoilme-gemma-2-9B-v0.2",
    "score": 0.292
  },
  {
    "model": "recoilme/recoilme-gemma-2-9B-v0.2",
    "score": 0.292
  },
  {
    "model": "sam-paech/Quill-v1",
    "score": 0.292
  },
  {
    "model": "zelk12/MT-Gen7-gemma-2-9B",
    "score": 0.292
  },
  {
    "model": "zelk12/MT-Merge1-gemma-2-9B",
    "score": 0.292
  },
  {
    "model": "zelk12/MT2-Max-Merge_02012025163610-gemma-2-9B",
    "score": 0.292
  },
  {
    "model": "zelk12/MT3-Gen3-gemma-2-9B",
    "score": 0.292
  },
  {
    "model": "zelk12/recoilme-gemma-2-Ifable-9B-v0.1",
    "score": 0.292
  },
  {
    "model": "zetasepic/Qwen2.5-72B-Instruct-abliterated",
    "score": 0.292
  },
  {
    "model": "BAAI/Gemma2-9B-IT-Simpo-Infinity-Preference",
    "score": 0.288
  },
  {
    "model": "Cran-May/merge_model_20250308_4",
    "score": 0.288
  },
  {
    "model": "DavidAU/Gemma-The-Writer-DEADLINE-10B",
    "score": 0.288
  },
  {
    "model": "DavidAU/Gemma-The-Writer-N-Restless-Quill-10B-Uncensored",
    "score": 0.288
  },
  {
    "model": "DreadPoor/Kindling-8B-Model_Stock",
    "score": 0.288
  },
  {
    "model": "Quazim0t0/1up-14b",
    "score": 0.288
  },
  {
    "model": "Quazim0t0/Imbue-14b",
    "score": 0.288
  },
  {
    "model": "Quazim0t0/Jigsaw-14B-Linear",
    "score": 0.288
  },
  {
    "model": "Quazim0t0/Lineage-14B",
    "score": 0.288
  },
  {
    "model": "Quazim0t0/Mithril-14B-sce",
    "score": 0.288
  },
  {
    "model": "Quazim0t0/NovaScotia-14b-stock",
    "score": 0.288
  },
  {
    "model": "Quazim0t0/ODB-14b-sce",
    "score": 0.288
  },
  {
    "model": "Quazim0t0/ODB-14b-sce",
    "score": 0.288
  },
  {
    "model": "Quazim0t0/Wendy-14B",
    "score": 0.288
  },
  {
    "model": "Qwen/Qwen2.5-Coder-32B-Instruct",
    "score": 0.288
  },
  {
    "model": "ValiantLabs/Llama3-70B-Fireplace",
    "score": 0.288
  },
  {
    "model": "allknowingroger/GemmaSlerp4-10B",
    "score": 0.288
  },
  {
    "model": "arcee-ai/Llama-Spark",
    "score": 0.288
  },
  {
    "model": "bunnycore/Phi-4-Model-Stock-v3",
    "score": 0.288
  },
  {
    "model": "bunnycore/Phi-4-Sce-exp-v0.1",
    "score": 0.288
  },
  {
    "model": "dnhkng/RYS-XLarge-base",
    "score": 0.288
  },
  {
    "model": "failspy/Meta-Llama-3-70B-Instruct-abliterated-v3.5",
    "score": 0.288
  },
  {
    "model": "google/gemma-2-27b-it",
    "score": 0.288
  },
  {
    "model": "jebish7/gemma-2-9b-it",
    "score": 0.288
  },
  {
    "model": "lemon07r/Gemma-2-Ataraxy-9B",
    "score": 0.288
  },
  {
    "model": "lemon07r/Gemma-2-Ataraxy-v2f-9B",
    "score": 0.288
  },
  {
    "model": "microsoft/phi-4",
    "score": 0.288
  },
  {
    "model": "microsoft/phi-4",
    "score": 0.288
  },
  {
    "model": "nbeerbower/gemma2-gutenberg-9B",
    "score": 0.288
  },
  {
    "model": "newsbang/Homer-v1.0-Qwen2.5-72B",
    "score": 0.288
  },
  {
    "model": "prithivMLmods/Epimetheus-14B-Axo",
    "score": 0.288
  },
  {
    "model": "prithivMLmods/Viper-Coder-v0.1",
    "score": 0.288
  },
  {
    "model": "recoilme/Gemma-2-Ataraxy-Gemmasutra-9B-slerp",
    "score": 0.288
  },
  {
    "model": "recoilme/Gemma-2-Ataraxy-Gemmasutra-9B-slerp",
    "score": 0.288
  },
  {
    "model": "sometimesanotion/Qwenvergence-14B-v11",
    "score": 0.288
  },
  {
    "model": "tannedbum/Ellaria-9B",
    "score": 0.288
  },
  {
    "model": "unsloth/phi-4",
    "score": 0.288
  },
  {
    "model": "zelk12/MT4-Gen5-gemma-2-9B",
    "score": 0.288
  },
  {
    "model": "zelk12/recoilme-gemma-2-Ataraxy-9B-v0.1",
    "score": 0.288
  },
  {
    "model": "Amaorynho/BBAIIFEV1",
    "score": 0.284
  },
  {
    "model": "Cran-May/tempmotacilla-cinerea-0308",
    "score": 0.284
  },
  {
    "model": "CultriX/Qwen2.5-14B-Wernicke-SFT",
    "score": 0.284
  },
  {
    "model": "KSU-HW-SEC/Llama3-70b-SVA-FT-1415",
    "score": 0.284
  },
  {
    "model": "KSU-HW-SEC/Llama3-70b-SVA-FT-final",
    "score": 0.284
  },
  {
    "model": "LightningRodLabs/Flashlight-v1.0",
    "score": 0.284
  },
  {
    "model": "Quazim0t0/GuiltySpark-14B-ties",
    "score": 0.284
  },
  {
    "model": "Quazim0t0/Phi4Basis-14B-sce",
    "score": 0.284
  },
  {
    "model": "Quazim0t0/Ponder-14B-linear",
    "score": 0.284
  },
  {
    "model": "Quazim0t0/Rosemary-14b",
    "score": 0.284
  },
  {
    "model": "Quazim0t0/Spok-14b-sce",
    "score": 0.284
  },
  {
    "model": "Qwen/Qwen2-VL-72B-Instruct",
    "score": 0.284
  },
  {
    "model": "Saxo/Linkbricks-Horizon-AI-Korean-Avengers-V3-27B",
    "score": 0.284
  },
  {
    "model": "Triangle104/Pans_Gutenbergum_V0.1",
    "score": 0.284
  },
  {
    "model": "bunnycore/Phi-4-RP-v0",
    "score": 0.284
  },
  {
    "model": "bunnycore/Phi-4-RR-Shoup",
    "score": 0.284
  },
  {
    "model": "dnhkng/RYS-Medium",
    "score": 0.284
  },
  {
    "model": "ehristoforu/Gemma2-9b-it-train6",
    "score": 0.284
  },
  {
    "model": "huihui-ai/QwQ-32B-Coder-Fusion-8020",
    "score": 0.284
  },
  {
    "model": "lemon07r/Gemma-2-Ataraxy-v2-9B",
    "score": 0.284
  },
  {
    "model": "microsoft/Phi-3-small-8k-instruct",
    "score": 0.284
  },
  {
    "model": "mistralai/Mistral-Large-Instruct-2411",
    "score": 0.284
  },
  {
    "model": "mlx-community/Mistral-Small-24B-Instruct-2501-bf16",
    "score": 0.284
  },
  {
    "model": "nbeerbower/Gemma2-Gutenberg-Doppel-9B",
    "score": 0.284
  },
  {
    "model": "recoilme/recoilme-gemma-2-9B-v0.1",
    "score": 0.284
  },
  {
    "model": "ssmits/Qwen2.5-95B-Instruct",
    "score": 0.284
  },
  {
    "model": "DavidAU/Gemma-The-Writer-J.GutenBerg-10B",
    "score": 0.28
  },
  {
    "model": "EVA-UNIT-01/EVA-Qwen2.5-72B-v0.2",
    "score": 0.28
  },
  {
    "model": "MaziyarPanahi/calme-2.2-rys-78b",
    "score": 0.28
  },
  {
    "model": "OpenBuddy/openbuddy-llama3.3-70b-v24.1-131k",
    "score": 0.28
  },
  {
    "model": "OpenGenerativeAI/Bifrost",
    "score": 0.28
  },
  {
    "model": "Quazim0t0/Lo-Phi-14b",
    "score": 0.28
  },
  {
    "model": "Quazim0t0/Wu-14b-sce",
    "score": 0.28
  },
  {
    "model": "Quazim0t0/time-14b-stock",
    "score": 0.28
  },
  {
    "model": "Quazim0t0/mosaic-14b-sce",
    "score": 0.28
  },
  {
    "model": "Sao10K/L3-70B-Euryale-v2.1",
    "score": 0.28
  },
  {
    "model": "Sao10K/L3-70B-Euryale-v2.1",
    "score": 0.28
  },
  {
    "model": "YOYO-AI/ZYH-LLM-Qwen2.5-14B-V2",
    "score": 0.28
  },
  {
    "model": "anthracite-org/magnum-v2-72b",
    "score": 0.28
  },
  {
    "model": "arshiaafshani/Arsh-V1",
    "score": 0.28
  },
  {
    "model": "dnhkng/RYS-XLarge",
    "score": 0.28
  },
  {
    "model": "lars1234/Mistral-Small-24B-Instruct-2501-writer",
    "score": 0.28
  },
  {
    "model": "lemon07r/Gemma-2-Ataraxy-Remix-9B",
    "score": 0.28
  },
  {
    "model": "nbeerbower/Llama3.1-Gutenberg-Doppel-70B",
    "score": 0.28
  },
  {
    "model": "prithivMLmods/Eridanus-Opus-14B-r999",
    "score": 0.28
  },
  {
    "model": "prithivMLmods/GWQ-9B-Preview",
    "score": 0.28
  },
  {
    "model": "prithivMLmods/GWQ-9B-Preview2",
    "score": 0.28
  },
  {
    "model": "rootxhacker/Apollo-70B",
    "score": 0.28
  },
  {
    "model": "sometimesanotion/Qwenvergence-14B-v15-Prose-MS",
    "score": 0.28
  },
  {
    "model": "speakleash/Bielik-11B-v2.0-Instruct",
    "score": 0.28
  },
  {
    "model": "suayptalha/Luminis-phi-4",
    "score": 0.28
  },
  {
    "model": "tensopolis/phi-4-tensopolis-v1",
    "score": 0.28
  },
  {
    "model": "wanlige/li-14b-v0.4-slerp",
    "score": 0.28
  },
  {
    "model": "zelk12/recoilme-gemma-2-Ataraxy-9B-v0.1-t0.75",
    "score": 0.28
  },
  {
    "model": "zelk12/recoilme-gemma-2-Ataraxy-9B-v0.2",
    "score": 0.28
  },
  {
    "model": "zelk12/recoilme-gemma-2-psy10k-mental_healt-9B-v0.1",
    "score": 0.28
  },
  {
    "model": "Danielbrdz/Barcenas-14b-phi-4",
    "score": 0.276
  },
  {
    "model": "Danielbrdz/Barcenas-14b-phi-4-v2",
    "score": 0.276
  },
  {
    "model": "DreadPoor/Noxis-8B-LINEAR",
    "score": 0.276
  },
  {
    "model": "DreadPoor/Rusted_Gold-8B-LINEAR",
    "score": 0.276
  },
  {
    "model": "DreadPoor/VENN_1.2-8B-Model_Stock",
    "score": 0.276
  },
  {
    "model": "FINGU-AI/QwQ-Buddy-32B-Alpha",
    "score": 0.276
  },
  {
    "model": "OpenBuddy/openbuddy-zero-56b-v21.2-32k",
    "score": 0.276
  },
  {
    "model": "Quazim0t0/Casa-14b-sce",
    "score": 0.276
  },
  {
    "model": "Quazim0t0/Casa-14b-sce",
    "score": 0.276
  },
  {
    "model": "Quazim0t0/Edu-14B-Linear",
    "score": 0.276
  },
  {
    "model": "Quazim0t0/SuperNova14b",
    "score": 0.276
  },
  {
    "model": "Quazim0t0/Venti-Blend-sce",
    "score": 0.276
  },
  {
    "model": "Quazim0t0/Vine-14b-sce",
    "score": 0.276
  },
  {
    "model": "Quazim0t0/caramel-14B",
    "score": 0.276
  },
  {
    "model": "Qwen/Qwen2-72B-Instruct",
    "score": 0.276
  },
  {
    "model": "Qwen/Qwen2.5-Coder-14B-Instruct",
    "score": 0.276
  },
  {
    "model": "Saxo/Linkbricks-Horizon-AI-Avengers-V1-32B",
    "score": 0.276
  },
  {
    "model": "Saxo/Linkbricks-Horizon-AI-Avengers-V5-32B",
    "score": 0.276
  },
  {
    "model": "Sorawiz/Gemma-9B-Base",
    "score": 0.276
  },
  {
    "model": "T145/ZEUS-8B-V17-abliterated",
    "score": 0.276
  },
  {
    "model": "UCLA-AGI/Gemma-2-9B-It-SPPO-Iter1",
    "score": 0.276
  },
  {
    "model": "Undi95/MG-FinalMix-72B",
    "score": 0.276
  },
  {
    "model": "ValiantLabs/Llama3-70B-ShiningValiant2",
    "score": 0.276
  },
  {
    "model": "Youlln/4PRYMMAL-GEMMA2-9B-SLERP",
    "score": 0.276
  },
  {
    "model": "abacusai/Smaug-Llama-3-70B-Instruct-32K",
    "score": 0.276
  },
  {
    "model": "bunnycore/Phi-4-Model-Stock-v2",
    "score": 0.276
  },
  {
    "model": "djuna/L3.1-Promissum_Mane-8B-Della-calc",
    "score": 0.276
  },
  {
    "model": "djuna/Q2.5-Veltha-14B",
    "score": 0.276
  },
  {
    "model": "hotmailuser/Gemma2magnum-27b",
    "score": 0.276
  },
  {
    "model": "lemon07r/Gemma-2-Ataraxy-v3i-9B",
    "score": 0.276
  },
  {
    "model": "lemon07r/Gemma-2-Ataraxy-v3j-9B",
    "score": 0.276
  },
  {
    "model": "maldv/Awqward2.5-32B-Instruct",
    "score": 0.276
  },
  {
    "model": "maldv/Qwentile2.5-32B-Instruct",
    "score": 0.276
  },
  {
    "model": "microsoft/Phi-3-medium-128k-instruct",
    "score": 0.276
  },
  {
    "model": "prithivMLmods/Evac-Opus-14B-Exp",
    "score": 0.276
  },
  {
    "model": "sthenno-com/miscii-14b-0130",
    "score": 0.276
  },
  {
    "model": "01-ai/Yi-1.5-34B-32K",
    "score": 0.272
  },
  {
    "model": "AELLM/gemma-2-lyco-infinity-9b",
    "score": 0.272
  },
  {
    "model": "CultriX/Qwen2.5-14B-ReasoningMerge",
    "score": 0.272
  },
  {
    "model": "CultriX/SeQwence-14Bv2",
    "score": 0.272
  },
  {
    "model": "Danielbrdz/Barcenas-14b-Phi-3-medium-ORPO",
    "score": 0.272
  },
  {
    "model": "DreadPoor/Lydia_of_Whiterun-8B-LINEAR",
    "score": 0.272
  },
  {
    "model": "DreadPoor/Morphing-8B-Model_Stock",
    "score": 0.272
  },
  {
    "model": "DreadPoor/Promissum_Mane-8B-LINEAR-lorablated",
    "score": 0.272
  },
  {
    "model": "DreadPoor/Yearn_V3-8B-Model_Stock",
    "score": 0.272
  },
  {
    "model": "DreadPoor/remember_to_breathe-8b-Model-Stock",
    "score": 0.272
  },
  {
    "model": "DreadPoor/test",
    "score": 0.272
  },
  {
    "model": "EpistemeAI/DeepThinkers-Phi4",
    "score": 0.272
  },
  {
    "model": "FINGU-AI/RomboUltima-32B",
    "score": 0.272
  },
  {
    "model": "GreenNode/GreenNode-small-9B-it",
    "score": 0.272
  },
  {
    "model": "Lambent/qwen2.5-reinstruct-alternate-lumen-14B",
    "score": 0.272
  },
  {
    "model": "Lunzima/NQLSG-Qwen2.5-14B-OriginalFusion",
    "score": 0.272
  },
  {
    "model": "Quazim0t0/Alice-14B",
    "score": 0.272
  },
  {
    "model": "Quazim0t0/Geedorah-14B",
    "score": 0.272
  },
  {
    "model": "Quazim0t0/Knot-CoT-14B-sce",
    "score": 0.272
  },
  {
    "model": "Quazim0t0/MFGRIMM-14B",
    "score": 0.272
  },
  {
    "model": "Quazim0t0/RZA-14B-sce",
    "score": 0.272
  },
  {
    "model": "Quazim0t0/bloom-14b-stock",
    "score": 0.272
  },
  {
    "model": "Sorawiz/Gemma-Creative-9B-Base",
    "score": 0.272
  },
  {
    "model": "T145/KRONOS-8B-V2",
    "score": 0.272
  },
  {
    "model": "T145/ZEUS-8B-V11",
    "score": 0.272
  },
  {
    "model": "Undi95/Phi4-abliterated",
    "score": 0.272
  },
  {
    "model": "abacusai/Dracarys-72B-Instruct",
    "score": 0.272
  },
  {
    "model": "agentlans/Llama3.1-LexiHermes-SuperStorm",
    "score": 0.272
  },
  {
    "model": "allenai/Llama-3.1-Tulu-3-70B-SFT",
    "score": 0.272
  },
  {
    "model": "allknowingroger/Qwenslerp2-14B",
    "score": 0.272
  },
  {
    "model": "cognitivecomputations/Dolphin3.0-R1-Mistral-24B",
    "score": 0.272
  },
  {
    "model": "dfurman/Qwen2-72B-Orpo-v0.1",
    "score": 0.272
  },
  {
    "model": "djuna/Gemma-2-gemmama-9b",
    "score": 0.272
  },
  {
    "model": "ehristoforu/qwen2.5-test-32b-it",
    "score": 0.272
  },
  {
    "model": "flammenai/Llama3.1-Flammades-70B",
    "score": 0.272
  },
  {
    "model": "grimjim/llama-3-Nephilim-v1-8B",
    "score": 0.272
  },
  {
    "model": "jpacifico/Chocolatine-14B-Instruct-DPO-v1.3",
    "score": 0.272
  },
  {
    "model": "marcuscedricridia/etr1o-v1.2",
    "score": 0.272
  },
  {
    "model": "meta-llama/Meta-Llama-3-70B",
    "score": 0.272
  },
  {
    "model": "prithivMLmods/Cygnus-II-14B",
    "score": 0.272
  },
  {
    "model": "prithivMLmods/Megatron-Corpus-14B-Exp.v2",
    "score": 0.272
  },
  {
    "model": "prithivMLmods/Tadpole-Opus-14B-Exp",
    "score": 0.272
  },
  {
    "model": "recoilme/recoilme-gemma-2-9B-v0.5",
    "score": 0.272
  },
  {
    "model": "rombodawg/Rombos-Coder-V2.5-Qwen-14b",
    "score": 0.272
  },
  {
    "model": "silma-ai/SILMA-9B-Instruct-v1.0",
    "score": 0.272
  },
  {
    "model": "sometimesanotion/Qwenvergence-14B-v3",
    "score": 0.272
  },
  {
    "model": "sthenno/tempesthenno-0120",
    "score": 0.272
  },
  {
    "model": "sthenno/tempesthenno-nuslerp-0124",
    "score": 0.272
  },
  {
    "model": "google/gemma-2-9b-it",
    "score": 0.268
  },
  {
    "model": "CombinHorizon/YiSM-blossom5.1-34B-SLERP",
    "score": 0.268
  },
  {
    "model": "CultriX/Qwen2.5-14B-Broca",
    "score": 0.268
  },
  {
    "model": "CultriX/Qwen2.5-14B-Wernicke",
    "score": 0.268
  },
  {
    "model": "DoppelReflEx/MN-12B-LilithFrame-Experiment-3",
    "score": 0.268
  },
  {
    "model": "DoppelReflEx/MiniusLight-24B-v1c-test",
    "score": 0.268
  },
  {
    "model": "DreadPoor/Derivative_V2_ALT-8B-Model_Stock",
    "score": 0.268
  },
  {
    "model": "DreadPoor/Happy_New_Year-8B-Model_Stock",
    "score": 0.268
  },
  {
    "model": "DreadPoor/Heart_Stolen-8B-Model_Stock",
    "score": 0.268
  },
  {
    "model": "DreadPoor/Matryoshka-8B-LINEAR",
    "score": 0.268
  },
  {
    "model": "MaziyarPanahi/calme-2.2-qwen2-72b",
    "score": 0.268
  },
  {
    "model": "Quazim0t0/Insom",
    "score": 0.268
  },
  {
    "model": "Quazim0t0/Phi4.Turn.R1Distill.16bit",
    "score": 0.268
  },
  {
    "model": "Quazim0t0/Venti-20b",
    "score": 0.268
  },
  {
    "model": "Saxo/Linkbricks-Horizon-AI-Avengers-V2-32B",
    "score": 0.268
  },
  {
    "model": "Triangle104/Robo-Gutenberg_V1.0",
    "score": 0.268
  },
  {
    "model": "Xclbr7/Hyena-12b",
    "score": 0.268
  },
  {
    "model": "allknowingroger/Yi-blossom-40B",
    "score": 0.268
  },
  {
    "model": "baconnier/Napoleon_24B_V0.0",
    "score": 0.268
  },
  {
    "model": "bunnycore/HyperLlama-3.1-8B",
    "score": 0.268
  },
  {
    "model": "dwikitheduck/gen-try1-notemp",
    "score": 0.268
  },
  {
    "model": "flammenai/Mahou-1.5-llama3.1-70B",
    "score": 0.268
  },
  {
    "model": "hotmailuser/Mistral-modelstock2-24B",
    "score": 0.268
  },
  {
    "model": "jpacifico/Chocolatine-2-14B-Instruct-DPO-v2.0b1",
    "score": 0.268
  },
  {
    "model": "jpacifico/Chocolatine-2-14B-Instruct-v2.0",
    "score": 0.268
  },
  {
    "model": "jpacifico/Chocolatine-2-14B-Instruct-v2.0.1",
    "score": 0.268
  },
  {
    "model": "mrm8488/phi-4-14B-grpo-gsm8k-3e",
    "score": 0.268
  },
  {
    "model": "mrm8488/phi-4-14B-grpo-limo",
    "score": 0.268
  },
  {
    "model": "prithivMLmods/Phi-4-Super-1",
    "score": 0.268
  },
  {
    "model": "prithivMLmods/Phi-4-Super-o1",
    "score": 0.268
  },
  {
    "model": "prithivMLmods/Tucana-Opus-14B-r999",
    "score": 0.268
  },
  {
    "model": "rootxhacker/Apollo_v2-32B",
    "score": 0.268
  },
  {
    "model": "sakaltcommunity/novablast-preview",
    "score": 0.268
  },
  {
    "model": "sometimesanotion/Qwenvergence-14B-qv256",
    "score": 0.268
  },
  {
    "model": "wanlige/li-14b-v0.4-slerp0.1",
    "score": 0.268
  },
  {
    "model": "zetasepic/Qwen2.5-32B-Instruct-abliterated-v2",
    "score": 0.268
  },
  {
    "model": "CultriX/Qwen2.5-14B-Hyperionv4",
    "score": 0.264
  },
  {
    "model": "CultriX/SeQwence-14Bv3",
    "score": 0.264
  },
  {
    "model": "Daemontatox/CogitoZ",
    "score": 0.264
  },
  {
    "model": "Daemontatox/PathfinderAI",
    "score": 0.264
  },
  {
    "model": "Daemontatox/PathfinderAI",
    "score": 0.264
  },
  {
    "model": "DreadPoor/BaeZel_V3-8B-Model_Stock",
    "score": 0.264
  },
  {
    "model": "DreadPoor/Elusive_Dragon_Heart-8B-LINEAR",
    "score": 0.264
  },
  {
    "model": "DreadPoor/Here_We_Go_Again-8B-SLERP",
    "score": 0.264
  },
  {
    "model": "DreadPoor/Laughing_Stock-8B-Model_Stock",
    "score": 0.264
  },
  {
    "model": "DreadPoor/Summer_Dusk-8B-TIES",
    "score": 0.264
  },
  {
    "model": "DreadPoor/mergekit-nuslerp-nqzkedi",
    "score": 0.264
  },
  {
    "model": "LightningRodLabs/Flashlight-v1.1",
    "score": 0.264
  },
  {
    "model": "MaziyarPanahi/calme-2.1-qwen2-72b",
    "score": 0.264
  },
  {
    "model": "Nohobby/MS-Schisandra-22B-v0.1",
    "score": 0.264
  },
  {
    "model": "OpenGenerativeAI/Bifrost-14B",
    "score": 0.264
  },
  {
    "model": "Quazim0t0/Sake-20b",
    "score": 0.264
  },
  {
    "model": "Sakalti/Oxyge1-33B",
    "score": 0.264
  },
  {
    "model": "Sakalti/ultiima-14B-v0.4",
    "score": 0.264
  },
  {
    "model": "Sakalti/ultiima-32B",
    "score": 0.264
  },
  {
    "model": "Saxo/Linkbricks-Horizon-AI-Avengers-V4-32B",
    "score": 0.264
  },
  {
    "model": "Saxo/Linkbricks-Horizon-AI-Korean-Superb-22B",
    "score": 0.264
  },
  {
    "model": "TheDrummer/Gemmasutra-9B-v1",
    "score": 0.264
  },
  {
    "model": "abideen/MedPhi-4-14B-v1",
    "score": 0.264
  },
  {
    "model": "allenai/Llama-3.1-Tulu-3-70B",
    "score": 0.264
  },
  {
    "model": "allenai/Llama-3.1-Tulu-3-70B",
    "score": 0.264
  },
  {
    "model": "allura-org/Mistral-Small-24b-Sertraline-0304",
    "score": 0.264
  },
  {
    "model": "altomek/YiSM-34B-0rn",
    "score": 0.264
  },
  {
    "model": "benhaotang/phi4-qwq-sky-t1",
    "score": 0.264
  },
  {
    "model": "bunnycore/Phi-4-Model-Stock",
    "score": 0.264
  },
  {
    "model": "cognitivecomputations/dolphin-2.9.1-yi-1.5-34b",
    "score": 0.264
  },
  {
    "model": "cognitivecomputations/dolphin-2.9.2-Phi-3-Medium-abliterated",
    "score": 0.264
  },
  {
    "model": "cognitivecomputations/dolphin-2.9.2-Phi-3-Medium-abliterated",
    "score": 0.264
  },
  {
    "model": "fblgit/TheBeagle-v2beta-32B-MGS",
    "score": 0.264
  },
  {
    "model": "fblgit/TheBeagle-v2beta-32B-MGS",
    "score": 0.264
  },
  {
    "model": "flammenai/Mahou-1.2a-llama3-8B",
    "score": 0.264
  },
  {
    "model": "huihui-ai/QwQ-32B-Coder-Fusion-9010",
    "score": 0.264
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-gamma-8B",
    "score": 0.264
  },
  {
    "model": "jaspionjader/fr-10-8b",
    "score": 0.264
  },
  {
    "model": "meditsolutions/Llama-3.1-MedIT-SUN-8B",
    "score": 0.264
  },
  {
    "model": "mlabonne/BigQwen2.5-52B-Instruct",
    "score": 0.264
  },
  {
    "model": "nhyha/N3N_gemma-2-9b-it_20241029_1532",
    "score": 0.264
  },
  {
    "model": "nhyha/N3N_gemma-2-9b-it_20241110_2026",
    "score": 0.264
  },
  {
    "model": "nlpguy/Miisce-one",
    "score": 0.264
  },
  {
    "model": "pankajmathur/orca_mini_v7_72b",
    "score": 0.264
  },
  {
    "model": "prithivMLmods/Jolt-v0.1",
    "score": 0.264
  },
  {
    "model": "prithivMLmods/Viper-Coder-v1.7-Vsm6",
    "score": 0.264
  },
  {
    "model": "recoilme/recoilme-gemma-2-9B-v0.3",
    "score": 0.264
  },
  {
    "model": "recoilme/recoilme-gemma-2-9B-v0.3",
    "score": 0.264
  },
  {
    "model": "sometimesanotion/LamarckInfusion-14B-v1",
    "score": 0.264
  },
  {
    "model": "sometimesanotion/LamarckInfusion-14B-v2-lo",
    "score": 0.264
  },
  {
    "model": "spow12/ChatWaifu_22B_v2.0_preview",
    "score": 0.264
  },
  {
    "model": "wanlige/li-14b-v0.4",
    "score": 0.264
  },
  {
    "model": "1-800-LLMs/Qwen-2.5-14B-Hindi",
    "score": 0.26
  },
  {
    "model": "4season/final_model_test_v2",
    "score": 0.26
  },
  {
    "model": "BlackBeenie/Neos-Gemma-2-9b",
    "score": 0.26
  },
  {
    "model": "Cran-May/merge_model_20250308_3",
    "score": 0.26
  },
  {
    "model": "CultriX/Qwen2.5-14B-Hyper",
    "score": 0.26
  },
  {
    "model": "Daemontatox/Llama3.3-70B-CogniLink",
    "score": 0.26
  },
  {
    "model": "Daemontatox/PathFinderAI2.0",
    "score": 0.26
  },
  {
    "model": "DavidAU/L3-Dark-Planet-8B",
    "score": 0.26
  },
  {
    "model": "DoppelReflEx/L3-8B-R1-WolfCore-V1.5-test",
    "score": 0.26
  },
  {
    "model": "DreadPoor/Aurora_faustus-8B-LINEAR",
    "score": 0.26
  },
  {
    "model": "DreadPoor/Minus_Penus-8B-Model_Stock",
    "score": 0.26
  },
  {
    "model": "DreadPoor/Nwah-8B-Model_Stock",
    "score": 0.26
  },
  {
    "model": "DreadPoor/ZEUS-8B-V17-Abliterated_ALT",
    "score": 0.26
  },
  {
    "model": "DreadPoor/Zelus_V2-8B-Model_Stock",
    "score": 0.26
  },
  {
    "model": "DreadPoor/Zelus-8B-Model_Stock",
    "score": 0.26
  },
  {
    "model": "Eurdem/Defne-llama3.1-8B",
    "score": 0.26
  },
  {
    "model": "Gunulhona/Gemma-Ko-Merge-PEFT",
    "score": 0.26
  },
  {
    "model": "Gunulhona/Gemma-Ko-Merge-PEFT",
    "score": 0.26
  },
  {
    "model": "Joseph717171/Llama-3.1-SuperNova-8B-Lite_TIES_with_Base",
    "score": 0.26
  },
  {
    "model": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v6",
    "score": 0.26
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_Dolermed_R1_V1.03",
    "score": 0.26
  },
  {
    "model": "Nitral-AI/Captain_BMO-12B",
    "score": 0.26
  },
  {
    "model": "Nohobby/MS-Schisandra-22B-v0.2",
    "score": 0.26
  },
  {
    "model": "Qwen/Qwen2-Math-72B-Instruct",
    "score": 0.26
  },
  {
    "model": "Saxo/Linkbricks-Horizon-AI-Superb-27B",
    "score": 0.26
  },
  {
    "model": "SicariusSicariiStuff/Redemption_Wind_24B",
    "score": 0.26
  },
  {
    "model": "T145/ZEUS-8B-V14",
    "score": 0.26
  },
  {
    "model": "T145/ZEUS-8B-V16",
    "score": 0.26
  },
  {
    "model": "TheTsar1209/qwen-carpmuscle-v0.4",
    "score": 0.26
  },
  {
    "model": "Xclbr7/caliburn-12b",
    "score": 0.26
  },
  {
    "model": "YOYO-AI/Qwen2.5-14B-YOYO-1005-v2",
    "score": 0.26
  },
  {
    "model": "ZeroXClem/L3-Aspire-Heart-Matrix-8B",
    "score": 0.26
  },
  {
    "model": "allknowingroger/MistralPhi3-11B",
    "score": 0.26
  },
  {
    "model": "allura-org/TQ2.5-14B-Aletheia-v1",
    "score": 0.26
  },
  {
    "model": "arcee-ai/SuperNova-Medius",
    "score": 0.26
  },
  {
    "model": "arcee-ai/Virtuoso-Small-v2",
    "score": 0.26
  },
  {
    "model": "bunnycore/Gemma2-9B-TitanFusion",
    "score": 0.26
  },
  {
    "model": "djuna/Q2.5-Veltha-14B-0.5",
    "score": 0.26
  },
  {
    "model": "dnhkng/RYS-Phi-3-medium-4k-instruct",
    "score": 0.26
  },
  {
    "model": "dwikitheduck/gen-try1",
    "score": 0.26
  },
  {
    "model": "ehristoforu/phi-4-25b",
    "score": 0.26
  },
  {
    "model": "hotmailuser/Falcon3Slerp1-10B",
    "score": 0.26
  },
  {
    "model": "hotmailuser/Phi4-Slerp4-14B",
    "score": 0.26
  },
  {
    "model": "hotmailuser/RombosBeagle-v2beta-MGS-32B",
    "score": 0.26
  },
  {
    "model": "jpacifico/Chocolatine-2-14B-Instruct-v2.0b2",
    "score": 0.26
  },
  {
    "model": "mergekit-community/mergekit-model_stock-azgztvm",
    "score": 0.26
  },
  {
    "model": "microsoft/Phi-3.5-MoE-instruct",
    "score": 0.26
  },
  {
    "model": "prithivMLmods/Elita-1",
    "score": 0.26
  },
  {
    "model": "prithivMLmods/Megatron-Opus-14B-Exp",
    "score": 0.26
  },
  {
    "model": "prithivMLmods/Phi-4-Math-IO",
    "score": 0.26
  },
  {
    "model": "rombodawg/Rombos-LLM-V2.5-Qwen-32b",
    "score": 0.26
  },
  {
    "model": "saishf/Neural-SOVLish-Devil-8B-L3",
    "score": 0.26
  },
  {
    "model": "sequelbox/Llama3.1-70B-PlumChat",
    "score": 0.26
  },
  {
    "model": "sometimesanotion/Lamarck-14B-v0.3",
    "score": 0.26
  },
  {
    "model": "sometimesanotion/Lamarck-14B-v0.7-Fusion",
    "score": 0.26
  },
  {
    "model": "sometimesanotion/LamarckInfusion-14B-v2",
    "score": 0.26
  },
  {
    "model": "sometimesanotion/Qwenvergence-14B-v12-Prose-DS",
    "score": 0.26
  },
  {
    "model": "sometimesanotion/Qwenvergence-14B-v12-Prose",
    "score": 0.26
  },
  {
    "model": "sometimesanotion/Qwenvergence-14B-v13-Prose-DS",
    "score": 0.26
  },
  {
    "model": "sometimesanotion/Qwenvergence-14B-v2-Prose",
    "score": 0.26
  },
  {
    "model": "sometimesanotion/Qwenvergence-14B-v3-Prose",
    "score": 0.26
  },
  {
    "model": "sometimesanotion/Qwenvergence-14B-v8",
    "score": 0.26
  },
  {
    "model": "sthenno/tempesthenno-nuslerp-001",
    "score": 0.26
  },
  {
    "model": "suayptalha/Lix-14B-v0.1",
    "score": 0.26
  },
  {
    "model": "unsloth/phi-4-unsloth-bnb-4bit",
    "score": 0.26
  },
  {
    "model": "ymcki/Llama-3.1-8B-GRPO-Instruct",
    "score": 0.26
  },
  {
    "model": "Aashraf995/QwenStock-14B",
    "score": 0.256
  },
  {
    "model": "Alsebay/Qwen2.5-7B-test-novelist",
    "score": 0.256
  },
  {
    "model": "CombinHorizon/Josiefied-abliteratedV4-Qwen2.5-14B-Inst-BaseMerge-TIES",
    "score": 0.256
  },
  {
    "model": "CultriX/Qwen2.5-14B-MergeStock",
    "score": 0.256
  },
  {
    "model": "CultriX/Qwestion-14B",
    "score": 0.256
  },
  {
    "model": "CultriX/SeQwence-14B-EvolMerge",
    "score": 0.256
  },
  {
    "model": "Dampfinchen/Llama-3.1-8B-Ultra-Instruct",
    "score": 0.256
  },
  {
    "model": "DeepAutoAI/ldm_soup_Llama-3.1-8B-Inst",
    "score": 0.256
  },
  {
    "model": "DeepAutoAI/ldm_soup_Llama-3.1-8B-Instruct-v0.0",
    "score": 0.256
  },
  {
    "model": "DeepAutoAI/ldm_soup_Llama-3.1-8B-Instruct-v0.1",
    "score": 0.256
  },
  {
    "model": "DeepMount00/Llama-3.1-Distilled",
    "score": 0.256
  },
  {
    "model": "DreadPoor/Alita99-8B-LINEAR",
    "score": 0.256
  },
  {
    "model": "DreadPoor/Asymmetric_Linearity-8B-Model_Stock",
    "score": 0.256
  },
  {
    "model": "DreadPoor/BaeZel_V2_ALT-8B-Model_Stock",
    "score": 0.256
  },
  {
    "model": "DreadPoor/BaeZel_V2-8B-Model_Stock",
    "score": 0.256
  },
  {
    "model": "DreadPoor/Blunt_Edge-8B-SLERP",
    "score": 0.256
  },
  {
    "model": "DreadPoor/Condensed_Milk-8B-Model_Stock",
    "score": 0.256
  },
  {
    "model": "DreadPoor/Decayed-8B-LINEAR",
    "score": 0.256
  },
  {
    "model": "DreadPoor/Incidental-8B-Model_Stock",
    "score": 0.256
  },
  {
    "model": "DreadPoor/LemonP-8B-Model_Stock",
    "score": 0.256
  },
  {
    "model": "DreadPoor/Something-8B-Model_Stock",
    "score": 0.256
  },
  {
    "model": "DreadPoor/Yafune-8B-Model_Stock",
    "score": 0.256
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_Dolermed_R1_V1.01",
    "score": 0.256
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_Typhoon_v1.03",
    "score": 0.256
  },
  {
    "model": "OpenBuddy/openbuddy-llama3-70b-v21.2-32k",
    "score": 0.256
  },
  {
    "model": "OpenBuddy/openbuddy-qwq-32b-v24.2-200k",
    "score": 0.256
  },
  {
    "model": "Qwen/QwQ-32B-Preview",
    "score": 0.256
  },
  {
    "model": "Sakalti/Saba2-14B-Preview",
    "score": 0.256
  },
  {
    "model": "Sakalti/ultiima-14B-v0.2",
    "score": 0.256
  },
  {
    "model": "Sakalti/ultiima-14B-v0.3",
    "score": 0.256
  },
  {
    "model": "T145/ZEUS-8B-V13",
    "score": 0.256
  },
  {
    "model": "T145/ZEUS-8B-V17",
    "score": 0.256
  },
  {
    "model": "T145/ZEUS-8B-V27",
    "score": 0.256
  },
  {
    "model": "T145/ZEUS-8B-V28",
    "score": 0.256
  },
  {
    "model": "T145/ZEUS-8B-V3",
    "score": 0.256
  },
  {
    "model": "YOYO-AI/Qwen2.5-14B-YOYO-0505",
    "score": 0.256
  },
  {
    "model": "YOYO-AI/Qwen2.5-14B-YOYO-0510-v2",
    "score": 0.256
  },
  {
    "model": "YOYO-AI/Qwen2.5-14B-YOYO-0805",
    "score": 0.256
  },
  {
    "model": "YOYO-AI/Qwen2.5-14B-YOYO-1005",
    "score": 0.256
  },
  {
    "model": "YOYO-AI/Qwen2.5-14B-YOYO-1010-v2",
    "score": 0.256
  },
  {
    "model": "YOYO-AI/Qwen2.5-14B-YOYO-SCE",
    "score": 0.256
  },
  {
    "model": "YOYO-AI/Qwen2.5-14B-YOYO-latest",
    "score": 0.256
  },
  {
    "model": "YOYO-AI/ZYH-LLM-Qwen2.5-14B",
    "score": 0.256
  },
  {
    "model": "allenai/Llama-3.1-Tulu-3-70B-DPO",
    "score": 0.256
  },
  {
    "model": "allknowingroger/Ph3merge-14B",
    "score": 0.256
  },
  {
    "model": "allknowingroger/Qwenslerp3-14B",
    "score": 0.256
  },
  {
    "model": "allknowingroger/Yislerp-34B",
    "score": 0.256
  },
  {
    "model": "alpindale/magnum-72b-v1",
    "score": 0.256
  },
  {
    "model": "anthracite-org/magnum-v1-72b",
    "score": 0.256
  },
  {
    "model": "bamec66557/MISCHIEVOUS-12B-Mix_0.5v",
    "score": 0.256
  },
  {
    "model": "cognitivecomputations/dolphin-2.9.3-Yi-1.5-34B-32k",
    "score": 0.256
  },
  {
    "model": "djuna/L3.1-Promissum_Mane-8B-Della-1.5-calc",
    "score": 0.256
  },
  {
    "model": "hotmailuser/QwenSlerp-14B",
    "score": 0.256
  },
  {
    "model": "hotmailuser/QwenStock1-14B",
    "score": 0.256
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-Franken-v38-8B",
    "score": 0.256
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-gamma-alt-8B",
    "score": 0.256
  },
  {
    "model": "jpacifico/Chocolatine-2-14B-Instruct-v2.0.3",
    "score": 0.256
  },
  {
    "model": "mistralai/Codestral-22B-v0.1",
    "score": 0.256
  },
  {
    "model": "moeru-ai/L3.1-Moe-2x8B-v0.2",
    "score": 0.256
  },
  {
    "model": "prithivMLmods/Coma-II-14B",
    "score": 0.256
  },
  {
    "model": "prithivMLmods/Dinobot-Opus-14B-Exp",
    "score": 0.256
  },
  {
    "model": "prithivMLmods/Galactic-Qwen-14B-Exp1",
    "score": 0.256
  },
  {
    "model": "prithivMLmods/Porpoise-Opus-14B-Exp",
    "score": 0.256
  },
  {
    "model": "redrix/patricide-12B-Unslop-Mell",
    "score": 0.256
  },
  {
    "model": "rombodawg/Rombos-LLM-V2.6-Qwen-14b",
    "score": 0.256
  },
  {
    "model": "sometimesanotion/Lamarck-14B-v0.1-experimental",
    "score": 0.256
  },
  {
    "model": "sometimesanotion/Lamarck-14B-v0.7-rc1",
    "score": 0.256
  },
  {
    "model": "sometimesanotion/LamarckInfusion-14B-v3",
    "score": 0.256
  },
  {
    "model": "sometimesanotion/Qwen-14B-ProseStock-v4",
    "score": 0.256
  },
  {
    "model": "sometimesanotion/Qwen2.5-14B-Vimarckoso-v3",
    "score": 0.256
  },
  {
    "model": "sometimesanotion/Qwen2.5-14B-Vimarckoso-v3-Prose01",
    "score": 0.256
  },
  {
    "model": "sometimesanotion/Qwen2.5-14B-Vimarckoso-v3-model_stock",
    "score": 0.256
  },
  {
    "model": "sometimesanotion/Qwentinuum-14B-v6-Prose",
    "score": 0.256
  },
  {
    "model": "sometimesanotion/Qwentinuum-14B-v9",
    "score": 0.256
  },
  {
    "model": "sometimesanotion/Qwenvergence-14B-v3-Reason",
    "score": 0.256
  },
  {
    "model": "sometimesanotion/Qwenvergence-14B-v3-Reason",
    "score": 0.256
  },
  {
    "model": "sometimesanotion/lamarck-14b-prose-model_stock",
    "score": 0.256
  },
  {
    "model": "sometimesanotion/lamarck-14b-reason-model_stock",
    "score": 0.256
  },
  {
    "model": "tensopolis/qwen2.5-14b-tensopolis-v1",
    "score": 0.256
  },
  {
    "model": "unsloth/phi-4-bnb-4bit",
    "score": 0.256
  },
  {
    "model": "152334H/miqu-1-70b-sf",
    "score": 0.252
  },
  {
    "model": "1024m/PHI-4-Hindi",
    "score": 0.252
  },
  {
    "model": "Aashraf995/Qwen-Evo-7B",
    "score": 0.252
  },
  {
    "model": "BoltMonkey/DreadMix",
    "score": 0.252
  },
  {
    "model": "CombinHorizon/zetasepic-abliteratedV2-Qwen2.5-32B-Inst-BaseMerge-TIES",
    "score": 0.252
  },
  {
    "model": "CultriX/Qwen2.5-14B-HyperMarck-dl",
    "score": 0.252
  },
  {
    "model": "CultriX/SeQwence-14B-EvolMergev1",
    "score": 0.252
  },
  {
    "model": "CultriX/SeQwence-14Bv1",
    "score": 0.252
  },
  {
    "model": "Darkknight535/OpenCrystal-12B-L3",
    "score": 0.252
  },
  {
    "model": "DreadPoor/Aspire_V2-8B-Model_Stock",
    "score": 0.252
  },
  {
    "model": "DreadPoor/Aurora_faustus-8B-LORABLATED_ALT",
    "score": 0.252
  },
  {
    "model": "DreadPoor/Cadence-8B-LINEAR",
    "score": 0.252
  },
  {
    "model": "DreadPoor/Derivative-8B-Model_Stock",
    "score": 0.252
  },
  {
    "model": "DreadPoor/Eunoia_Vespera-8B-LINEAR",
    "score": 0.252
  },
  {
    "model": "DreadPoor/L3.1-BaeZel-8B-Della",
    "score": 0.252
  },
  {
    "model": "DreadPoor/Mercury_In_Retrograde-8b-Model-Stock",
    "score": 0.252
  },
  {
    "model": "DreadPoor/Minthy_V2-8B-Model_Stock",
    "score": 0.252
  },
  {
    "model": "DreadPoor/Oh_Boy-8B-LINEAR",
    "score": 0.252
  },
  {
    "model": "DreadPoor/Sun-8B-Model_Stock",
    "score": 0.252
  },
  {
    "model": "DreadPoor/UNTESTED-VENN_1.2-8B-Model_Stock",
    "score": 0.252
  },
  {
    "model": "DreadPoor/hakuchido-8B-MODEL_STOCK",
    "score": 0.252
  },
  {
    "model": "DreadPoor/ichor_1.1-8B-Model_Stock",
    "score": 0.252
  },
  {
    "model": "DreadPoor/inexpertus_1.2-8B-LINEAR",
    "score": 0.252
  },
  {
    "model": "GoToCompany/gemma2-9b-cpt-sahabatai-v1-instruct",
    "score": 0.252
  },
  {
    "model": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v9-stock",
    "score": 0.252
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_Stormeder_v1.04",
    "score": 0.252
  },
  {
    "model": "NikolaSigmoid/phi-4-1steps",
    "score": 0.252
  },
  {
    "model": "NyxKrage/Microsoft_Phi-4",
    "score": 0.252
  },
  {
    "model": "Quazim0t0/Mononoke-14B-sce",
    "score": 0.252
  },
  {
    "model": "Qwen/Qwen2.5-32B-Instruct",
    "score": 0.252
  },
  {
    "model": "Sakalti/ultiima-14B",
    "score": 0.252
  },
  {
    "model": "Syed-Hasan-8503/Phi-3-mini-4K-instruct-cpo-simpo",
    "score": 0.252
  },
  {
    "model": "T145/ZEUS-8B-V10",
    "score": 0.252
  },
  {
    "model": "T145/ZEUS-8B-V18",
    "score": 0.252
  },
  {
    "model": "T145/ZEUS-8B-V26",
    "score": 0.252
  },
  {
    "model": "TheTsar1209/qwen-carpmuscle-v0.1",
    "score": 0.252
  },
  {
    "model": "Triangle104/Herodotos-14B",
    "score": 0.252
  },
  {
    "model": "Triangle104/Phi-4-AbliteratedRP",
    "score": 0.252
  },
  {
    "model": "Triangle104/Rocinante-Prism_V2.0",
    "score": 0.252
  },
  {
    "model": "VAGOsolutions/Llama-3.1-SauerkrautLM-8b-Instruct",
    "score": 0.252
  },
  {
    "model": "VAGOsolutions/SauerkrautLM-Phi-3-medium",
    "score": 0.252
  },
  {
    "model": "YOYO-AI/Qwen2.5-14B-YOYO-V4",
    "score": 0.252
  },
  {
    "model": "allknowingroger/Qwen2.5-slerp-14B",
    "score": 0.252
  },
  {
    "model": "allknowingroger/QwenSlerp4-14B",
    "score": 0.252
  },
  {
    "model": "allura-org/TQ2.5-14B-Neon-v1",
    "score": 0.252
  },
  {
    "model": "arcee-ai/Llama-3.1-SuperNova-Lite",
    "score": 0.252
  },
  {
    "model": "bamec66557/VICIOUS_MESH-12B",
    "score": 0.252
  },
  {
    "model": "cognitivecomputations/dolphin-2.9.2-Phi-3-Medium",
    "score": 0.252
  },
  {
    "model": "cstr/llama3.1-8b-spaetzle-v90",
    "score": 0.252
  },
  {
    "model": "djuna/L3.1-Purosani-2-8B",
    "score": 0.252
  },
  {
    "model": "hotmailuser/QwenSlerp2-14B",
    "score": 0.252
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-PRP-v25-8B",
    "score": 0.252
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-immersive-sof-v44-8B",
    "score": 0.252
  },
  {
    "model": "jaspionjader/f-1-8b",
    "score": 0.252
  },
  {
    "model": "jaspionjader/test-17",
    "score": 0.252
  },
  {
    "model": "marcuscedricridia/Cheng-2-v1.1",
    "score": 0.252
  },
  {
    "model": "mergekit-community/VirtuosoSmall-InstructModelStock",
    "score": 0.252
  },
  {
    "model": "mergekit-community/mergekit-della-zgowfmf",
    "score": 0.252
  },
  {
    "model": "mergekit-community/mergekit-ties-ykqemwr",
    "score": 0.252
  },
  {
    "model": "nbeerbower/Dumpling-Qwen2.5-14B",
    "score": 0.252
  },
  {
    "model": "nbeerbower/mistral-nemo-gutenberg-12B",
    "score": 0.252
  },
  {
    "model": "prithivMLmods/Condor-Opus-14B-Exp",
    "score": 0.252
  },
  {
    "model": "prithivMLmods/Equuleus-Opus-14B-Exp",
    "score": 0.252
  },
  {
    "model": "prithivMLmods/Pegasus-Opus-14B-Exp",
    "score": 0.252
  },
  {
    "model": "prithivMLmods/Phi-4-QwQ",
    "score": 0.252
  },
  {
    "model": "prithivMLmods/Sombrero-Opus-14B-Sm2",
    "score": 0.252
  },
  {
    "model": "prithivMLmods/Sombrero-Opus-14B-Sm4",
    "score": 0.252
  },
  {
    "model": "prithivMLmods/Viper-Coder-v1.1",
    "score": 0.252
  },
  {
    "model": "prithivMLmods/Viper-Coder-v1.6-r999",
    "score": 0.252
  },
  {
    "model": "qingy2024/Fusion4-14B-Instruct",
    "score": 0.252
  },
  {
    "model": "rombodawg/Rombos-LLM-V2.5-Qwen-14b",
    "score": 0.252
  },
  {
    "model": "sometimesanotion/Lamarck-14B-v0.6",
    "score": 0.252
  },
  {
    "model": "sometimesanotion/Qwentinuum-14B-v2",
    "score": 0.252
  },
  {
    "model": "sometimesanotion/Qwentinuum-14B-v7",
    "score": 0.252
  },
  {
    "model": "sthenno/tempesthenno-kto-0205-ckpt80",
    "score": 0.252
  },
  {
    "model": "sthenno/tempestissimo-14b-0309",
    "score": 0.252
  },
  {
    "model": "synergetic/FrankenQwen2.5-14B",
    "score": 0.252
  },
  {
    "model": "tanliboy/lambda-qwen2.5-14b-dpo-test",
    "score": 0.252
  },
  {
    "model": "tensopolis/lamarckvergence-14b-tensopolis-v1",
    "score": 0.252
  },
  {
    "model": "tomasmcm/sky-t1-coder-32b-flash",
    "score": 0.252
  },
  {
    "model": "01-ai/Yi-1.5-34B-Chat",
    "score": 0.248
  },
  {
    "model": "BlackBeenie/llama-3-luminous-merged",
    "score": 0.248
  },
  {
    "model": "CohereForAI/c4ai-command-r-plus",
    "score": 0.248
  },
  {
    "model": "Cran-May/merge_model_20250308_2",
    "score": 0.248
  },
  {
    "model": "CultriX/Qwen2.5-14B-MegaMerge-pt2",
    "score": 0.248
  },
  {
    "model": "CultriX/Qwen2.5-14B-Ultimav2",
    "score": 0.248
  },
  {
    "model": "CultriX/SeQwence-14B",
    "score": 0.248
  },
  {
    "model": "Daemontatox/Phi-4-COT",
    "score": 0.248
  },
  {
    "model": "DreadPoor/Aurora_faustus-8B-LORABLATED",
    "score": 0.248
  },
  {
    "model": "DreadPoor/Fu_sion_HA-8B-SLERP",
    "score": 0.248
  },
  {
    "model": "DreadPoor/Lava_Lamp-8B-SLERP",
    "score": 0.248
  },
  {
    "model": "DreadPoor/Sweetened_Condensed_Milk-8B-Model_Stock",
    "score": 0.248
  },
  {
    "model": "DreadPoor/TEST08-ignore",
    "score": 0.248
  },
  {
    "model": "DreadPoor/Wannabe-8B-Model_Stock",
    "score": 0.248
  },
  {
    "model": "DreadPoor/inexpertus_1.1-8B-LINEAR",
    "score": 0.248
  },
  {
    "model": "EpistemeAI/DeepPhi-3.5-mini-instruct",
    "score": 0.248
  },
  {
    "model": "Etherll/SuperHermes",
    "score": 0.248
  },
  {
    "model": "FINGU-AI/Chocolatine-Fusion-14B",
    "score": 0.248
  },
  {
    "model": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v3",
    "score": 0.248
  },
  {
    "model": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v7",
    "score": 0.248
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_Dolerstormed_V1.04",
    "score": 0.248
  },
  {
    "model": "OpenBuddy/openbuddy-yi1.5-34b-v21.3-32k",
    "score": 0.248
  },
  {
    "model": "Orenguteng/Llama-3.1-8B-Lexi-Uncensored-V2",
    "score": 0.248
  },
  {
    "model": "Quazim0t0/Alien-CoT-14B-sce",
    "score": 0.248
  },
  {
    "model": "Quazim0t0/GZA-14B-sce",
    "score": 0.248
  },
  {
    "model": "Qwen/Qwen2.5-14B-Instruct",
    "score": 0.248
  },
  {
    "model": "T145/KRONOS-8B-V8",
    "score": 0.248
  },
  {
    "model": "T145/ZEUS-8B-V12",
    "score": 0.248
  },
  {
    "model": "T145/ZEUS-8B-V19",
    "score": 0.248
  },
  {
    "model": "T145/ZEUS-8B-V20",
    "score": 0.248
  },
  {
    "model": "T145/ZEUS-8B-V22",
    "score": 0.248
  },
  {
    "model": "T145/ZEUS-8B-V2L2",
    "score": 0.248
  },
  {
    "model": "T145/ZEUS-8B-V29",
    "score": 0.248
  },
  {
    "model": "T145/ZEUS-8B-V4",
    "score": 0.248
  },
  {
    "model": "Triangle104/Q2.5-14B-Instruct-1M-Harmony",
    "score": 0.248
  },
  {
    "model": "YOYO-AI/Qwen2.5-14B-1M-YOYO-V3",
    "score": 0.248
  },
  {
    "model": "YOYO-AI/Qwen2.5-14B-YOYO-1010",
    "score": 0.248
  },
  {
    "model": "YOYO-AI/Qwen2.5-14B-YOYO-1010",
    "score": 0.248
  },
  {
    "model": "abacusai/Smaug-72B-v0.1",
    "score": 0.248
  },
  {
    "model": "abacusai/Smaug-Qwen2-72B-Instruct",
    "score": 0.248
  },
  {
    "model": "allknowingroger/Ph3task2-14B",
    "score": 0.248
  },
  {
    "model": "allknowingroger/QwenSlerp6-14B",
    "score": 0.248
  },
  {
    "model": "allknowingroger/Yislerp2-34B",
    "score": 0.248
  },
  {
    "model": "anthracite-org/magnum-v4-22b",
    "score": 0.248
  },
  {
    "model": "arcee-ai/Virtuoso-Lite",
    "score": 0.248
  },
  {
    "model": "braindao/DeepSeek-R1-Distill-Qwen-14B-ABUB-ST",
    "score": 0.248
  },
  {
    "model": "braindao/Qwen2.5-14B-Instruct",
    "score": 0.248
  },
  {
    "model": "bunnycore/Phi-Seek-4-Sce-V1",
    "score": 0.248
  },
  {
    "model": "crestf411/MN-Slush",
    "score": 0.248
  },
  {
    "model": "ehristoforu/Gemma2-9B-it-psy10k-mental_health",
    "score": 0.248
  },
  {
    "model": "grimjim/llama-3-Nephilim-v2-8B",
    "score": 0.248
  },
  {
    "model": "hotmailuser/Mistral-modelstock-24B",
    "score": 0.248
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-PRP-v34-8B",
    "score": 0.248
  },
  {
    "model": "jaspionjader/TSN-Kosmos-EVAA-8B",
    "score": 0.248
  },
  {
    "model": "jaspionjader/TSN-Kosmos-EVAA-v2-8B",
    "score": 0.248
  },
  {
    "model": "jaspionjader/fr-3-8b",
    "score": 0.248
  },
  {
    "model": "jpacifico/Chocolatine-2-14B-Instruct-v2.0b3",
    "score": 0.248
  },
  {
    "model": "marcuscedricridia/Cheng-2",
    "score": 0.248
  },
  {
    "model": "neopolita/jessi-v0.2-falcon3-10b-instruct",
    "score": 0.248
  },
  {
    "model": "paloalma/ECE-TW3-JRGL-V5",
    "score": 0.248
  },
  {
    "model": "prithivMLmods/Phi-4-Super",
    "score": 0.248
  },
  {
    "model": "prithivMLmods/Phi4-Super",
    "score": 0.248
  },
  {
    "model": "prithivMLmods/Primal-Opus-14B-Optimus-v2",
    "score": 0.248
  },
  {
    "model": "prithivMLmods/Sombrero-Opus-14B-Elite5",
    "score": 0.248
  },
  {
    "model": "prithivMLmods/Sombrero-Opus-14B-Sm1",
    "score": 0.248
  },
  {
    "model": "prithivMLmods/Sombrero-Opus-14B-Sm5",
    "score": 0.248
  },
  {
    "model": "qingy2024/Eyas-17B-Instruct",
    "score": 0.248
  },
  {
    "model": "sometimesanotion/ChocoTrio-14B-v1",
    "score": 0.248
  },
  {
    "model": "sometimesanotion/Lamarck-14B-v0.4-Qwenvergence",
    "score": 0.248
  },
  {
    "model": "sometimesanotion/LamarckInfusion-14B-v2-hi",
    "score": 0.248
  },
  {
    "model": "sometimesanotion/Qwen2.5-14B-Vimarckoso-v2",
    "score": 0.248
  },
  {
    "model": "sometimesanotion/Qwentessential-14B-v1",
    "score": 0.248
  },
  {
    "model": "sometimesanotion/Qwentinuum-14B-v3",
    "score": 0.248
  },
  {
    "model": "sometimesanotion/Qwentinuum-14B-v6",
    "score": 0.248
  },
  {
    "model": "sometimesanotion/Qwenvergence-14B-v10",
    "score": 0.248
  },
  {
    "model": "sometimesanotion/Qwenvergence-14B-v6-Prose",
    "score": 0.248
  },
  {
    "model": "sometimesanotion/Qwenvergence-14B-v6-Prose-model_stock",
    "score": 0.248
  },
  {
    "model": "speakleash/Bielik-11B-v2.3-Instruct",
    "score": 0.248
  },
  {
    "model": "sthenno/tempesthenno-ppo-ckpt40",
    "score": 0.248
  },
  {
    "model": "sthenno-com/miscii-14b-1028",
    "score": 0.248
  },
  {
    "model": "tensopolis/virtuoso-lite-tensopolis-v1",
    "score": 0.248
  },
  {
    "model": "tensopolis/virtuoso-lite-tensopolis-v2",
    "score": 0.248
  },
  {
    "model": "tensopolis/virtuoso-small-tensopolis-v2",
    "score": 0.248
  },
  {
    "model": "CausalLM/34b-beta",
    "score": 0.244
  },
  {
    "model": "CultriX/Qwen2.5-14B-Hyperionv5",
    "score": 0.244
  },
  {
    "model": "Daemontatox/CogitoZ14",
    "score": 0.244
  },
  {
    "model": "DoppelReflEx/MN-12B-Kakigori",
    "score": 0.244
  },
  {
    "model": "DreadPoor/Aspire_V2.1-8B-Model_Stock",
    "score": 0.244
  },
  {
    "model": "DreadPoor/BaeZel-8B-LINEAR",
    "score": 0.244
  },
  {
    "model": "DreadPoor/BaeZel-8B-Model_Stock",
    "score": 0.244
  },
  {
    "model": "DreadPoor/Derivative_V2-8B-Model_Stock",
    "score": 0.244
  },
  {
    "model": "DreadPoor/H_the_eighth-8B-LINEAR",
    "score": 0.244
  },
  {
    "model": "EpistemeAI2/Fireball-Phi-3-medium-4k-inst-Philos",
    "score": 0.244
  },
  {
    "model": "Isaak-Carter/JOSIEv4o-8b-stage1-v4",
    "score": 0.244
  },
  {
    "model": "Isaak-Carter/JOSIEv4o-8b-stage1-v4",
    "score": 0.244
  },
  {
    "model": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v4",
    "score": 0.244
  },
  {
    "model": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v9",
    "score": 0.244
  },
  {
    "model": "Naveenpoliasetty/llama3-8B-V2",
    "score": 0.244
  },
  {
    "model": "Nitral-AI/Hathor_Tahsin-L3-8B-v0.85",
    "score": 0.244
  },
  {
    "model": "Pinkstack/SuperThoughts-CoT-14B-16k-o1-QwQ",
    "score": 0.244
  },
  {
    "model": "Quazim0t0/CoT_Phi",
    "score": 0.244
  },
  {
    "model": "Quazim0t0/InspectorDeck-14B-sce",
    "score": 0.244
  },
  {
    "model": "Quazim0t0/Phi4.Turn.R1Distill_v1.5.1-Tensors",
    "score": 0.244
  },
  {
    "model": "Quazim0t0/Sumatra-20b",
    "score": 0.244
  },
  {
    "model": "Quazim0t0/graphite-14b-sce",
    "score": 0.244
  },
  {
    "model": "Qwen/Qwen2.5-72B",
    "score": 0.244
  },
  {
    "model": "Sakalti/Euphrates-14B",
    "score": 0.244
  },
  {
    "model": "Saxo/Linkbricks-Horizon-AI-Avengers-V6-32B",
    "score": 0.244
  },
  {
    "model": "T145/ZEUS-8B-V6",
    "score": 0.244
  },
  {
    "model": "Triangle104/Minerva-14b",
    "score": 0.244
  },
  {
    "model": "Triangle104/Minerva-14b-V0.1",
    "score": 0.244
  },
  {
    "model": "Triangle104/Phi4-RP-o1-Ablit",
    "score": 0.244
  },
  {
    "model": "Triangle104/Phi4-RP-o1",
    "score": 0.244
  },
  {
    "model": "YOYO-AI/Qwen2.5-14B-it-restore",
    "score": 0.244
  },
  {
    "model": "agentlans/Llama3.1-Daredevilish-Instruct",
    "score": 0.244
  },
  {
    "model": "allknowingroger/Chocolatine-24B",
    "score": 0.244
  },
  {
    "model": "allknowingroger/Ph3task1-14B",
    "score": 0.244
  },
  {
    "model": "allknowingroger/QwenStock2-14B",
    "score": 0.244
  },
  {
    "model": "allknowingroger/QwenStock3-14B",
    "score": 0.244
  },
  {
    "model": "anthracite-org/magnum-v4-27b",
    "score": 0.244
  },
  {
    "model": "bamec66557/MISCHIEVOUS-12B-Mix_0.3v",
    "score": 0.244
  },
  {
    "model": "bamec66557/MISCHIEVOUS-12B-Mix_III_IV_V",
    "score": 0.244
  },
  {
    "model": "bamec66557/VICIOUS_MESH-12B-NEMO",
    "score": 0.244
  },
  {
    "model": "bamec66557/VICIOUS_MESH-12B_Razor",
    "score": 0.244
  },
  {
    "model": "ehristoforu/RQwen-v0.1",
    "score": 0.244
  },
  {
    "model": "grimjim/Magnolia-v3-12B",
    "score": 0.244
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-PRP-v28-8B",
    "score": 0.244
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-PRP-v31-8B",
    "score": 0.244
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-PRP-v33-8B",
    "score": 0.244
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-gamma-v14-8B",
    "score": 0.244
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-gamma-v15-8B",
    "score": 0.244
  },
  {
    "model": "jaspionjader/bbb-5",
    "score": 0.244
  },
  {
    "model": "jaspionjader/bbb-7",
    "score": 0.244
  },
  {
    "model": "jaspionjader/bh-60",
    "score": 0.244
  },
  {
    "model": "jaspionjader/fct-14-8b",
    "score": 0.244
  },
  {
    "model": "jaspionjader/fr-1-8b",
    "score": 0.244
  },
  {
    "model": "jaspionjader/kstc-1-8b",
    "score": 0.244
  },
  {
    "model": "jaspionjader/slu-mix-1",
    "score": 0.244
  },
  {
    "model": "jaspionjader/test-18",
    "score": 0.244
  },
  {
    "model": "migtissera/Tess-v2.5-Phi-3-medium-128k-14B",
    "score": 0.244
  },
  {
    "model": "migtissera/Trinity-2-Codestral-22B",
    "score": 0.244
  },
  {
    "model": "mlabonne/BigQwen2.5-Echo-47B-Instruct",
    "score": 0.244
  },
  {
    "model": "nbeerbower/llama-3-gutenberg-8B",
    "score": 0.244
  },
  {
    "model": "nbeerbower/mistral-nemo-gutades-12B",
    "score": 0.244
  },
  {
    "model": "neopolita/jessi-v0.1-qwen2.5-7b-instruct",
    "score": 0.244
  },
  {
    "model": "prithivMLmods/Gaea-Opus-14B-Exp",
    "score": 0.244
  },
  {
    "model": "prithivMLmods/Llama-Deepsync-1B",
    "score": 0.244
  },
  {
    "model": "prithivMLmods/Messier-Opus-14B-Elite7",
    "score": 0.244
  },
  {
    "model": "prithivMLmods/Phi-4-Empathetic",
    "score": 0.244
  },
  {
    "model": "prithivMLmods/Triangulum-v2-10B",
    "score": 0.244
  },
  {
    "model": "prithivMLmods/Volans-Opus-14B-Exp",
    "score": 0.244
  },
  {
    "model": "sometimesanotion/Lamarck-14B-v0.7-rc4",
    "score": 0.244
  },
  {
    "model": "sometimesanotion/Qwentinuum-14B-v1",
    "score": 0.244
  },
  {
    "model": "sometimesanotion/Qwentinuum-14B-v5",
    "score": 0.244
  },
  {
    "model": "sometimesanotion/Qwentinuum-14B-v8",
    "score": 0.244
  },
  {
    "model": "sometimesanotion/Qwenvergence-14B-v9",
    "score": 0.244
  },
  {
    "model": "sthenno/tempesthenno-sft-0314-stage1-ckpt50",
    "score": 0.244
  },
  {
    "model": "suayptalha/Lamarckvergence-14B",
    "score": 0.244
  },
  {
    "model": "theprint/CleverBoi-7B-v2",
    "score": 0.244
  },
  {
    "model": "yuchenxie/ArlowGPT-8B",
    "score": 0.244
  },
  {
    "model": "CohereForAI/c4ai-command-r-plus-08-2024",
    "score": 0.24
  },
  {
    "model": "CultriX/Qwen2.5-14B-Emergedv3",
    "score": 0.24
  },
  {
    "model": "CultriX/SeQwence-14B-v5",
    "score": 0.24
  },
  {
    "model": "DeepMount00/Llama-3.1-8b-Ita",
    "score": 0.24
  },
  {
    "model": "DeepMount00/Llama-3.1-8b-Ita",
    "score": 0.24
  },
  {
    "model": "Delta-Vector/Control-8B",
    "score": 0.24
  },
  {
    "model": "DoppelReflEx/MN-12B-LilithFrame-Experiment-4",
    "score": 0.24
  },
  {
    "model": "DoppelReflEx/MiniusLight-24B",
    "score": 0.24
  },
  {
    "model": "DreadPoor/Aspire_V4-8B-Model_Stock",
    "score": 0.24
  },
  {
    "model": "DreadPoor/Damasteel-8B-LINEAR",
    "score": 0.24
  },
  {
    "model": "DreadPoor/Howdy-8B-LINEAR",
    "score": 0.24
  },
  {
    "model": "DreadPoor/OrangeJ-8B-Model_Stock",
    "score": 0.24
  },
  {
    "model": "DreadPoor/Promissum_Mane-8B-LINEAR",
    "score": 0.24
  },
  {
    "model": "DreadPoor/Rusted_Platinum-8B-LINEAR",
    "score": 0.24
  },
  {
    "model": "DreadPoor/Summer_Rain-8B-SCE",
    "score": 0.24
  },
  {
    "model": "DreadPoor/Summer_Rain-8B-TIES",
    "score": 0.24
  },
  {
    "model": "FINGU-AI/Phi-4-RRStock",
    "score": 0.24
  },
  {
    "model": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v6-cpt",
    "score": 0.24
  },
  {
    "model": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v8",
    "score": 0.24
  },
  {
    "model": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v8.5",
    "score": 0.24
  },
  {
    "model": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v8.8",
    "score": 0.24
  },
  {
    "model": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v9.1",
    "score": 0.24
  },
  {
    "model": "NLPark/B-and-W_Flycatcher-3AD1E",
    "score": 0.24
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_Hermedash_R1_V1.04",
    "score": 0.24
  },
  {
    "model": "NikolaSigmoid/phi-4-300steps",
    "score": 0.24
  },
  {
    "model": "Quazim0t0/Chromatic-8b-sce",
    "score": 0.24
  },
  {
    "model": "Quazim0t0/Origami-14B-sce",
    "score": 0.24
  },
  {
    "model": "Qwen/Qwen2.5-14B",
    "score": 0.24
  },
  {
    "model": "Sakalti/Saka-14B",
    "score": 0.24
  },
  {
    "model": "Saxo/Linkbricks-Horizon-AI-Avengers-V3-32B",
    "score": 0.24
  },
  {
    "model": "T145/KRONOS-8B-V4",
    "score": 0.24
  },
  {
    "model": "T145/Llama-3.1-8B-Instruct-Zeus",
    "score": 0.24
  },
  {
    "model": "T145/Meta-Llama-3.1-8B-Instruct-TIES",
    "score": 0.24
  },
  {
    "model": "T145/ZEUS-8B-V13-abliterated",
    "score": 0.24
  },
  {
    "model": "T145/ZEUS-8B-V2",
    "score": 0.24
  },
  {
    "model": "T145/ZEUS-8B-V2-abliterated",
    "score": 0.24
  },
  {
    "model": "T145/ZEUS-8B-V30",
    "score": 0.24
  },
  {
    "model": "Triangle104/Chatty-Harry_V2.0",
    "score": 0.24
  },
  {
    "model": "Triangle104/Rocinante-Prism_V2.1",
    "score": 0.24
  },
  {
    "model": "Youlln/1PARAMMYL-8B-ModelStock",
    "score": 0.24
  },
  {
    "model": "allknowingroger/Ph3della5-14B",
    "score": 0.24
  },
  {
    "model": "allknowingroger/QwenStock1-14B",
    "score": 0.24
  },
  {
    "model": "allknowingroger/Yibuddy-35B",
    "score": 0.24
  },
  {
    "model": "allknowingroger/llama3AnFeng-40B",
    "score": 0.24
  },
  {
    "model": "anthracite-org/magnum-v3-34b",
    "score": 0.24
  },
  {
    "model": "bamec66557/MISCHIEVOUS-12B-Mix_0.1v",
    "score": 0.24
  },
  {
    "model": "bamec66557/VICIOUS_MESH-12B-0.X.ver",
    "score": 0.24
  },
  {
    "model": "djuna/L3.1-ForStHS",
    "score": 0.24
  },
  {
    "model": "ehristoforu/RQwen-v0.2",
    "score": 0.24
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-gamma-light-8B",
    "score": 0.24
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-gamma-v13-8B",
    "score": 0.24
  },
  {
    "model": "jaspionjader/bh-49",
    "score": 0.24
  },
  {
    "model": "jaspionjader/f-8-8b",
    "score": 0.24
  },
  {
    "model": "jaspionjader/knf-2-8b",
    "score": 0.24
  },
  {
    "model": "jaspionjader/slu-36",
    "score": 0.24
  },
  {
    "model": "jaspionjader/sof-6",
    "score": 0.24
  },
  {
    "model": "jaspionjader/test-10",
    "score": 0.24
  },
  {
    "model": "jaspionjader/test-16",
    "score": 0.24
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.5-gamma-0.01",
    "score": 0.24
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_linear",
    "score": 0.24
  },
  {
    "model": "maldv/Lytta2.5-32B-Instruct",
    "score": 0.24
  },
  {
    "model": "mattshumer/ref_70_e3",
    "score": 0.24
  },
  {
    "model": "migtissera/Tess-v2.5.2-Qwen2-72B",
    "score": 0.24
  },
  {
    "model": "nbeerbower/mistral-nemo-gutenberg2-12B-test",
    "score": 0.24
  },
  {
    "model": "paloalma/TW3-JRGL-v2",
    "score": 0.24
  },
  {
    "model": "pankajmathur/orca_mini_v6_8b_dpo",
    "score": 0.24
  },
  {
    "model": "princeton-nlp/Llama-3-Instruct-8B-RDPO-v0.2",
    "score": 0.24
  },
  {
    "model": "prithivMLmods/Calcium-Opus-14B-Elite4",
    "score": 0.24
  },
  {
    "model": "prithivMLmods/Deepthink-Reasoning-14B",
    "score": 0.24
  },
  {
    "model": "senseable/WestLake-7B-v2",
    "score": 0.24
  },
  {
    "model": "sometimesanotion/KytheraMix-7B-v0.2",
    "score": 0.24
  },
  {
    "model": "sometimesanotion/Lamarck-14B-v0.6-model_stock",
    "score": 0.24
  },
  {
    "model": "sometimesanotion/Qwenvergence-14B-v0.6-004-model_stock",
    "score": 0.24
  },
  {
    "model": "sthenno-com/miscii-14b-1225",
    "score": 0.24
  },
  {
    "model": "vicgalle/Configurable-Llama-3.1-8B-Instruct",
    "score": 0.24
  },
  {
    "model": "vonjack/Phi-3-mini-4k-instruct-LLaMAfied",
    "score": 0.24
  },
  {
    "model": "zake7749/gemma-2-9b-it-chinese-kyara",
    "score": 0.24
  },
  {
    "model": "Azure99/blossom-v5.1-34b",
    "score": 0.236
  },
  {
    "model": "Cran-May/SCE-2-24B",
    "score": 0.236
  },
  {
    "model": "CultriX/Qwen2.5-14B-Emerged",
    "score": 0.236
  },
  {
    "model": "CultriX/Qwen2.5-14B-FinalMerge",
    "score": 0.236
  },
  {
    "model": "Daemontatox/DocumentCogito",
    "score": 0.236
  },
  {
    "model": "Daemontatox/DocumentCogito",
    "score": 0.236
  },
  {
    "model": "Daemontatox/PathFinderAi3.0",
    "score": 0.236
  },
  {
    "model": "Daemontatox/Sphinx2.0",
    "score": 0.236
  },
  {
    "model": "DavidAU/Qwen2.5-MOE-6x1.5B-DeepSeek-Reasoning-e32",
    "score": 0.236
  },
  {
    "model": "DeepAutoAI/Explore_Llama-3.1-8B-Inst",
    "score": 0.236
  },
  {
    "model": "DreadPoor/Autumn_Dawn-8B-LINEAR",
    "score": 0.236
  },
  {
    "model": "DreadPoor/Caelid-8B-Model_Stock",
    "score": 0.236
  },
  {
    "model": "DreadPoor/Sellen-8B-model_stock",
    "score": 0.236
  },
  {
    "model": "DreadPoor/TEST03-ignore",
    "score": 0.236
  },
  {
    "model": "DreadPoor/Trinas_Nectar-8B-model_stock",
    "score": 0.236
  },
  {
    "model": "DreadPoor/Winter_Night-8B-Model_Stock",
    "score": 0.236
  },
  {
    "model": "DreadPoor/inexpertus-8B-Model_Stock",
    "score": 0.236
  },
  {
    "model": "Gryphe/Pantheon-RP-Pure-1.6.2-22b-Small",
    "score": 0.236
  },
  {
    "model": "Krystalan/DRT-o1-14B",
    "score": 0.236
  },
  {
    "model": "Kukedlc/NeuralLLaMa-3-8b-DT-v0.1",
    "score": 0.236
  },
  {
    "model": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v8.6",
    "score": 0.236
  },
  {
    "model": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v8.7",
    "score": 0.236
  },
  {
    "model": "MaziyarPanahi/calme-2.1-llama3.1-70b",
    "score": 0.236
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_DodoWild_v2.02",
    "score": 0.236
  },
  {
    "model": "Orion-zhen/phi-4-abliterated",
    "score": 0.236
  },
  {
    "model": "PJMixers-Dev/LLaMa-3.1-Instruct-Interleaved-Zeroed-13B",
    "score": 0.236
  },
  {
    "model": "PJMixers-Dev/LLaMa-3.1-RomboTiesTest2-8B",
    "score": 0.236
  },
  {
    "model": "PJMixers-Dev/LLaMa-3.1-RomboTiesTest-8B",
    "score": 0.236
  },
  {
    "model": "Sakalti/Phi3.5-Comets-3.8B",
    "score": 0.236
  },
  {
    "model": "SicariusSicariiStuff/2B_or_not_2B",
    "score": 0.236
  },
  {
    "model": "SicariusSicariiStuff/Qwen2.5-14B_Uncencored",
    "score": 0.236
  },
  {
    "model": "SicariusSicariiStuff/Qwen2.5-14B_Uncensored",
    "score": 0.236
  },
  {
    "model": "Supichi/BBA99",
    "score": 0.236
  },
  {
    "model": "Supichi/BBAI_275_Tsunami_gZ",
    "score": 0.236
  },
  {
    "model": "T145/KRONOS-8B-V1-P1",
    "score": 0.236
  },
  {
    "model": "TheDrummer/Cydonia-22B-v1.2",
    "score": 0.236
  },
  {
    "model": "Triangle104/Chatty-Harry_V3.0",
    "score": 0.236
  },
  {
    "model": "Xclbr7/Arcanum-12b",
    "score": 0.236
  },
  {
    "model": "YOYO-AI/Qwen2.5-14B-YOYO-V4-p1",
    "score": 0.236
  },
  {
    "model": "YOYO-AI/Qwen2.5-14B-YOYO-V4-p2",
    "score": 0.236
  },
  {
    "model": "allura-org/MS-Meadowlark-22B",
    "score": 0.236
  },
  {
    "model": "bamec66557/MISCHIEVOUS-12B",
    "score": 0.236
  },
  {
    "model": "bamec66557/MISCHIEVOUS-12B-Mix_0.6v",
    "score": 0.236
  },
  {
    "model": "cognitivecomputations/dolphin-2.9.3-mistral-7B-32k",
    "score": 0.236
  },
  {
    "model": "fhai50032/Unaligned-Thinker-PHI-4",
    "score": 0.236
  },
  {
    "model": "google/gemma-2-27b",
    "score": 0.236
  },
  {
    "model": "grimjim/Llama-Nephilim-Metamorphosis-v2-8B",
    "score": 0.236
  },
  {
    "model": "huihui-ai/QwQ-32B-Coder-Fusion-7030",
    "score": 0.236
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-PRP-light-8B",
    "score": 0.236
  },
  {
    "model": "jaspionjader/bh-58",
    "score": 0.236
  },
  {
    "model": "jaspionjader/bh-59",
    "score": 0.236
  },
  {
    "model": "jaspionjader/ek-6",
    "score": 0.236
  },
  {
    "model": "jaspionjader/f-2-8b",
    "score": 0.236
  },
  {
    "model": "jaspionjader/f-5-8b",
    "score": 0.236
  },
  {
    "model": "jaspionjader/kstc-11-8b",
    "score": 0.236
  },
  {
    "model": "jaspionjader/slu-37",
    "score": 0.236
  },
  {
    "model": "jaspionjader/test-11",
    "score": 0.236
  },
  {
    "model": "jaspionjader/test-12",
    "score": 0.236
  },
  {
    "model": "jaspionjader/test-15",
    "score": 0.236
  },
  {
    "model": "jaspionjader/test-19",
    "score": 0.236
  },
  {
    "model": "jpacifico/Chocolatine-14B-Instruct-4k-DPO",
    "score": 0.236
  },
  {
    "model": "lkoenig/BBAI_145_",
    "score": 0.236
  },
  {
    "model": "migtissera/Trinity-2-Codestral-22B-v0.2",
    "score": 0.236
  },
  {
    "model": "migtissera/Trinity-2-Codestral-22B-v0.2",
    "score": 0.236
  },
  {
    "model": "mkurman/phi-4-MedIT-11B-exp-1",
    "score": 0.236
  },
  {
    "model": "nbeerbower/Mistral-Small-Gutenberg-Doppel-22B",
    "score": 0.236
  },
  {
    "model": "nbeerbower/mistral-nemo-gutenberg-12B-v4",
    "score": 0.236
  },
  {
    "model": "neopolita/jessi-v0.1-falcon3-10b-instruct",
    "score": 0.236
  },
  {
    "model": "neopolita/loki-v0.1-virtuoso",
    "score": 0.236
  },
  {
    "model": "newsbang/Homer-v1.0-Qwen2.5-7B",
    "score": 0.236
  },
  {
    "model": "ontocord/merged_0.2_expert_0.8",
    "score": 0.236
  },
  {
    "model": "prithivMLmods/Megatron-Opus-14B-2.1",
    "score": 0.236
  },
  {
    "model": "prithivMLmods/QwQ-MathOct-7B",
    "score": 0.236
  },
  {
    "model": "prithivMLmods/Sombrero-Opus-14B-Elite6",
    "score": 0.236
  },
  {
    "model": "prithivMLmods/Viper-Coder-Hybrid-v1.2",
    "score": 0.236
  },
  {
    "model": "qingy2019/Qwen2.5-Math-14B-Instruct",
    "score": 0.236
  },
  {
    "model": "qingy2019/Qwen2.5-Math-14B-Instruct",
    "score": 0.236
  },
  {
    "model": "qingy2024/Falcon3-2x10B-MoE-Instruct",
    "score": 0.236
  },
  {
    "model": "qingy2024/OwO-14B-Instruct",
    "score": 0.236
  },
  {
    "model": "sometimesanotion/Qwen2.5-14B-Vimarckoso",
    "score": 0.236
  },
  {
    "model": "sthenno/tempesthenno-fusion-0309",
    "score": 0.236
  },
  {
    "model": "tanliboy/lambda-qwen2.5-32b-dpo-test",
    "score": 0.236
  },
  {
    "model": "tiiuae/Falcon3-10B-Base",
    "score": 0.236
  },
  {
    "model": "vhab10/llama-3-8b-merged-linear",
    "score": 0.236
  },
  {
    "model": "Arthur-LAGACHERIE/Precis-1B-Instruct",
    "score": 0.232
  },
  {
    "model": "Aryanne/SHBA",
    "score": 0.232
  },
  {
    "model": "Cran-May/T.E-8.1",
    "score": 0.232
  },
  {
    "model": "Danielbrdz/Barcenas-10b",
    "score": 0.232
  },
  {
    "model": "DoppelReflEx/MiniusLight-24B-v1d-test",
    "score": 0.232
  },
  {
    "model": "DreadPoor/Aspire-8B-model_stock",
    "score": 0.232
  },
  {
    "model": "DreadPoor/Minthy-8B-Model_Stock",
    "score": 0.232
  },
  {
    "model": "DreadPoor/Minthy_ALT-8B-Model_Stock",
    "score": 0.232
  },
  {
    "model": "DreadPoor/Spring_Dusk-8B-SCE",
    "score": 0.232
  },
  {
    "model": "DreadPoor/TEST06-ignore",
    "score": 0.232
  },
  {
    "model": "DreadPoor/TEST07-ignore",
    "score": 0.232
  },
  {
    "model": "DreadPoor/Winter_Dawn-8B-TIES",
    "score": 0.232
  },
  {
    "model": "EpistemeAI/Mistral-Nemo-Instruct-12B-Philosophy-Math",
    "score": 0.232
  },
  {
    "model": "Goekdeniz-Guelmez/Josiefied-Qwen2.5-14B-Instruct-abliterated-v4",
    "score": 0.232
  },
  {
    "model": "HuggingFaceH4/zephyr-7b-gemma-v0.1",
    "score": 0.232
  },
  {
    "model": "Invalid-Null/PeiYangMe-0.5",
    "score": 0.232
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_Math_Teacher",
    "score": 0.232
  },
  {
    "model": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v8.9",
    "score": 0.232
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_DodoWild_v2.03",
    "score": 0.232
  },
  {
    "model": "P0x0/Astra-v1-12B",
    "score": 0.232
  },
  {
    "model": "Qwen/Qwen2-72B",
    "score": 0.232
  },
  {
    "model": "Replete-AI/Replete-LLM-V2-Llama-3.1-8b",
    "score": 0.232
  },
  {
    "model": "Sakalti/Saka-24B",
    "score": 0.232
  },
  {
    "model": "Sakalti/light-1.1-3B",
    "score": 0.232
  },
  {
    "model": "Supichi/BBAI_135_Gemma",
    "score": 0.232
  },
  {
    "model": "Supichi/BBAI_525_Tsu_gZ_Xia0",
    "score": 0.232
  },
  {
    "model": "T145/ZEUS-8B-V23",
    "score": 0.232
  },
  {
    "model": "T145/ZEUS-8B-V9",
    "score": 0.232
  },
  {
    "model": "TheTsar1209/qwen-carpmuscle-v0.4.1",
    "score": 0.232
  },
  {
    "model": "Triangle104/Annunaki-12b",
    "score": 0.232
  },
  {
    "model": "Triangle104/Mistral-Small-24b-Harmony",
    "score": 0.232
  },
  {
    "model": "Triangle104/Q2.5-Humane-RP",
    "score": 0.232
  },
  {
    "model": "Tsunami-th/Tsunami-1.0-14B-Instruct",
    "score": 0.232
  },
  {
    "model": "abhishek/autotrain-llama3-70b-orpo-v1",
    "score": 0.232
  },
  {
    "model": "akjindal53244/Llama-3.1-Storm-8B",
    "score": 0.232
  },
  {
    "model": "akjindal53244/Llama-3.1-Storm-8B",
    "score": 0.232
  },
  {
    "model": "alcholjung/llama3_medical_tuned",
    "score": 0.232
  },
  {
    "model": "allknowingroger/Ph3task3-14B",
    "score": 0.232
  },
  {
    "model": "allknowingroger/QwenSlerp5-14B",
    "score": 0.232
  },
  {
    "model": "allknowingroger/llama3-Jallabi-40B-s",
    "score": 0.232
  },
  {
    "model": "aloobun/d-SmolLM2-360M",
    "score": 0.232
  },
  {
    "model": "arcee-ai/Virtuoso-Small",
    "score": 0.232
  },
  {
    "model": "bunnycore/Qwen2.5-7B-Fuse-Exp",
    "score": 0.232
  },
  {
    "model": "bunnycore/Tulu-3.1-8B-SuperNova",
    "score": 0.232
  },
  {
    "model": "byroneverson/Mistral-Small-Instruct-2409-abliterated",
    "score": 0.232
  },
  {
    "model": "darkc0de/BuddyGlassNeverSleeps",
    "score": 0.232
  },
  {
    "model": "dnhkng/RYS-Llama-3.1-8B-Instruct",
    "score": 0.232
  },
  {
    "model": "ehristoforu/ud-14b",
    "score": 0.232
  },
  {
    "model": "freewheelin/free-evo-qwen72b-v0.8-re",
    "score": 0.232
  },
  {
    "model": "google/umt5-base",
    "score": 0.232
  },
  {
    "model": "grimjim/Magnolia-v4-12B",
    "score": 0.232
  },
  {
    "model": "hotmailuser/Falcon3Slerp2-10B",
    "score": 0.232
  },
  {
    "model": "inflatebot/MN-12B-Mag-Mell-R1",
    "score": 0.232
  },
  {
    "model": "jaspionjader/Auro-Kosmos-EVAA-v2.1-8B",
    "score": 0.232
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-PRP-v30-8B",
    "score": 0.232
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-PRP-v32-8B",
    "score": 0.232
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-gamma-light-alt-8B",
    "score": 0.232
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-gamma-v16-8B",
    "score": 0.232
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-v10-8B",
    "score": 0.232
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-v5-8B",
    "score": 0.232
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-v8-8B",
    "score": 0.232
  },
  {
    "model": "jaspionjader/Kosmos-Elusive-VENN-Asymmetric-8B",
    "score": 0.232
  },
  {
    "model": "jaspionjader/bh-11",
    "score": 0.232
  },
  {
    "model": "jaspionjader/bh-44",
    "score": 0.232
  },
  {
    "model": "jaspionjader/bh-62",
    "score": 0.232
  },
  {
    "model": "jaspionjader/ek-7",
    "score": 0.232
  },
  {
    "model": "jaspionjader/f-9-8b",
    "score": 0.232
  },
  {
    "model": "jaspionjader/kstc-9-8b",
    "score": 0.232
  },
  {
    "model": "jaspionjader/sof-1",
    "score": 0.232
  },
  {
    "model": "jaspionjader/test-20",
    "score": 0.232
  },
  {
    "model": "jpacifico/Chocolatine-14B-Instruct-DPO-v1.2",
    "score": 0.232
  },
  {
    "model": "meditsolutions/MSH-v1-Bielik-v2.3-Instruct-MedIT-merge",
    "score": 0.232
  },
  {
    "model": "nbeerbower/EVA-abliterated-TIES-Qwen2.5-14B",
    "score": 0.232
  },
  {
    "model": "nbeerbower/Mistral-Nemo-Gutenberg-Doppel-12B",
    "score": 0.232
  },
  {
    "model": "nhyha/merge_Qwen2.5-7B-Instruct_20241023_0314",
    "score": 0.232
  },
  {
    "model": "princeton-nlp/Llama-3-Instruct-8B-DPO-v0.2",
    "score": 0.232
  },
  {
    "model": "princeton-nlp/Llama-3-Instruct-8B-ORPO",
    "score": 0.232
  },
  {
    "model": "qingy2019/Qwen2.5-Math-14B-Instruct-Alpha",
    "score": 0.232
  },
  {
    "model": "rubenroy/Geneva-12B-GCv2-5m",
    "score": 0.232
  },
  {
    "model": "sometimesanotion/Qwen-2.5-14B-Virmarckeoso",
    "score": 0.232
  },
  {
    "model": "sthenno/tempesthenno-sft-0309-ckpt10",
    "score": 0.232
  },
  {
    "model": "tensopolis/mistral-small-2501-tensopolis-v1",
    "score": 0.232
  },
  {
    "model": "tensopolis/virtuoso-small-tensopolis-v1",
    "score": 0.232
  },
  {
    "model": "tiiuae/falcon-7b-instruct",
    "score": 0.232
  },
  {
    "model": "v000000/L3.1-Niitorm-8B-DPO-t0.0001",
    "score": 0.232
  },
  {
    "model": "v000000/Qwen2.5-14B-Gutenberg-Instruct-Slerpeno",
    "score": 0.232
  },
  {
    "model": "1-800-LLMs/Qwen-2.5-14B-Hindi-Custom-Instruct",
    "score": 0.228
  },
  {
    "model": "01-ai/Yi-1.5-34B",
    "score": 0.228
  },
  {
    "model": "1024m/QWEN-14B-B100",
    "score": 0.228
  },
  {
    "model": "Aryanne/SuperHeart",
    "score": 0.228
  },
  {
    "model": "BAAI/OPI-Llama-3.1-8B-Instruct",
    "score": 0.228
  },
  {
    "model": "Daemontatox/NemoR",
    "score": 0.228
  },
  {
    "model": "Daemontatox/RA_Reasoner2.0",
    "score": 0.228
  },
  {
    "model": "DeepAutoAI/d2nwg_Llama-3.1-8B-Instruct-v0.0",
    "score": 0.228
  },
  {
    "model": "DreadPoor/WIP_Damascus-8B-TIES",
    "score": 0.228
  },
  {
    "model": "DreadPoor/Winter-8B-SCE",
    "score": 0.228
  },
  {
    "model": "DreadPoor/tests_pending-do_not_use_yet",
    "score": 0.228
  },
  {
    "model": "HuggingFaceTB/SmolLM2-135M",
    "score": 0.228
  },
  {
    "model": "Jacoby746/Casual-Magnum-34B",
    "score": 0.228
  },
  {
    "model": "LeroyDyer/SpydazWeb_HumanAI_M2",
    "score": 0.228
  },
  {
    "model": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v7-rebase",
    "score": 0.228
  },
  {
    "model": "MaziyarPanahi/calme-2.1-phi3-4b",
    "score": 0.228
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_DodoWild_v2.10",
    "score": 0.228
  },
  {
    "model": "NikolaSigmoid/phi-4-14b",
    "score": 0.228
  },
  {
    "model": "OpenBuddy/openbuddy-falcon3-10b-v24.2-131k",
    "score": 0.228
  },
  {
    "model": "OpenBuddy/openbuddy-qwq-32b-v24.1-200k",
    "score": 0.228
  },
  {
    "model": "OpenLLM-France/Lucie-7B",
    "score": 0.228
  },
  {
    "model": "Quazim0t0/TBL-8B-sce",
    "score": 0.228
  },
  {
    "model": "Qwen/Qwen2.5-Coder-14B",
    "score": 0.228
  },
  {
    "model": "SicariusSicariiStuff/Impish_QWEN_14B-1M",
    "score": 0.228
  },
  {
    "model": "T145/ZEUS-8B-V8",
    "score": 0.228
  },
  {
    "model": "Triangle104/Mistral-Redemption-Arc",
    "score": 0.228
  },
  {
    "model": "Vikhrmodels/Vikhr-Llama3.1-8B-Instruct-R-21-09-24",
    "score": 0.228
  },
  {
    "model": "aixonlab/Grey-12b",
    "score": 0.228
  },
  {
    "model": "allknowingroger/QwenSlerp12-7B",
    "score": 0.228
  },
  {
    "model": "allknowingroger/Strangecoven-7B-slerp",
    "score": 0.228
  },
  {
    "model": "anthracite-org/magnum-v3-27b-kto",
    "score": 0.228
  },
  {
    "model": "anthracite-org/magnum-v4-12b",
    "score": 0.228
  },
  {
    "model": "baconnier/Napoleon_24B_V0.2",
    "score": 0.228
  },
  {
    "model": "google/mt5-xxl",
    "score": 0.228
  },
  {
    "model": "grimjim/DeepSauerHuatuoSkywork-R1-o1-Llama-3.1-8B",
    "score": 0.228
  },
  {
    "model": "hotmailuser/FalconSlerp3-10B",
    "score": 0.228
  },
  {
    "model": "hotmailuser/FalconSlerp4-7B",
    "score": 0.228
  },
  {
    "model": "hotmailuser/LlamaStock-8B",
    "score": 0.228
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-Franken-Immersive-v39-8B",
    "score": 0.228
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-PRP-v24-8B",
    "score": 0.228
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-PRP-v27-8B",
    "score": 0.228
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-PRP-v26-8B",
    "score": 0.228
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-PRP-v29-8B",
    "score": 0.228
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-gamma-v18-8B",
    "score": 0.228
  },
  {
    "model": "jaspionjader/bbb-2",
    "score": 0.228
  },
  {
    "model": "jaspionjader/bh-48",
    "score": 0.228
  },
  {
    "model": "jaspionjader/bh-53",
    "score": 0.228
  },
  {
    "model": "jaspionjader/bh-55",
    "score": 0.228
  },
  {
    "model": "jaspionjader/bh-61",
    "score": 0.228
  },
  {
    "model": "jaspionjader/f-4-8b",
    "score": 0.228
  },
  {
    "model": "jaspionjader/f-7-8b",
    "score": 0.228
  },
  {
    "model": "jaspionjader/knfp-3-8b",
    "score": 0.228
  },
  {
    "model": "jaspionjader/slu-25",
    "score": 0.228
  },
  {
    "model": "jaspionjader/slu-32",
    "score": 0.228
  },
  {
    "model": "jeffmeloy/Qwen2.5-7B-nerd-uncensored-v1.8",
    "score": 0.228
  },
  {
    "model": "jeffmeloy/Qwen2.5-7B-olm-v1.3",
    "score": 0.228
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.3-gamma-0.1",
    "score": 0.228
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_ties-density-0.1",
    "score": 0.228
  },
  {
    "model": "khoantap/cheap-moe-merge",
    "score": 0.228
  },
  {
    "model": "lkoenig/BBAI_456_QwenKoen",
    "score": 0.228
  },
  {
    "model": "lkoenig/BBAI_7B_QwenDyancabsLAW",
    "score": 0.228
  },
  {
    "model": "mergekit-community/sexeh_time_testing",
    "score": 0.228
  },
  {
    "model": "microsoft/Phi-3-small-128k-instruct",
    "score": 0.228
  },
  {
    "model": "mistralai/Mistral-Small-Instruct-2409",
    "score": 0.228
  },
  {
    "model": "mistralai/Mistral-Small-Instruct-2409",
    "score": 0.228
  },
  {
    "model": "mkxu/llama-3-8b-instruct-fpo",
    "score": 0.228
  },
  {
    "model": "nbeerbower/Gutensuppe-mistral-nemo-12B",
    "score": 0.228
  },
  {
    "model": "nbeerbower/Lyra4-Gutenberg2-12B",
    "score": 0.228
  },
  {
    "model": "nbeerbower/Qwen2.5-Gutenberg-Doppel-14B",
    "score": 0.228
  },
  {
    "model": "nisten/franqwenstein-35b",
    "score": 0.228
  },
  {
    "model": "nisten/franqwenstein-35b",
    "score": 0.228
  },
  {
    "model": "nlpguy/Lion-Lamarck-v.1.1.0",
    "score": 0.228
  },
  {
    "model": "paloalma/ECE-TW3-JRGL-V1",
    "score": 0.228
  },
  {
    "model": "prithivMLmods/Calcium-Opus-20B-v1",
    "score": 0.228
  },
  {
    "model": "prithivMLmods/Gauss-Opus-14B-R999",
    "score": 0.228
  },
  {
    "model": "prithivMLmods/Magellanic-Opus-14B-Exp",
    "score": 0.228
  },
  {
    "model": "prithivMLmods/Megatron-Opus-14B-Stock",
    "score": 0.228
  },
  {
    "model": "qingy2019/Qwen2.5-Ultimate-14B-Instruct",
    "score": 0.228
  },
  {
    "model": "qingy2024/QwEnlarge-16B-Instruct",
    "score": 0.228
  },
  {
    "model": "sthenno-com/miscii-14b-0218",
    "score": 0.228
  },
  {
    "model": "sumink/Qwensci",
    "score": 0.228
  },
  {
    "model": "tannedbum/L3-Nymeria-v2-8B",
    "score": 0.228
  },
  {
    "model": "tensopolis/falcon3-10b-tensopolis-v1",
    "score": 0.228
  },
  {
    "model": "tensopolis/falcon3-10b-tensopolis-v2",
    "score": 0.228
  },
  {
    "model": "tensopolis/virtuoso-small-v2-tensopolis-v1",
    "score": 0.228
  },
  {
    "model": "tiiuae/Falcon3-10B-Instruct",
    "score": 0.228
  },
  {
    "model": "vonjack/Phi-3.5-mini-instruct-hermes-fc-json",
    "score": 0.228
  },
  {
    "model": "win10/Qwen2.5-2B-Instruct",
    "score": 0.228
  },
  {
    "model": "AALF/gemma-2-27b-it-SimPO-37K-100steps",
    "score": 0.224
  },
  {
    "model": "AbacusResearch/Jallabi-34B",
    "score": 0.224
  },
  {
    "model": "Amaorynho/BBAI270V4",
    "score": 0.224
  },
  {
    "model": "CultriX/Qwen2.5-14B-Hyperionv3",
    "score": 0.224
  },
  {
    "model": "CultriX/Qwen2.5-14B-Wernicke-SLERP",
    "score": 0.224
  },
  {
    "model": "CultriX/Qwen2.5-14B-Wernickev3",
    "score": 0.224
  },
  {
    "model": "Dans-DiscountModels/12b-mn-dans-reasoning-test-3",
    "score": 0.224
  },
  {
    "model": "DoppelReflEx/MN-12B-Mimicore-GreenSnake",
    "score": 0.224
  },
  {
    "model": "DoppelReflEx/MiniusLight-24B-v1b-test",
    "score": 0.224
  },
  {
    "model": "Etherll/Herplete-LLM-Llama-3.1-8b",
    "score": 0.224
  },
  {
    "model": "Etherll/Herplete-LLM-Llama-3.1-8b",
    "score": 0.224
  },
  {
    "model": "HiroseKoichi/Llama-Salad-4x8B-V3",
    "score": 0.224
  },
  {
    "model": "Lawnakk/BBALAW1.6",
    "score": 0.224
  },
  {
    "model": "Quazim0t0/Jekyl-8b-sce",
    "score": 0.224
  },
  {
    "model": "Sakalti/SJT-900M",
    "score": 0.224
  },
  {
    "model": "Sakalti/Saba2-3B",
    "score": 0.224
  },
  {
    "model": "Sao10K/L3-8B-Lunaris-v1",
    "score": 0.224
  },
  {
    "model": "SicariusSicariiStuff/Impish_Mind_8B",
    "score": 0.224
  },
  {
    "model": "SicariusSicariiStuff/Phi-lthy4",
    "score": 0.224
  },
  {
    "model": "Supichi/BBAIK29",
    "score": 0.224
  },
  {
    "model": "T145/KRONOS-8B-V9",
    "score": 0.224
  },
  {
    "model": "T145/ZEUS-8B-V15",
    "score": 0.224
  },
  {
    "model": "T145/ZEUS-8B-V2L1",
    "score": 0.224
  },
  {
    "model": "TheTsar1209/qwen-carpmuscle-v0.2",
    "score": 0.224
  },
  {
    "model": "TheTsar1209/qwen-carpmuscle-v0.3",
    "score": 0.224
  },
  {
    "model": "Triangle104/BigTalker-Lite-8B",
    "score": 0.224
  },
  {
    "model": "VAGOsolutions/SauerkrautLM-v2-14b-DPO",
    "score": 0.224
  },
  {
    "model": "VAGOsolutions/SauerkrautLM-v2-14b-SFT",
    "score": 0.224
  },
  {
    "model": "Xiaojian9992024/Phi-4-Megatron-Empathetic",
    "score": 0.224
  },
  {
    "model": "YOYO-AI/Qwen2.5-14B-YOYO-latest-V2",
    "score": 0.224
  },
  {
    "model": "Youlln/ECE-PRYMMAL-0.5B-SLERP-V3",
    "score": 0.224
  },
  {
    "model": "ZeroXClem/Llama-3.1-8B-SpecialTitanFusion",
    "score": 0.224
  },
  {
    "model": "ZeroXClem/Qwen2.5-7B-CelestialHarmony-1M",
    "score": 0.224
  },
  {
    "model": "aaditya/Llama3-OpenBioLLM-70B",
    "score": 0.224
  },
  {
    "model": "abhishek/autotrain-vr4a1-e5mms",
    "score": 0.224
  },
  {
    "model": "agentlans/Llama3.1-8B-drill",
    "score": 0.224
  },
  {
    "model": "aixonlab/Zara-14b-v1.2",
    "score": 0.224
  },
  {
    "model": "akhadangi/Llama3.2.1B.BaseFiT",
    "score": 0.224
  },
  {
    "model": "cloudyu/Mixtral_34Bx2_MoE_60B",
    "score": 0.224
  },
  {
    "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    "score": 0.224
  },
  {
    "model": "djuna/L3.1-Suze-Vume-calc",
    "score": 0.224
  },
  {
    "model": "dwikitheduck/gen-inst-1",
    "score": 0.224
  },
  {
    "model": "failspy/Phi-3-medium-4k-instruct-abliterated-v3",
    "score": 0.224
  },
  {
    "model": "fluently-sets/FalconThink3-10B-IT",
    "score": 0.224
  },
  {
    "model": "godlikehhd/alpaca_data_full_2",
    "score": 0.224
  },
  {
    "model": "godlikehhd/qwen_full_data_alpaca",
    "score": 0.224
  },
  {
    "model": "grimjim/Llama3.1-SuperNovaLite-HuatuoSkywork-o1-8B",
    "score": 0.224
  },
  {
    "model": "grimjim/Magnolia-v5a-12B",
    "score": 0.224
  },
  {
    "model": "grimjim/llama-3-Nephilim-v3-8B",
    "score": 0.224
  },
  {
    "model": "hotmailuser/Llama-Hermes-slerp2-8B",
    "score": 0.224
  },
  {
    "model": "ibm-granite/granite-3.1-3b-a800m-instruct",
    "score": 0.224
  },
  {
    "model": "jaspionjader/Auro-Kosmos-EVAA-v2-8B",
    "score": 0.224
  },
  {
    "model": "jaspionjader/Kosmos-Aurora_faustus-8B",
    "score": 0.224
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-8B",
    "score": 0.224
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-v7-8B",
    "score": 0.224
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-v6-8B",
    "score": 0.224
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-v9-8B",
    "score": 0.224
  },
  {
    "model": "jaspionjader/bbb-6",
    "score": 0.224
  },
  {
    "model": "jaspionjader/bh-24",
    "score": 0.224
  },
  {
    "model": "jaspionjader/bh-41",
    "score": 0.224
  },
  {
    "model": "jaspionjader/bh-50",
    "score": 0.224
  },
  {
    "model": "jaspionjader/bh-57",
    "score": 0.224
  },
  {
    "model": "jaspionjader/dp-6-8b",
    "score": 0.224
  },
  {
    "model": "jaspionjader/f-3-8b",
    "score": 0.224
  },
  {
    "model": "jaspionjader/gamma-Kosmos-EVAA-v2-8B",
    "score": 0.224
  },
  {
    "model": "jaspionjader/gamma-Kosmos-EVAA-v3-8B",
    "score": 0.224
  },
  {
    "model": "jaspionjader/slu-23",
    "score": 0.224
  },
  {
    "model": "jaspionjader/slu-34",
    "score": 0.224
  },
  {
    "model": "jaspionjader/slu-35",
    "score": 0.224
  },
  {
    "model": "jeffmeloy/Qwen-7B-nerd-uncensored-v1.0",
    "score": 0.224
  },
  {
    "model": "jeffmeloy/Qwen2.5-7B-nerd-uncensored-v0.9",
    "score": 0.224
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.1-gamma-0.1",
    "score": 0.224
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.3-gamma-0.01",
    "score": 0.224
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.9-gamma-0.1",
    "score": 0.224
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.5-gamma-0.1",
    "score": 0.224
  },
  {
    "model": "khoantap/llama-3-8b-stock-merge",
    "score": 0.224
  },
  {
    "model": "lkoenig/BBAI_212_QwenLawLo",
    "score": 0.224
  },
  {
    "model": "meta-llama/Llama-3.1-70B",
    "score": 0.224
  },
  {
    "model": "meta-llama/Llama-3.2-1B-Instruct",
    "score": 0.224
  },
  {
    "model": "mistralai/Mistral-Small-24B-Base-2501",
    "score": 0.224
  },
  {
    "model": "mlabonne/ChimeraLlama-3-8B-v2",
    "score": 0.224
  },
  {
    "model": "mlabonne/Daredevil-8B",
    "score": 0.224
  },
  {
    "model": "mlabonne/ChimeraLlama-3-8B-v3",
    "score": 0.224
  },
  {
    "model": "nbeerbower/Lyra4-Gutenberg-12B",
    "score": 0.224
  },
  {
    "model": "nvidia/AceInstruct-72B",
    "score": 0.224
  },
  {
    "model": "nvidia/AceMath-72B-Instruct",
    "score": 0.224
  },
  {
    "model": "ontocord/starcoder2_3b-AutoRedteam",
    "score": 0.224
  },
  {
    "model": "ozone-ai/0x-lite",
    "score": 0.224
  },
  {
    "model": "paloalma/Le_Triomphant-ECE-TW3",
    "score": 0.224
  },
  {
    "model": "prithivMLmods/Blaze-14B-xElite",
    "score": 0.224
  },
  {
    "model": "qingy2024/Qwen2.6-Math-14B-Instruct",
    "score": 0.224
  },
  {
    "model": "spow12/ChatWaifu_v2.0_22B",
    "score": 0.224
  },
  {
    "model": "spow12/ChatWaifu_v2.0_22B",
    "score": 0.224
  },
  {
    "model": "suayptalha/Rombos-2.5-T.E-8.1",
    "score": 0.224
  },
  {
    "model": "togethercomputer/RedPajama-INCITE-7B-Base",
    "score": 0.224
  },
  {
    "model": "vihangd/smart-dan-sft-v0.1",
    "score": 0.224
  },
  {
    "model": "01-ai/Yi-1.5-9B-Chat",
    "score": 0.22
  },
  {
    "model": "Columbia-NLP/LION-Gemma-2b-sft-v1.0",
    "score": 0.22
  },
  {
    "model": "Corianas/Quokka_2.7b",
    "score": 0.22
  },
  {
    "model": "DreadPoor/Heart_Stolen-ALT-8B-Model_Stock",
    "score": 0.22
  },
  {
    "model": "EleutherAI/pythia-160m",
    "score": 0.22
  },
  {
    "model": "Etherll/Herplete-LLM-Llama-3.1-8b-Ties",
    "score": 0.22
  },
  {
    "model": "FlofloB/smollm2-135M_pretrained_400k_fineweb_uncovai_human_removed",
    "score": 0.22
  },
  {
    "model": "FlofloB/smollm2-135M_pretrained_600k_fineweb_uncovai_human_removed",
    "score": 0.22
  },
  {
    "model": "HelpingAI/Priya-10B",
    "score": 0.22
  },
  {
    "model": "HuggingFaceTB/SmolLM-1.7B",
    "score": 0.22
  },
  {
    "model": "HuggingFaceTB/SmolLM2-360M-Instruct",
    "score": 0.22
  },
  {
    "model": "HuggingFaceTB/SmolLM2-360M-Instruct",
    "score": 0.22
  },
  {
    "model": "LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct",
    "score": 0.22
  },
  {
    "model": "LLM360/K2-Chat",
    "score": 0.22
  },
  {
    "model": "Lawnakk/BBALAW1.61",
    "score": 0.22
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_TEMP_",
    "score": 0.22
  },
  {
    "model": "LimYeri/CodeMind-Llama3-8B-unsloth_v4-one-merged",
    "score": 0.22
  },
  {
    "model": "ManoloPueblo/LLM_MERGE_CC3",
    "score": 0.22
  },
  {
    "model": "Nitral-AI/Hathor_Stable-v0.2-L3-8B",
    "score": 0.22
  },
  {
    "model": "Quazim0t0/GivingTree-8b-sce",
    "score": 0.22
  },
  {
    "model": "Quazim0t0/Heretic1.5b",
    "score": 0.22
  },
  {
    "model": "Qwen/Qwen1.5-110B-Chat",
    "score": 0.22
  },
  {
    "model": "Qwen/Qwen1.5-110B",
    "score": 0.22
  },
  {
    "model": "Qwen/Qwen2.5-Math-72B-Instruct",
    "score": 0.22
  },
  {
    "model": "SanjiWatsuki/Silicon-Maid-7B",
    "score": 0.22
  },
  {
    "model": "Sicarius-Prototyping/Brainy_LLAMA",
    "score": 0.22
  },
  {
    "model": "SicariusSicariiStuff/Dusk_Rainbow",
    "score": 0.22
  },
  {
    "model": "SicariusSicariiStuff/Qwen2.5-14B_Uncensored_Instruct",
    "score": 0.22
  },
  {
    "model": "SicariusSicariiStuff/dn_ep02",
    "score": 0.22
  },
  {
    "model": "SkyOrbis/SKY-Ko-Llama3.1-8B-lora-epoch1",
    "score": 0.22
  },
  {
    "model": "SkyOrbis/SKY-Ko-Llama3.1-8B-lora",
    "score": 0.22
  },
  {
    "model": "Triangle104/Chronos-Prism_V1.0",
    "score": 0.22
  },
  {
    "model": "Xclbr7/caliburn-v2-12b",
    "score": 0.22
  },
  {
    "model": "Xiaojian9992024/Qwen2.5-THREADRIPPER-Small",
    "score": 0.22
  },
  {
    "model": "Yuma42/Llama3.1-IgneousIguana-8B",
    "score": 0.22
  },
  {
    "model": "ZhangShenao/SELM-Llama-3-8B-Instruct-iter-3",
    "score": 0.22
  },
  {
    "model": "abacusai/bigstral-12b-32k",
    "score": 0.22
  },
  {
    "model": "akhadangi/Llama3.2.1B.0.01-First",
    "score": 0.22
  },
  {
    "model": "allknowingroger/Marco-01-slerp1-7B",
    "score": 0.22
  },
  {
    "model": "cognitivecomputations/dolphin-2.9.1-llama-3-70b",
    "score": 0.22
  },
  {
    "model": "darkc0de/BuddyGlassUncensored2025.2",
    "score": 0.22
  },
  {
    "model": "ehristoforu/della-70b-test-v1",
    "score": 0.22
  },
  {
    "model": "formulae/mita-elite-sce-gen1.1-v1-7b-2-26-2025-exp",
    "score": 0.22
  },
  {
    "model": "godlikehhd/alpaca_data_ins_max_5200",
    "score": 0.22
  },
  {
    "model": "godlikehhd/alpaca_data_score_max_0.3_2600",
    "score": 0.22
  },
  {
    "model": "gz987/qwen2.5-7b-cabs-v0.3",
    "score": 0.22
  },
  {
    "model": "hotmailuser/Qwen2.5-HomerSlerp-7B",
    "score": 0.22
  },
  {
    "model": "hotmailuser/QwenStock-1.7B",
    "score": 0.22
  },
  {
    "model": "invisietch/EtherealRainbow-v0.2-8B",
    "score": 0.22
  },
  {
    "model": "invisietch/EtherealRainbow-v0.3-8B",
    "score": 0.22
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-Fusion-8B",
    "score": 0.22
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-Fusion-8B",
    "score": 0.22
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-TSN-v19-8B",
    "score": 0.22
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-v4-8B",
    "score": 0.22
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-v3-8B",
    "score": 0.22
  },
  {
    "model": "jaspionjader/Kosmos-Elusive-8b",
    "score": 0.22
  },
  {
    "model": "jaspionjader/Kosmos-Elusive-VENN-8B",
    "score": 0.22
  },
  {
    "model": "jaspionjader/Kosmos-VENN-8B",
    "score": 0.22
  },
  {
    "model": "jaspionjader/bh-33",
    "score": 0.22
  },
  {
    "model": "jaspionjader/bh-39",
    "score": 0.22
  },
  {
    "model": "jaspionjader/bh-40",
    "score": 0.22
  },
  {
    "model": "jaspionjader/bh-43",
    "score": 0.22
  },
  {
    "model": "jaspionjader/bh-47",
    "score": 0.22
  },
  {
    "model": "jaspionjader/bh-51",
    "score": 0.22
  },
  {
    "model": "jaspionjader/bh-54",
    "score": 0.22
  },
  {
    "model": "jaspionjader/bh-56",
    "score": 0.22
  },
  {
    "model": "jaspionjader/bh-64",
    "score": 0.22
  },
  {
    "model": "jaspionjader/dp-7-8b",
    "score": 0.22
  },
  {
    "model": "jaspionjader/fct-9-8b",
    "score": 0.22
  },
  {
    "model": "jaspionjader/kstc-4-8b",
    "score": 0.22
  },
  {
    "model": "jaspionjader/kstc-5-8b",
    "score": 0.22
  },
  {
    "model": "jaspionjader/slu-33",
    "score": 0.22
  },
  {
    "model": "jaspionjader/sof-10",
    "score": 0.22
  },
  {
    "model": "jaspionjader/test-13",
    "score": 0.22
  },
  {
    "model": "jebish7/Llama-3.1-8B-Instruct",
    "score": 0.22
  },
  {
    "model": "jeffmeloy/Qwen2.5-7B-olm-v1.0",
    "score": 0.22
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.7-gamma-0.01",
    "score": 0.22
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.3-gamma-0.1",
    "score": 0.22
  },
  {
    "model": "lkoenig/BBAI_230_Xiaqwen",
    "score": 0.22
  },
  {
    "model": "lkoenig/BBAI_375_QwenDyancabs",
    "score": 0.22
  },
  {
    "model": "lodrick-the-lafted/llama-3.1-8b-instruct-ortho-v7",
    "score": 0.22
  },
  {
    "model": "meta-llama/Llama-3.2-1B",
    "score": 0.22
  },
  {
    "model": "microsoft/phi-1_5",
    "score": 0.22
  },
  {
    "model": "mindw96/DeepSeek-llama3.3-Bllossom-8B-DACON-LLM3",
    "score": 0.22
  },
  {
    "model": "mosaicml/mpt-7b",
    "score": 0.22
  },
  {
    "model": "nbeerbower/Mistral-Small-Drummer-22B",
    "score": 0.22
  },
  {
    "model": "nbeerbower/Stella-mistral-nemo-12B-v2",
    "score": 0.22
  },
  {
    "model": "neopolita/jessi-v0.1-virtuoso-small",
    "score": 0.22
  },
  {
    "model": "netcat420/MFANN-Llama3.1-Abliterated-SLERP-TIES-V3",
    "score": 0.22
  },
  {
    "model": "netcat420/MFANN-Llama3.1-Abliterated-SLERP-V5",
    "score": 0.22
  },
  {
    "model": "netcat420/MFANN-Llama3.1-Abliterated-Slerp-V3.2",
    "score": 0.22
  },
  {
    "model": "netcat420/MFANN-llama3.1-abliterated-SLERP-v3",
    "score": 0.22
  },
  {
    "model": "netcat420/MFANN3bv0.21",
    "score": 0.22
  },
  {
    "model": "netcat420/MFANNv0.19",
    "score": 0.22
  },
  {
    "model": "princeton-nlp/Llama-3-Instruct-8B-SimPO",
    "score": 0.22
  },
  {
    "model": "prithivMLmods/COCO-7B-Instruct-1M",
    "score": 0.22
  },
  {
    "model": "prithivMLmods/Calcium-Opus-14B-Elite2",
    "score": 0.22
  },
  {
    "model": "prithivMLmods/Calcium-Opus-14B-Elite2-R1",
    "score": 0.22
  },
  {
    "model": "prithivMLmods/Calcium-Opus-14B-Elite3",
    "score": 0.22
  },
  {
    "model": "prithivMLmods/Phi-4-o1",
    "score": 0.22
  },
  {
    "model": "prithivMLmods/Primal-Opus-14B-Optimus-v1",
    "score": 0.22
  },
  {
    "model": "prithivMLmods/QwQ-LCoT1-Merged",
    "score": 0.22
  },
  {
    "model": "prithivMLmods/Viper-Coder-7B-Elite14",
    "score": 0.22
  },
  {
    "model": "rmdhirr/Gluon-8B",
    "score": 0.22
  },
  {
    "model": "sumink/somerft",
    "score": 0.22
  },
  {
    "model": "theprint/CleverBoi-Nemo-12B-v2",
    "score": 0.22
  },
  {
    "model": "v000000/Qwen2.5-14B-Gutenberg-1e-Delta",
    "score": 0.22
  },
  {
    "model": "v000000/Qwen2.5-Lumen-14B",
    "score": 0.22
  },
  {
    "model": "win10/llama3-13.45b-Instruct",
    "score": 0.22
  },
  {
    "model": "zhengr/MixTAO-7Bx2-MoE-v8.1",
    "score": 0.22
  },
  {
    "model": "AI4free/Dhanishtha",
    "score": 0.216
  },
  {
    "model": "BAAI/Infinity-Instruct-3M-0613-Mistral-7B",
    "score": 0.216
  },
  {
    "model": "BoltMonkey/NeuralDaredevil-SuperNova-Lite-7B-DARETIES-abliterated",
    "score": 0.216
  },
  {
    "model": "BoltMonkey/NeuralDaredevil-SuperNova-Lite-7B-DARETIES-abliterated",
    "score": 0.216
  },
  {
    "model": "CYFRAGOVPL/PLLuM-12B-nc-chat",
    "score": 0.216
  },
  {
    "model": "Casual-Autopsy/L3-Umbral-Mind-RP-v2.0-8B",
    "score": 0.216
  },
  {
    "model": "Cran-May/SCE-3-24B",
    "score": 0.216
  },
  {
    "model": "Daemontatox/AetherSett",
    "score": 0.216
  },
  {
    "model": "Daemontatox/SphinX",
    "score": 0.216
  },
  {
    "model": "Daemontatox/Zirel_1.5",
    "score": 0.216
  },
  {
    "model": "DoppelReflEx/L3-8B-R1-WolfCore",
    "score": 0.216
  },
  {
    "model": "DoppelReflEx/L3-8B-WolfCore",
    "score": 0.216
  },
  {
    "model": "DreadPoor/Aspire_1.3-8B_model-stock",
    "score": 0.216
  },
  {
    "model": "DreadPoor/Aspire_V2_ALT-8B-Model_Stock",
    "score": 0.216
  },
  {
    "model": "DreadPoor/Aspire_V2_ALT_ROW-8B-Model_Stock",
    "score": 0.216
  },
  {
    "model": "DreadPoor/HOT_STINKING_GARBAGE",
    "score": 0.216
  },
  {
    "model": "DreadPoor/WIP-Acacia-8B-Model_Stock",
    "score": 0.216
  },
  {
    "model": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.003-128K-code-ds-auto",
    "score": 0.216
  },
  {
    "model": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.003-128K-code-ds-auto",
    "score": 0.216
  },
  {
    "model": "FallenMerick/Chewy-Lemon-Cookie-11B",
    "score": 0.216
  },
  {
    "model": "FlofloB/smollm2-135M_pretrained_1000k_fineweb_uncovai_human_removed",
    "score": 0.216
  },
  {
    "model": "FlofloB/smollm2-135M_pretrained_400k_fineweb_uncovai_selected",
    "score": 0.216
  },
  {
    "model": "Jacoby746/Proto-Athena-4x7B",
    "score": 0.216
  },
  {
    "model": "Kumar955/Hemanth-llm",
    "score": 0.216
  },
  {
    "model": "LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct",
    "score": 0.216
  },
  {
    "model": "LGAI-EXAONE/EXAONE-3.5-32B-Instruct",
    "score": 0.216
  },
  {
    "model": "LeroyDyer/SpydazWeb_AI_HumanAI_012_INSTRUCT_XA",
    "score": 0.216
  },
  {
    "model": "LeroyDyer/SpydazWeb_AI_HumanAI_012_INSTRUCT_XA",
    "score": 0.216
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_Math_AdvancedStudent",
    "score": 0.216
  },
  {
    "model": "Lil-R/2_PRYMMAL-ECE-7B-SLERP",
    "score": 0.216
  },
  {
    "model": "Lil-R/PRYMMAL-ECE-7B-SLERP-V8",
    "score": 0.216
  },
  {
    "model": "LilRg/PRYMMAL-ECE-7B-SLERP-V3",
    "score": 0.216
  },
  {
    "model": "LilRg/PRYMMAL-ECE-7B-SLERP-V4",
    "score": 0.216
  },
  {
    "model": "LilRg/PRYMMAL-ECE-7B-SLERP-V5",
    "score": 0.216
  },
  {
    "model": "LilRg/PRYMMAL-ECE-7B-SLERP-V6",
    "score": 0.216
  },
  {
    "model": "LilRg/PRYMMAL-ECE-7B-SLERP-V7",
    "score": 0.216
  },
  {
    "model": "Locutusque/TinyMistral-248M-v2.5",
    "score": 0.216
  },
  {
    "model": "Luni/StarDust-12b-v2",
    "score": 0.216
  },
  {
    "model": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v9.2",
    "score": 0.216
  },
  {
    "model": "M4-ai/TinyMistral-248M-v3",
    "score": 0.216
  },
  {
    "model": "MLP-KTLim/llama-3-Korean-Bllossom-8B",
    "score": 0.216
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_DoberWild_v2.02",
    "score": 0.216
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_DoberWild_v2.03",
    "score": 0.216
  },
  {
    "model": "Nexesenex/Llama_3.2_1b_SunOrca_V1",
    "score": 0.216
  },
  {
    "model": "NotASI/FineTome-v1.5-Llama3.2-3B-1007",
    "score": 0.216
  },
  {
    "model": "Novaciano/BLAST_PROCESSING-3.2-1B",
    "score": 0.216
  },
  {
    "model": "OEvortex/HelpingAI2-9B",
    "score": 0.216
  },
  {
    "model": "Quazim0t0/Math_Phi4_Reason",
    "score": 0.216
  },
  {
    "model": "Sakalti/SJTPass-5",
    "score": 0.216
  },
  {
    "model": "Sakalti/Saba1.5-Pro-3B",
    "score": 0.216
  },
  {
    "model": "Sakalti/Saka-7.2B",
    "score": 0.216
  },
  {
    "model": "Sakalti/Saka-7.6B",
    "score": 0.216
  },
  {
    "model": "Sakalti/qwen2.5-2.3B",
    "score": 0.216
  },
  {
    "model": "T145/KRONOS-8B-V5",
    "score": 0.216
  },
  {
    "model": "THUDM/glm-4-9b-chat-1m",
    "score": 0.216
  },
  {
    "model": "TheTsar1209/qwen-carpmuscle-r-v0.3",
    "score": 0.216
  },
  {
    "model": "Triangle104/DS-Distilled-Hermes-Llama-3.1_TIES",
    "score": 0.216
  },
  {
    "model": "Triangle104/DS-R1-Distill-Q2.5-10B-Harmony",
    "score": 0.216
  },
  {
    "model": "Triangle104/Q2.5-AthensCOT",
    "score": 0.216
  },
  {
    "model": "Xiaojian9992024/Qwen2.5-Dyanka-7B-Preview",
    "score": 0.216
  },
  {
    "model": "Yuma42/Llama3.1-SuperHawk-8B",
    "score": 0.216
  },
  {
    "model": "ZeroXClem/Llama-3.1-8B-SuperTulu-LexiNova",
    "score": 0.216
  },
  {
    "model": "akhadangi/Llama3.2.1B.0.01-Last",
    "score": 0.216
  },
  {
    "model": "allknowingroger/HomerSlerp2-7B",
    "score": 0.216
  },
  {
    "model": "allknowingroger/Qwen2.5-7B-task2",
    "score": 0.216
  },
  {
    "model": "allknowingroger/Qwen2.5-7B-task8",
    "score": 0.216
  },
  {
    "model": "anakin87/gemma-2b-orpo",
    "score": 0.216
  },
  {
    "model": "baebee/7B-Cetacea",
    "score": 0.216
  },
  {
    "model": "bamec66557/MISCHIEVOUS-12B-Mix_0.2v",
    "score": 0.216
  },
  {
    "model": "braindao/iq-code-evmind-0.5b",
    "score": 0.216
  },
  {
    "model": "brgx53/3Bgeneralv2-ECE-PRYMMAL-Martial",
    "score": 0.216
  },
  {
    "model": "brgx53/3Blarenegv2-ECE-PRYMMAL-Martial",
    "score": 0.216
  },
  {
    "model": "brgx53/LaConfiance-PRYMMAL-ECE-TW3",
    "score": 0.216
  },
  {
    "model": "bunnycore/Llama-3.1-8B-TitanFusion-v3",
    "score": 0.216
  },
  {
    "model": "c10x/Q-Pluse",
    "score": 0.216
  },
  {
    "model": "davidkim205/Rhea-72b-v0.5",
    "score": 0.216
  },
  {
    "model": "ehristoforu/fq2.5-7b-it-normalize_true",
    "score": 0.216
  },
  {
    "model": "ehristoforu/fq2.5-7b-it-normalize_false",
    "score": 0.216
  },
  {
    "model": "ehristoforu/rmoe-v1",
    "score": 0.216
  },
  {
    "model": "experiment-llm/exp-3-q-r",
    "score": 0.216
  },
  {
    "model": "fblgit/una-cybertron-7b-v2-bf16",
    "score": 0.216
  },
  {
    "model": "formulae/mita-elite-v1.2-7b-2-26-2025",
    "score": 0.216
  },
  {
    "model": "gpt2",
    "score": 0.216
  },
  {
    "model": "gpt2",
    "score": 0.216
  },
  {
    "model": "grimjim/Llama-3-Instruct-8B-SPPO-Iter3-SimPO-merge",
    "score": 0.216
  },
  {
    "model": "grimjim/SauerHuatuoSkywork-o1-Llama-3.1-8B",
    "score": 0.216
  },
  {
    "model": "gz987/qwen2.5-7b-cabs-v0.1",
    "score": 0.216
  },
  {
    "model": "gz987/qwen2.5-7b-cabs-v0.2",
    "score": 0.216
  },
  {
    "model": "gz987/qwen2.5-7b-cabs-v0.4",
    "score": 0.216
  },
  {
    "model": "h2oai/h2o-danube3.1-4b-chat",
    "score": 0.216
  },
  {
    "model": "haoranxu/Llama-3-Instruct-8B-SimPO",
    "score": 0.216
  },
  {
    "model": "internlm/internlm2_5-7b-chat",
    "score": 0.216
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-TSN-v22-8B",
    "score": 0.216
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-gamma-v17-8B",
    "score": 0.216
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-v12-8B",
    "score": 0.216
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-v2-8B",
    "score": 0.216
  },
  {
    "model": "jaspionjader/Kosmos-Elusive-VENN-Aurora_faustus-8B",
    "score": 0.216
  },
  {
    "model": "jaspionjader/bh-30",
    "score": 0.216
  },
  {
    "model": "jaspionjader/bh-32",
    "score": 0.216
  },
  {
    "model": "jaspionjader/bh-46",
    "score": 0.216
  },
  {
    "model": "jaspionjader/slu-13",
    "score": 0.216
  },
  {
    "model": "jaspionjader/slu-20",
    "score": 0.216
  },
  {
    "model": "jaspionjader/slu-29",
    "score": 0.216
  },
  {
    "model": "jaspionjader/sof-3",
    "score": 0.216
  },
  {
    "model": "jaspionjader/test-14",
    "score": 0.216
  },
  {
    "model": "jeffmeloy/Qwen2.5-7B-nerd-uncensored-v1.0",
    "score": 0.216
  },
  {
    "model": "jeffmeloy/Qwen2.5-7B-olm-v1.4",
    "score": 0.216
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.5-gamma-0.1",
    "score": 0.216
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.1-gamma-0.1",
    "score": 0.216
  },
  {
    "model": "kaist-ai/janus-rm-7b",
    "score": 0.216
  },
  {
    "model": "khoantap/llama-linear-0.5-0.5-1-merge",
    "score": 0.216
  },
  {
    "model": "khoantap/moe-out-merge",
    "score": 0.216
  },
  {
    "model": "laislemke/LLaMA-2-vicuna-7b-slerp",
    "score": 0.216
  },
  {
    "model": "lalainy/ECE-PRYMMAL-YL-0.5B-SLERP-BIS-V1",
    "score": 0.216
  },
  {
    "model": "lkoenig/BBAI_7B_KoenQwenDyan",
    "score": 0.216
  },
  {
    "model": "lkoenig/BBAI_7B_QwenDyanKoenLo",
    "score": 0.216
  },
  {
    "model": "marcuscedricridia/cursorr-o1.2-7b",
    "score": 0.216
  },
  {
    "model": "microsoft/DialoGPT-medium",
    "score": 0.216
  },
  {
    "model": "nbeerbower/Lyra-Gutenberg-mistral-nemo-12B",
    "score": 0.216
  },
  {
    "model": "netcat420/MFANN-Llama3.1-Abliterated-SLERP-TIES-V2",
    "score": 0.216
  },
  {
    "model": "oopere/pruned60-llama-1b",
    "score": 0.216
  },
  {
    "model": "openai-community/gpt2-medium",
    "score": 0.216
  },
  {
    "model": "paloalma/ECE-TW3-JRGL-V2",
    "score": 0.216
  },
  {
    "model": "paulml/ECE-ILAB-Q1",
    "score": 0.216
  },
  {
    "model": "prithivMLmods/LwQ-Reasoner-10B",
    "score": 0.216
  },
  {
    "model": "prithivMLmods/Megatron-Corpus-14B-Exp",
    "score": 0.216
  },
  {
    "model": "prithivMLmods/Triangulum-5B",
    "score": 0.216
  },
  {
    "model": "prithivMLmods/Viper-Coder-HybridMini-v1.3",
    "score": 0.216
  },
  {
    "model": "qingy2024/Fusion-14B-Instruct",
    "score": 0.216
  },
  {
    "model": "qingy2024/Fusion2-14B-Instruct",
    "score": 0.216
  },
  {
    "model": "sakhan10/quantized_open_llama_3b_v2",
    "score": 0.216
  },
  {
    "model": "sethuiyer/Llamazing-3.1-8B-Instruct",
    "score": 0.216
  },
  {
    "model": "skumar9/Llama-medx_v2",
    "score": 0.216
  },
  {
    "model": "sometimesanotion/Lamarck-14B-v0.6-002-model_stock",
    "score": 0.216
  },
  {
    "model": "spow12/ChatWaifu_12B_v2.0",
    "score": 0.216
  },
  {
    "model": "suayptalha/Clarus-7B-v0.3",
    "score": 0.216
  },
  {
    "model": "sumink/bbhqwen5",
    "score": 0.216
  },
  {
    "model": "sumink/qwft",
    "score": 0.216
  },
  {
    "model": "theprint/ReWiz-Qwen-2.5-14B",
    "score": 0.216
  },
  {
    "model": "togethercomputer/RedPajama-INCITE-Instruct-3B-v1",
    "score": 0.216
  },
  {
    "model": "v000000/L3.1-Storniitova-8B",
    "score": 0.216
  },
  {
    "model": "waqasali1707/Beast-Soul-new",
    "score": 0.216
  },
  {
    "model": "ymcki/Llama-3.1-8B-SFT-GRPO-Instruct",
    "score": 0.216
  },
  {
    "model": "3rd-Degree-Burn/L-3.1-Science-Writer-8B",
    "score": 0.212
  },
  {
    "model": "01-ai/Yi-1.5-34B-Chat-16K",
    "score": 0.212
  },
  {
    "model": "01-ai/Yi-Coder-9B-Chat",
    "score": 0.212
  },
  {
    "model": "0-hero/Matter-0.2-7B-DPO",
    "score": 0.212
  },
  {
    "model": "AI-MO/NuminaMath-7B-TIR",
    "score": 0.212
  },
  {
    "model": "Ateron/Glowing-Forest-12B",
    "score": 0.212
  },
  {
    "model": "BEE-spoke-data/tFINE-900m-e16-d32-flan-infinity-instruct-7m-T2T_en-1024",
    "score": 0.212
  },
  {
    "model": "BEE-spoke-data/tFINE-900m-e16-d32-instruct_2e",
    "score": 0.212
  },
  {
    "model": "Columbia-NLP/LION-Gemma-2b-dpo-v1.0",
    "score": 0.212
  },
  {
    "model": "Columbia-NLP/LION-Gemma-2b-dpo-v1.0",
    "score": 0.212
  },
  {
    "model": "CultriX/Qwen2.5-14B-Brocav3",
    "score": 0.212
  },
  {
    "model": "CultriX/Qwenfinity-2.5-14B",
    "score": 0.212
  },
  {
    "model": "DRXD1000/Atlas-7B",
    "score": 0.212
  },
  {
    "model": "Daemontatox/RA_Reasoner",
    "score": 0.212
  },
  {
    "model": "Daemontatox/Zirel-7B-Math",
    "score": 0.212
  },
  {
    "model": "Danielbrdz/Barcenas-R1-Qwen-1.5b",
    "score": 0.212
  },
  {
    "model": "DeepAutoAI/d2nwg_causal_gpt2_v1",
    "score": 0.212
  },
  {
    "model": "DoppelReflEx/MN-12B-FoxFrame2-test",
    "score": 0.212
  },
  {
    "model": "DreadPoor/Aspire_V3-8B-Model_Stock",
    "score": 0.212
  },
  {
    "model": "DreadPoor/What_A_Thrill-8B-Model_Stock",
    "score": 0.212
  },
  {
    "model": "DreadPoor/ichor-8B-Model_Stock",
    "score": 0.212
  },
  {
    "model": "EpistemeAI/Fireball-R1.1-Llama-3.1-8B",
    "score": 0.212
  },
  {
    "model": "FlofloB/smollm2-135M_pretrained_200k_fineweb_uncovai_human_removed",
    "score": 0.212
  },
  {
    "model": "GalrionSoftworks/MN-LooseCannon-12B-v1",
    "score": 0.212
  },
  {
    "model": "Gryphe/Pantheon-RP-1.5-12b-Nemo",
    "score": 0.212
  },
  {
    "model": "Jacoby746/Proto-Harpy-Blazing-Light-v0.1-2x7B",
    "score": 0.212
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-IRPO_5e-6-2ep_1alp_0lam",
    "score": 0.212
  },
  {
    "model": "Josephgflowers/TinyLlama-Cinder-Agent-v1",
    "score": 0.212
  },
  {
    "model": "Khetterman/Kosmos-8B-v1",
    "score": 0.212
  },
  {
    "model": "Lawnakk/BBALAW1.2",
    "score": 0.212
  },
  {
    "model": "Lawnakk/BBALAW1.63",
    "score": 0.212
  },
  {
    "model": "LeroyDyer/SpydazWeb_AI_HumanAI_009_CHAT",
    "score": 0.212
  },
  {
    "model": "LeroyDyer/SpydazWeb_AI_HumanAI_011_INSTRUCT_ML",
    "score": 0.212
  },
  {
    "model": "LeroyDyer/SpydazWeb_AI_HumanAI_RP",
    "score": 0.212
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_ChatQA",
    "score": 0.212
  },
  {
    "model": "LightningRodLabs/Flashlight-v1.2",
    "score": 0.212
  },
  {
    "model": "Locutusque/Hercules-6.1-Llama-3.1-8B",
    "score": 0.212
  },
  {
    "model": "Marsouuu/general3Bv2-ECE-PRYMMAL-Martial",
    "score": 0.212
  },
  {
    "model": "MrRobotoAI/MrRoboto-ProLongBASE-pt8-unaligned-8b",
    "score": 0.212
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_Smarteaz_V1.01",
    "score": 0.212
  },
  {
    "model": "Nexesenex/Llama_3.2_1b_AquaSyn_0.1",
    "score": 0.212
  },
  {
    "model": "Nitral-AI/Captain-Eris_Violet-V0.420-12B",
    "score": 0.212
  },
  {
    "model": "NotASI/FineTome-Llama3.2-3B-1002",
    "score": 0.212
  },
  {
    "model": "OpenBuddy/openbuddy-qwen2.5llamaify-14b-v23.1-200k",
    "score": 0.212
  },
  {
    "model": "OpenBuddy/openbuddy-qwen2.5llamaify-14b-v23.3-200k",
    "score": 0.212
  },
  {
    "model": "Orion-zhen/Qwen2.5-7B-Instruct-Uncensored",
    "score": 0.212
  },
  {
    "model": "PJMixers/LLaMa-3-CursedStock-v2.0-8B",
    "score": 0.212
  },
  {
    "model": "Quazim0t0/Katana-8b-sce",
    "score": 0.212
  },
  {
    "model": "Quazim0t0/TB0-8B-sce",
    "score": 0.212
  },
  {
    "model": "Qwen/Qwen1.5-0.5B",
    "score": 0.212
  },
  {
    "model": "Qwen/Qwen2.5-Coder-32B",
    "score": 0.212
  },
  {
    "model": "Rakuten/RakutenAI-2.0-mini-instruct",
    "score": 0.212
  },
  {
    "model": "Sakalti/SJT-24B-Alpha",
    "score": 0.212
  },
  {
    "model": "Sakalti/SJTPass-4",
    "score": 0.212
  },
  {
    "model": "Sakalti/model-3",
    "score": 0.212
  },
  {
    "model": "Spestly/Atlas-Pro-1.5B-Preview",
    "score": 0.212
  },
  {
    "model": "Supichi/HF_TOKEN",
    "score": 0.212
  },
  {
    "model": "Triangle104/Q2.5-EVACOT-7b",
    "score": 0.212
  },
  {
    "model": "VAGOsolutions/SauerkrautLM-Gemma-7b",
    "score": 0.212
  },
  {
    "model": "YOYO-AI/ZYH-LLM-Qwen2.5-14B-V3",
    "score": 0.212
  },
  {
    "model": "ZeroXClem/Qwen2.5-7B-HomerCreative-Mix",
    "score": 0.212
  },
  {
    "model": "allknowingroger/HomerSlerp1-7B",
    "score": 0.212
  },
  {
    "model": "allknowingroger/HomerSlerp4-7B",
    "score": 0.212
  },
  {
    "model": "allknowingroger/Neuralcoven-7B-slerp",
    "score": 0.212
  },
  {
    "model": "allknowingroger/Ph3unsloth-3B-slerp",
    "score": 0.212
  },
  {
    "model": "allknowingroger/Qwen2.5-7B-task3",
    "score": 0.212
  },
  {
    "model": "allknowingroger/Qwen2.5-7B-task4",
    "score": 0.212
  },
  {
    "model": "alpindale/WizardLM-2-8x22B",
    "score": 0.212
  },
  {
    "model": "ashercn97/a1-v002",
    "score": 0.212
  },
  {
    "model": "bunnycore/Blabbertron-1.1",
    "score": 0.212
  },
  {
    "model": "bunnycore/Llama-3.1-8B-TitanFusion-Mix",
    "score": 0.212
  },
  {
    "model": "bunnycore/Phi-4-Trim-Exp1",
    "score": 0.212
  },
  {
    "model": "bunnycore/Qwen2.5-7B-Instruct-Merge-Stock-v0.1",
    "score": 0.212
  },
  {
    "model": "bunnycore/Qwen2.5-7B-Sky-R1-Mini",
    "score": 0.212
  },
  {
    "model": "ehristoforu/fd-lora-merged-64x128",
    "score": 0.212
  },
  {
    "model": "ehristoforu/tmoe",
    "score": 0.212
  },
  {
    "model": "eworojoshua/vas-01",
    "score": 0.212
  },
  {
    "model": "fluently-sets/reasoning-1-1k-demo",
    "score": 0.212
  },
  {
    "model": "godlikehhd/alpaca_data_ifd_me_max_5200",
    "score": 0.212
  },
  {
    "model": "godlikehhd/alpaca_data_sampled_ifd_new_5200",
    "score": 0.212
  },
  {
    "model": "godlikehhd/alpaca_data_score_max_2500",
    "score": 0.212
  },
  {
    "model": "google/flan-t5-small",
    "score": 0.212
  },
  {
    "model": "google/mt5-xl",
    "score": 0.212
  },
  {
    "model": "goulue5/merging_LLM",
    "score": 0.212
  },
  {
    "model": "grimjim/Llama-3-Instruct-8B-SimPO-SPPO-Iter3-merge",
    "score": 0.212
  },
  {
    "model": "grimjim/Llama-3.1-8B-Instruct-abliterated_via_adapter",
    "score": 0.212
  },
  {
    "model": "grimjim/Llama-3.1-Bonsaikraft-8B-Instruct",
    "score": 0.212
  },
  {
    "model": "hongbai12/li-0.4-pre",
    "score": 0.212
  },
  {
    "model": "hotmailuser/Falcon3Slerp4-10B",
    "score": 0.212
  },
  {
    "model": "hotmailuser/FalconSlerp1-7B",
    "score": 0.212
  },
  {
    "model": "hotmailuser/QwenModelStock-1.8B",
    "score": 0.212
  },
  {
    "model": "hotmailuser/QwenSlerp-7B",
    "score": 0.212
  },
  {
    "model": "iRyanBell/ARC1",
    "score": 0.212
  },
  {
    "model": "invisietch/MiS-Firefly-v0.2-22B",
    "score": 0.212
  },
  {
    "model": "jaspionjader/Auro-Kosmos-EVAA-v2.2-8B",
    "score": 0.212
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-TSN-light-8B",
    "score": 0.212
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-TSN-v21-8B",
    "score": 0.212
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-v11-8B",
    "score": 0.212
  },
  {
    "model": "jaspionjader/bbb-3",
    "score": 0.212
  },
  {
    "model": "jaspionjader/bbb-4",
    "score": 0.212
  },
  {
    "model": "jaspionjader/bh-18",
    "score": 0.212
  },
  {
    "model": "jaspionjader/bh-27",
    "score": 0.212
  },
  {
    "model": "jaspionjader/bh-28",
    "score": 0.212
  },
  {
    "model": "jaspionjader/bh-36",
    "score": 0.212
  },
  {
    "model": "jaspionjader/bh-52",
    "score": 0.212
  },
  {
    "model": "jaspionjader/gamma-Kosmos-EVAA-8B",
    "score": 0.212
  },
  {
    "model": "jaspionjader/kstc-8-8b",
    "score": 0.212
  },
  {
    "model": "jaspionjader/slu-2",
    "score": 0.212
  },
  {
    "model": "jaspionjader/slu-22",
    "score": 0.212
  },
  {
    "model": "jeffmeloy/Qwen2.5-7B-minperplexity-2",
    "score": 0.212
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.7-gamma-0.1",
    "score": 0.212
  },
  {
    "model": "jpacifico/Chocolatine-3B-Instruct-DPO-Revised",
    "score": 0.212
  },
  {
    "model": "lalainy/ECE-PRYMMAL-YL-1B-SLERP-V3",
    "score": 0.212
  },
  {
    "model": "lkoenig/BBAI_212_Qwencore",
    "score": 0.212
  },
  {
    "model": "lkoenig/BBAI_7B_Qwen2.5koen",
    "score": 0.212
  },
  {
    "model": "marcuscedricridia/sbr-o1-7b",
    "score": 0.212
  },
  {
    "model": "meditsolutions/Llama-3.2-SUN-1B-chat",
    "score": 0.212
  },
  {
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "score": 0.212
  },
  {
    "model": "microsoft/Phi-3-medium-4k-instruct",
    "score": 0.212
  },
  {
    "model": "mlabonne/NeuralDaredevil-8B-abliterated",
    "score": 0.212
  },
  {
    "model": "mlabonne/NeuralDaredevil-8B-abliterated",
    "score": 0.212
  },
  {
    "model": "netcat420/MFANN-Llama3.1-Abliterated-Slerp-TIES",
    "score": 0.212
  },
  {
    "model": "netcat420/MFANN-llama3.1-abliterated-SLERP-v3.1",
    "score": 0.212
  },
  {
    "model": "netcat420/MFANN-phigments-slerp-V3.3",
    "score": 0.212
  },
  {
    "model": "netcat420/MFANN3bv0.22",
    "score": 0.212
  },
  {
    "model": "newsbang/Homer-7B-v0.1",
    "score": 0.212
  },
  {
    "model": "nlpguy/Lion-Lamarck-v.1.0.9",
    "score": 0.212
  },
  {
    "model": "noname0202/gemma-2-9b-sft-jp-en-zh-v1",
    "score": 0.212
  },
  {
    "model": "ontocord/Llama_3.2_1b-autoredteam_helpfulness-train",
    "score": 0.212
  },
  {
    "model": "ontocord/wide_3b_sft_stage1.2-ss1-expert_math",
    "score": 0.212
  },
  {
    "model": "openai-community/gpt2",
    "score": 0.212
  },
  {
    "model": "openai-community/gpt2",
    "score": 0.212
  },
  {
    "model": "pankajmathur/orca_mini_3b",
    "score": 0.212
  },
  {
    "model": "pankajmathur/orca_mini_v2_7b",
    "score": 0.212
  },
  {
    "model": "pints-ai/1.5-Pints-2K-v0.1",
    "score": 0.212
  },
  {
    "model": "prithivMLmods/Calcium-Opus-14B-Elite",
    "score": 0.212
  },
  {
    "model": "prithivMLmods/Calcium-Opus-14B-Elite",
    "score": 0.212
  },
  {
    "model": "prithivMLmods/Deepthink-Reasoning-7B",
    "score": 0.212
  },
  {
    "model": "prithivMLmods/Magellanic-Qwen-25B-R999",
    "score": 0.212
  },
  {
    "model": "prithivMLmods/QwQ-LCoT2-7B-Instruct",
    "score": 0.212
  },
  {
    "model": "prithivMLmods/Viper-Coder-Hybrid-v1.3",
    "score": 0.212
  },
  {
    "model": "qingy2019/Qwen2.5-Math-14B-Instruct-Pro",
    "score": 0.212
  },
  {
    "model": "qingy2024/Qwen2.6-14B-Instruct",
    "score": 0.212
  },
  {
    "model": "rombodawg/Rombos-LLM-V2.5-Qwen-7b",
    "score": 0.212
  },
  {
    "model": "sarvamai/OpenHathi-7B-Hi-v0.1-Base",
    "score": 0.212
  },
  {
    "model": "sometimesanotion/IF-reasoning-experiment-40",
    "score": 0.212
  },
  {
    "model": "sumink/bbhqwen",
    "score": 0.212
  },
  {
    "model": "sumink/Qwenftmodel",
    "score": 0.212
  },
  {
    "model": "togethercomputer/RedPajama-INCITE-7B-Instruct",
    "score": 0.212
  },
  {
    "model": "vicgalle/ConfigurableHermes-7B",
    "score": 0.212
  },
  {
    "model": "vonjack/SmolLM2-135M-Merged",
    "score": 0.212
  },
  {
    "model": "win10/miscii-14b-1M-0128",
    "score": 0.212
  },
  {
    "model": "yam-peleg/Hebrew-Gemma-11B-Instruct",
    "score": 0.212
  },
  {
    "model": "ycros/BagelMIsteryTour-v2-8x7B",
    "score": 0.212
  },
  {
    "model": "ycros/BagelMIsteryTour-v2-8x7B",
    "score": 0.212
  },
  {
    "model": "meta-llama/Meta-Llama-3-8B-Instruct",
    "score": 0.208
  },
  {
    "model": "BoltMonkey/SuperNeuralDreadDevil-8b",
    "score": 0.208
  },
  {
    "model": "Columbia-NLP/LION-Gemma-2b-odpo-v1.0",
    "score": 0.208
  },
  {
    "model": "CultriX/Qwen2.5-14B-BrocaV9",
    "score": 0.208
  },
  {
    "model": "CultriX/Qwen2.5-14B-Unity",
    "score": 0.208
  },
  {
    "model": "Daemontatox/Llama_cot",
    "score": 0.208
  },
  {
    "model": "Daemontatox/MawaredT1",
    "score": 0.208
  },
  {
    "model": "Daemontatox/Mini_QwQ",
    "score": 0.208
  },
  {
    "model": "Daemontatox/Research_PathfinderAI",
    "score": 0.208
  },
  {
    "model": "DavidAU/L3-DARKEST-PLANET-16.5B",
    "score": 0.208
  },
  {
    "model": "DavieLion/Llama-3.2-1B-SPIN-iter0",
    "score": 0.208
  },
  {
    "model": "DavieLion/Llama-3.2-1B-SPIN-iter0",
    "score": 0.208
  },
  {
    "model": "DeepAutoAI/causal_gpt2",
    "score": 0.208
  },
  {
    "model": "Delta-Vector/Baldur-8B",
    "score": 0.208
  },
  {
    "model": "DreadPoor/Nullsworn-12B-LINEAR",
    "score": 0.208
  },
  {
    "model": "DreadPoor/RPMash-8B-Model_Stock",
    "score": 0.208
  },
  {
    "model": "DreadPoor/Rusted_Platinum-8B-Model_Stock",
    "score": 0.208
  },
  {
    "model": "FlofloB/smollm2-135M_pretrained_800k_fineweb_uncovai_human_removed",
    "score": 0.208
  },
  {
    "model": "GalrionSoftworks/MagnusIntellectus-12B-v1",
    "score": 0.208
  },
  {
    "model": "HeraiHench/Phi-4-slerp-ReasoningRP-14B",
    "score": 0.208
  },
  {
    "model": "IDEA-CCNL/Ziya-LLaMA-13B-v1",
    "score": 0.208
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPOP_5e-6-3ep_0alp_5lam",
    "score": 0.208
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_5e-6-1ep_0alp_0lam",
    "score": 0.208
  },
  {
    "model": "Lawnakk/BBALAW1.0",
    "score": 0.208
  },
  {
    "model": "Lawnakk/BBALAW1.62",
    "score": 0.208
  },
  {
    "model": "LeroyDyer/LCARS_AI_1x4_003_SuperAI",
    "score": 0.208
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_BIBLE_002",
    "score": 0.208
  },
  {
    "model": "Lunzima/NQLSG-Qwen2.5-14B-MegaFusion-v5",
    "score": 0.208
  },
  {
    "model": "MTSAIR/MultiVerse_70B",
    "score": 0.208
  },
  {
    "model": "MultivexAI/Phi-3.5-Mini-Instruct-MultiVex-v0.25-GGUF",
    "score": 0.208
  },
  {
    "model": "NYTK/PULI-LlumiX-32K",
    "score": 0.208
  },
  {
    "model": "Nekochu/Luminia-8B-RP",
    "score": 0.208
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_DoberWild_v2.01",
    "score": 0.208
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_Hermedive_R1_V1.01",
    "score": 0.208
  },
  {
    "model": "NikolaSigmoid/AceMath-1.5B-Instruct-dolphin-r1-200",
    "score": 0.208
  },
  {
    "model": "NousResearch/Hermes-2-Pro-Mistral-7B",
    "score": 0.208
  },
  {
    "model": "NousResearch/Hermes-2-Theta-Llama-3-8B",
    "score": 0.208
  },
  {
    "model": "NucleusAI/nucleus-22B-token-500B",
    "score": 0.208
  },
  {
    "model": "PrimeIntellect/INTELLECT-1",
    "score": 0.208
  },
  {
    "model": "PrimeIntellect/INTELLECT-1",
    "score": 0.208
  },
  {
    "model": "PrimeIntellect/INTELLECT-1-Instruct",
    "score": 0.208
  },
  {
    "model": "Qwen/Qwen2.5-32B",
    "score": 0.208
  },
  {
    "model": "RDson/WomboCombo-R1-Coder-14B-Preview",
    "score": 0.208
  },
  {
    "model": "RLHFlow/ArmoRM-Llama3-8B-v0.1",
    "score": 0.208
  },
  {
    "model": "Replete-AI/Replete-LLM-Qwen2-7b",
    "score": 0.208
  },
  {
    "model": "Replete-AI/Replete-LLM-Qwen2-7b",
    "score": 0.208
  },
  {
    "model": "Replete-AI/Replete-LLM-Qwen2-7b_Beta-Preview",
    "score": 0.208
  },
  {
    "model": "Sakalti/SJT-1.7B",
    "score": 0.208
  },
  {
    "model": "Sakalti/Saba1-7B",
    "score": 0.208
  },
  {
    "model": "Sakalti/Sailor-japanese",
    "score": 0.208
  },
  {
    "model": "Sakalti/SakalFusion-7B-Beta",
    "score": 0.208
  },
  {
    "model": "Sakalti/light-7b-beta",
    "score": 0.208
  },
  {
    "model": "Sakalti/mergekit-01",
    "score": 0.208
  },
  {
    "model": "Sao10K/L3-8B-Niitama-v1",
    "score": 0.208
  },
  {
    "model": "Sao10K/L3-8B-Stheno-v3.2",
    "score": 0.208
  },
  {
    "model": "Sharathhebbar24/SSH_355M",
    "score": 0.208
  },
  {
    "model": "Sharathhebbar24/chat_gpt2_dpo",
    "score": 0.208
  },
  {
    "model": "SicariusSicariiStuff/LLAMA-3_8B_Unaligned_BETA",
    "score": 0.208
  },
  {
    "model": "Sourjayon/DeepSeek-R1-8b-Sify",
    "score": 0.208
  },
  {
    "model": "StelleX/Vorisatex-7B-preview",
    "score": 0.208
  },
  {
    "model": "Supichi/BBAI_250_Xia0_gZ",
    "score": 0.208
  },
  {
    "model": "T145/ZEUS-8B-V7",
    "score": 0.208
  },
  {
    "model": "TinyLlama/TinyLlama-1.1B-Chat-v0.5",
    "score": 0.208
  },
  {
    "model": "TinyLlama/TinyLlama-1.1B-Chat-v0.6",
    "score": 0.208
  },
  {
    "model": "Triangle104/DSR1-Distill-Llama-Lit-8B",
    "score": 0.208
  },
  {
    "model": "Triangle104/Herodotos-14B_V0.1",
    "score": 0.208
  },
  {
    "model": "Triangle104/LThreePointOne-8B-HermesBlackroot",
    "score": 0.208
  },
  {
    "model": "Triangle104/Minerva-10b",
    "score": 0.208
  },
  {
    "model": "Triangle104/Q2.5-Instruct-1M_Harmony",
    "score": 0.208
  },
  {
    "model": "Triangle104/Q2.5-R1-7B",
    "score": 0.208
  },
  {
    "model": "Weyaxi/Bagel-Hermes-34B-Slerp",
    "score": 0.208
  },
  {
    "model": "Weyaxi/Einstein-v8-Llama3.2-1B",
    "score": 0.208
  },
  {
    "model": "ZeroXClem/Llama-3.1-8B-SuperNova-EtherealHermes",
    "score": 0.208
  },
  {
    "model": "ahmeda335/13_outOf_32_pruned_layers_llama3.1-8b",
    "score": 0.208
  },
  {
    "model": "allenai/OLMo-1.7-7B-hf",
    "score": 0.208
  },
  {
    "model": "allknowingroger/Mistralmash1-7B-s",
    "score": 0.208
  },
  {
    "model": "allknowingroger/Qwen2.5-42B-AGI",
    "score": 0.208
  },
  {
    "model": "allknowingroger/Rombos-LLM-V2.5-Qwen-42b",
    "score": 0.208
  },
  {
    "model": "allknowingroger/Weirdslerp2-25B",
    "score": 0.208
  },
  {
    "model": "amd/AMD-Llama-135m",
    "score": 0.208
  },
  {
    "model": "amd/AMD-Llama-135m",
    "score": 0.208
  },
  {
    "model": "anthracite-org/magnum-v4-9b",
    "score": 0.208
  },
  {
    "model": "bamec66557/VICIOUS_MESH-12B-0.1v",
    "score": 0.208
  },
  {
    "model": "bfuzzy1/acheron-c",
    "score": 0.208
  },
  {
    "model": "bunnycore/DeepThinker-7B-Sce-v1",
    "score": 0.208
  },
  {
    "model": "bunnycore/DeepThinker-7B-Sce-v2",
    "score": 0.208
  },
  {
    "model": "bunnycore/FuseQwQen-7B",
    "score": 0.208
  },
  {
    "model": "bunnycore/Qwen-2.5-7b-S1k",
    "score": 0.208
  },
  {
    "model": "bunnycore/Qwen2.5-1.5B-Model-Stock",
    "score": 0.208
  },
  {
    "model": "bunnycore/Qwen2.5-7B-R1-Bespoke-Task",
    "score": 0.208
  },
  {
    "model": "carsenk/flippa-v6",
    "score": 0.208
  },
  {
    "model": "cgato/TheSalt-L3-8b-v0.3.2",
    "score": 0.208
  },
  {
    "model": "chujiezheng/Llama-3-Instruct-8B-SimPO-ExPO",
    "score": 0.208
  },
  {
    "model": "cluebbers/Llama-3.1-8B-paraphrase-type-generation-apty-ipo",
    "score": 0.208
  },
  {
    "model": "cognitivecomputations/dolphin-2.9-llama3-8b",
    "score": 0.208
  },
  {
    "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    "score": 0.208
  },
  {
    "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "score": 0.208
  },
  {
    "model": "distilbert/distilgpt2",
    "score": 0.208
  },
  {
    "model": "dreamgen/WizardLM-2-7B",
    "score": 0.208
  },
  {
    "model": "ehristoforu/fd-lora-merged-16x32",
    "score": 0.208
  },
  {
    "model": "ewre324/Thinker-SmolLM2-135M-Instruct-Reasoning",
    "score": 0.208
  },
  {
    "model": "ewre324/ewre324-R1-SmolLM2-135M-Distill",
    "score": 0.208
  },
  {
    "model": "fblgit/UNA-TheBeagle-7b-v1",
    "score": 0.208
  },
  {
    "model": "formulae/mita-elite-v1.1-7b-2-25-2025",
    "score": 0.208
  },
  {
    "model": "formulae/mita-math-v2.3-2-25-2025",
    "score": 0.208
  },
  {
    "model": "gabrielmbmb/SmolLM-1.7B-Instruct-IFEval",
    "score": 0.208
  },
  {
    "model": "godlikehhd/alpaca_data_ins_ans_max_5200",
    "score": 0.208
  },
  {
    "model": "godlikehhd/alpaca_data_ins_min_5200",
    "score": 0.208
  },
  {
    "model": "godlikehhd/alpaca_data_score_max_0.1_2600",
    "score": 0.208
  },
  {
    "model": "grimjim/Magnolia-v2-12B",
    "score": 0.208
  },
  {
    "model": "h2oai/h2o-danube3-500m-chat",
    "score": 0.208
  },
  {
    "model": "ibivibiv/multimaster-7b-v6",
    "score": 0.208
  },
  {
    "model": "instruction-pretrain/InstructLM-500M",
    "score": 0.208
  },
  {
    "model": "internlm/internlm2_5-1_8b-chat",
    "score": 0.208
  },
  {
    "model": "jaspionjader/Auro-Kosmos-EVAA-v2.3-8B",
    "score": 0.208
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-PRP-v23-8B",
    "score": 0.208
  },
  {
    "model": "jaspionjader/bbb-1",
    "score": 0.208
  },
  {
    "model": "jaspionjader/bh-17",
    "score": 0.208
  },
  {
    "model": "jaspionjader/bh-2",
    "score": 0.208
  },
  {
    "model": "jaspionjader/bh-22",
    "score": 0.208
  },
  {
    "model": "jaspionjader/bh-25",
    "score": 0.208
  },
  {
    "model": "jaspionjader/bh-26",
    "score": 0.208
  },
  {
    "model": "jaspionjader/bh-35",
    "score": 0.208
  },
  {
    "model": "jaspionjader/bh-38",
    "score": 0.208
  },
  {
    "model": "jaspionjader/bh-42",
    "score": 0.208
  },
  {
    "model": "jaspionjader/f-6-8b",
    "score": 0.208
  },
  {
    "model": "jaspionjader/knfp-2-8b",
    "score": 0.208
  },
  {
    "model": "jebish7/qwen2.5-0.5B-IHA-Hin",
    "score": 0.208
  },
  {
    "model": "jeffmeloy/Qwen2.5-7B-nerd-uncensored-v1.5",
    "score": 0.208
  },
  {
    "model": "jeffmeloy/Qwen2.5-7B-nerd-uncensored-v1.4",
    "score": 0.208
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.9-gamma-0.1",
    "score": 0.208
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.7-gamma-0.1",
    "score": 0.208
  },
  {
    "model": "kayfour/T3Q-Qwen2.5-7B-it-KOR-Safe",
    "score": 0.208
  },
  {
    "model": "keeeeenw/MicroLlama",
    "score": 0.208
  },
  {
    "model": "lalainy/ECE-PRYMMAL-0.5B-SLERP-V4",
    "score": 0.208
  },
  {
    "model": "maldv/badger-lambda-llama-3-8b",
    "score": 0.208
  },
  {
    "model": "maldv/badger-writer-llama-3-8b",
    "score": 0.208
  },
  {
    "model": "marcuscedricridia/Qwen2.5-7B-Preview",
    "score": 0.208
  },
  {
    "model": "marcuscedricridia/etr1o-explicit-v1.1",
    "score": 0.208
  },
  {
    "model": "marcuscedricridia/post-cursa-o1",
    "score": 0.208
  },
  {
    "model": "mergekit-community/diabolic6045_ELN-AOC-CAIN",
    "score": 0.208
  },
  {
    "model": "meta-llama/Llama-2-70b-chat-hf",
    "score": 0.208
  },
  {
    "model": "mhl1/Qwen2.5-0.5B-cinstruct-stage1",
    "score": 0.208
  },
  {
    "model": "mkxu/llama-3-8b-po1",
    "score": 0.208
  },
  {
    "model": "mobiuslabsgmbh/DeepSeek-R1-ReDistill-Llama3-8B-v1.1",
    "score": 0.208
  },
  {
    "model": "monsterapi/Llama-3_1-8B-Instruct-orca-ORPO",
    "score": 0.208
  },
  {
    "model": "nbeerbower/mistral-nemo-cc-12B",
    "score": 0.208
  },
  {
    "model": "nbrahme/IndusQ",
    "score": 0.208
  },
  {
    "model": "netcat420/MFANN-phigments-slerp-V2",
    "score": 0.208
  },
  {
    "model": "netcat420/MFANN3bv0.23",
    "score": 0.208
  },
  {
    "model": "netease-youdao/Confucius-o1-14B",
    "score": 0.208
  },
  {
    "model": "nhyha/N3N_Llama-3.1-8B-Instruct_1028_0216",
    "score": 0.208
  },
  {
    "model": "nvidia/AceMath-72B-RM",
    "score": 0.208
  },
  {
    "model": "nxmwxm/Beast-Soul-new",
    "score": 0.208
  },
  {
    "model": "ontocord/merged_0.5_expert_0.5",
    "score": 0.208
  },
  {
    "model": "ontocord/ontocord_wide_7b-stacked-stage1",
    "score": 0.208
  },
  {
    "model": "ontocord/ontocord_wide_7b-stacked-stage1-instruct",
    "score": 0.208
  },
  {
    "model": "ontocord/wide_3b-stage1_shuf_sample1_jsonl-pretrained",
    "score": 0.208
  },
  {
    "model": "ontocord/wide_3b_sft_stage1.1-ss1-with_math.no_issue",
    "score": 0.208
  },
  {
    "model": "oopere/pruned20-llama-1b",
    "score": 0.208
  },
  {
    "model": "oopere/pruned60-llama-3.2-3b",
    "score": 0.208
  },
  {
    "model": "princeton-nlp/Llama-3-Instruct-8B-KTO-v0.2",
    "score": 0.208
  },
  {
    "model": "princeton-nlp/Llama-3-Instruct-8B-RDPO",
    "score": 0.208
  },
  {
    "model": "princeton-nlp/Llama-3-Instruct-8B-SLiC-HF",
    "score": 0.208
  },
  {
    "model": "princeton-nlp/Mistral-7B-Instruct-SLiC-HF",
    "score": 0.208
  },
  {
    "model": "princeton-nlp/Sheared-LLaMA-1.3B",
    "score": 0.208
  },
  {
    "model": "prithivMLmods/Elita-0.1-Distilled-R1-abliterated",
    "score": 0.208
  },
  {
    "model": "prithivMLmods/Omni-Reasoner-Merged",
    "score": 0.208
  },
  {
    "model": "qingy2024/Qwen2.5-Coder-Draft-1.5B-Instruct",
    "score": 0.208
  },
  {
    "model": "rombodawg/Rombos-LLM-V2.5-Qwen-1.5b",
    "score": 0.208
  },
  {
    "model": "rootxhacker/apollo-7B",
    "score": 0.208
  },
  {
    "model": "rwitz/go-bruins-v2",
    "score": 0.208
  },
  {
    "model": "saltlux/luxia-21.4b-alignment-v1.0",
    "score": 0.208
  },
  {
    "model": "securin/Securin-LLM-V2.5-Qwen-1.5B",
    "score": 0.208
  },
  {
    "model": "sometimesanotion/Qwen2.5-7B-Gordion-v0.1",
    "score": 0.208
  },
  {
    "model": "stupidity-ai/Llama-3-8B-Instruct-MultiMoose",
    "score": 0.208
  },
  {
    "model": "suayptalha/Clarus-7B-v0.1",
    "score": 0.208
  },
  {
    "model": "suayptalha/Clarus-7B-v0.2",
    "score": 0.208
  },
  {
    "model": "suayptalha/Maestro-10B",
    "score": 0.208
  },
  {
    "model": "sumink/bbhqwen2",
    "score": 0.208
  },
  {
    "model": "sumink/bbhqwen3",
    "score": 0.208
  },
  {
    "model": "sumink/bbhqwen4",
    "score": 0.208
  },
  {
    "model": "sumink/bbhqwen6",
    "score": 0.208
  },
  {
    "model": "talha2001/Beast-Soul-new",
    "score": 0.208
  },
  {
    "model": "tanliboy/lambda-gemma-2-9b-dpo",
    "score": 0.208
  },
  {
    "model": "tanliboy/lambda-gemma-2-9b-dpo",
    "score": 0.208
  },
  {
    "model": "vicgalle/CarbonBeagle-11B-truthy",
    "score": 0.208
  },
  {
    "model": "winglian/llama-3-8b-256k-PoSE",
    "score": 0.208
  },
  {
    "model": "yanng1242/Marcoro14-7B-slerp",
    "score": 0.208
  },
  {
    "model": "yfzp/Llama-3-8B-Instruct-SPPO-Iter1_bt_8b-table",
    "score": 0.208
  },
  {
    "model": "zake7749/gemma-2-2b-it-chinese-kyara-dpo",
    "score": 0.208
  },
  {
    "model": "ArliAI/Llama-3.1-8B-ArliAI-RPMax-v1.1",
    "score": 0.204
  },
  {
    "model": "BEE-spoke-data/smol_llama-101M-GQA",
    "score": 0.204
  },
  {
    "model": "BEE-spoke-data/Meta-Llama-3-8Bee",
    "score": 0.204
  },
  {
    "model": "BSC-LT/salamandra-7b",
    "score": 0.204
  },
  {
    "model": "BlackBeenie/Neos-Llama-3.1-base",
    "score": 0.204
  },
  {
    "model": "ClaudioItaly/Albacus",
    "score": 0.204
  },
  {
    "model": "ClaudioItaly/Evolutionstory-7B-v2.2",
    "score": 0.204
  },
  {
    "model": "CombinHorizon/huihui-ai-abliteratedV2-Qwen2.5-14B-Inst-BaseMerge-TIES",
    "score": 0.204
  },
  {
    "model": "CultriX/Qwen2.5-14B-Brocav6",
    "score": 0.204
  },
  {
    "model": "CultriX/Qwen2.5-14B-Brocav7",
    "score": 0.204
  },
  {
    "model": "CultriX/Qwen2.5-14B-partialmergept1",
    "score": 0.204
  },
  {
    "model": "Daemontatox/ReasonTest",
    "score": 0.204
  },
  {
    "model": "DavieLion/Llama-3.2-1B-SPIN-iter1",
    "score": 0.204
  },
  {
    "model": "DeepAutoAI/Explore_Llama-3.2-1B-Inst_v1.1",
    "score": 0.204
  },
  {
    "model": "DoppelReflEx/MN-12B-Mimicore-WhiteSnake",
    "score": 0.204
  },
  {
    "model": "DoppelReflEx/MiniusLight-24B-test",
    "score": 0.204
  },
  {
    "model": "DreadPoor/Aspire_V4_ALT-8B-Model_Stock",
    "score": 0.204
  },
  {
    "model": "DreadPoor/BulkUp",
    "score": 0.204
  },
  {
    "model": "DreadPoor/Derivative_V3-8B-Model_Stock",
    "score": 0.204
  },
  {
    "model": "DreadPoor/ONeil-model_stock-8B",
    "score": 0.204
  },
  {
    "model": "DreadPoor/Summer_Dawn-8B-SCE",
    "score": 0.204
  },
  {
    "model": "EpistemeAI/Fireball-Alpaca-Llama3.1.07-8B-Philos-Math-KTO-beta",
    "score": 0.204
  },
  {
    "model": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.004-128K-code-ds-auto",
    "score": 0.204
  },
  {
    "model": "Eric111/CatunaMayo",
    "score": 0.204
  },
  {
    "model": "FlofloB/40k_continued_pretraining_Qwen2.5-0.5B-Instruct_Unsloth_merged_16bit",
    "score": 0.204
  },
  {
    "model": "FlofloB/smollm2-135M_pretrained_1200k_fineweb",
    "score": 0.204
  },
  {
    "model": "FlofloB/smollm2-135M_pretrained_1200k_fineweb_uncovai_selected",
    "score": 0.204
  },
  {
    "model": "FlofloB/smollm2-135M_pretrained_400k_fineweb",
    "score": 0.204
  },
  {
    "model": "Gryphe/Pantheon-RP-1.6-12b-Nemo",
    "score": 0.204
  },
  {
    "model": "HuggingFaceTB/SmolLM-135M-Instruct",
    "score": 0.204
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-1e-5",
    "score": 0.204
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-4-2ep",
    "score": 0.204
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_3e-6-2ep_0alp_0lam",
    "score": 0.204
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-IRPO_5e-6-1ep_1alp_0lam",
    "score": 0.204
  },
  {
    "model": "Josephgflowers/TinyLlama_v1.1_math_code-world-test-1",
    "score": 0.204
  },
  {
    "model": "Lawnakk/BBALAW1.64",
    "score": 0.204
  },
  {
    "model": "LeroyDyer/CheckPoint_C",
    "score": 0.204
  },
  {
    "model": "LeroyDyer/SpydazWeb_AI_HumanAGI_002",
    "score": 0.204
  },
  {
    "model": "LeroyDyer/SpydazWeb_AI_HumanAI_006",
    "score": 0.204
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_14",
    "score": 0.204
  },
  {
    "model": "Locutusque/Llama-3-NeuralHercules-5.0-8B",
    "score": 0.204
  },
  {
    "model": "MaziyarPanahi/calme-2.3-phi3-4b",
    "score": 0.204
  },
  {
    "model": "MrRobotoAI/MrRoboto-ProLong-8b-v4i",
    "score": 0.204
  },
  {
    "model": "NAPS-ai/naps-llama3.1-70B-v0.2-fp16",
    "score": 0.204
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_DodoWild_v2.01",
    "score": 0.204
  },
  {
    "model": "Nexesenex/Llama_3.2_1b_Synopsys_0.1",
    "score": 0.204
  },
  {
    "model": "OpenLeecher/llama3-8b-lima",
    "score": 0.204
  },
  {
    "model": "Qwen/Qwen1.5-0.5B-Chat",
    "score": 0.204
  },
  {
    "model": "Qwen/Qwen2.5-1.5B",
    "score": 0.204
  },
  {
    "model": "RWKV/rwkv-raven-14b",
    "score": 0.204
  },
  {
    "model": "RubielLabarta/LogoS-7Bx2-MoE-13B-v0.2",
    "score": 0.204
  },
  {
    "model": "Sakalti/SJT-7B-V1.1-Multilingal",
    "score": 0.204
  },
  {
    "model": "Sakalti/SakalFusion-7B-Alpha",
    "score": 0.204
  },
  {
    "model": "SentientAGI/Dobby-Mini-Unhinged-Llama-3.1-8B",
    "score": 0.204
  },
  {
    "model": "Sicarius-Prototyping/Micropenis_1B",
    "score": 0.204
  },
  {
    "model": "SkyOrbis/SKY-Ko-Llama3.2-1B-lora-epoch3",
    "score": 0.204
  },
  {
    "model": "Solshine/Llama-3-1-big-thoughtful-passthrough-merge-2",
    "score": 0.204
  },
  {
    "model": "Stark2008/LayleleFlamPi",
    "score": 0.204
  },
  {
    "model": "T145/KRONOS-8B-V1-P2",
    "score": 0.204
  },
  {
    "model": "TIGER-Lab/MAmmoTH2-7B-Plus",
    "score": 0.204
  },
  {
    "model": "Tremontaine/L3-12B-Lunaris-v1",
    "score": 0.204
  },
  {
    "model": "Triangle104/Hermes3-L3.1-DirtyHarry-8B",
    "score": 0.204
  },
  {
    "model": "Tsunami-th/Tsunami-1.0-7B-Instruct",
    "score": 0.204
  },
  {
    "model": "Youlln/ECE-PRYMMAL-0.5B-FT-V3",
    "score": 0.204
  },
  {
    "model": "ZeroXClem/Qwen2.5-7B-HomerAnvita-NerdMix",
    "score": 0.204
  },
  {
    "model": "akhadangi/Llama3.2.1B.0.1-Last",
    "score": 0.204
  },
  {
    "model": "allknowingroger/HomerSlerp3-7B",
    "score": 0.204
  },
  {
    "model": "allknowingroger/Llama3.1-60B",
    "score": 0.204
  },
  {
    "model": "allknowingroger/Quen2-65B",
    "score": 0.204
  },
  {
    "model": "allknowingroger/Qwenslerp2-7B",
    "score": 0.204
  },
  {
    "model": "allknowingroger/WestlakeMaziyar-7B-slerp",
    "score": 0.204
  },
  {
    "model": "allknowingroger/Yi-1.5-34B",
    "score": 0.204
  },
  {
    "model": "allknowingroger/Yillama-40B",
    "score": 0.204
  },
  {
    "model": "braindao/DeepSeek-R1-Distill-Qwen-14B",
    "score": 0.204
  },
  {
    "model": "braindao/Qwen2.5-14B",
    "score": 0.204
  },
  {
    "model": "darkc0de/BuddyGlass_v0.3_Xortron7MethedUpSwitchedUp",
    "score": 0.204
  },
  {
    "model": "databricks/dolly-v2-12b",
    "score": 0.204
  },
  {
    "model": "deepseek-ai/deepseek-llm-67b-chat",
    "score": 0.204
  },
  {
    "model": "dfurman/Llama-3-8B-Orpo-v0.1",
    "score": 0.204
  },
  {
    "model": "dfurman/Llama-3-8B-Orpo-v0.1",
    "score": 0.204
  },
  {
    "model": "duyhv1411/Llama-3.2-1B-en-vi",
    "score": 0.204
  },
  {
    "model": "duyhv1411/Llama-3.2-3B-en-vi",
    "score": 0.204
  },
  {
    "model": "ehristoforu/frqwen2.5-from7b-it",
    "score": 0.204
  },
  {
    "model": "ehristoforu/testq-32b",
    "score": 0.204
  },
  {
    "model": "ehristoforu/ruphi-4b",
    "score": 0.204
  },
  {
    "model": "elinas/Chronos-Gold-12B-1.0",
    "score": 0.204
  },
  {
    "model": "ewre324/Thinker-Qwen2.5-0.5B-Instruct-Reasoning",
    "score": 0.204
  },
  {
    "model": "fhai50032/RolePlayLake-7B",
    "score": 0.204
  },
  {
    "model": "flammenai/Mahou-1.2a-mistral-7B",
    "score": 0.204
  },
  {
    "model": "formulae/mita-elite-v1.1-gen2-7b-2-25-2025",
    "score": 0.204
  },
  {
    "model": "godlikehhd/alpaca_data_score_max_0.7_2600",
    "score": 0.204
  },
  {
    "model": "godlikehhd/alpaca_data_score_max_5200",
    "score": 0.204
  },
  {
    "model": "godlikehhd/ifd_2500_qwen",
    "score": 0.204
  },
  {
    "model": "godlikehhd/ifd_new_qwen_2500",
    "score": 0.204
  },
  {
    "model": "google/switch-base-8",
    "score": 0.204
  },
  {
    "model": "grimjim/Magnolia-v1-Gemma2-8k-9B",
    "score": 0.204
  },
  {
    "model": "grimjim/llama-3-Nephilim-v2.1-8B",
    "score": 0.204
  },
  {
    "model": "hotmailuser/QwenSparse-7B",
    "score": 0.204
  },
  {
    "model": "huihui-ai/DeepSeek-R1-Distill-Qwen-14B-abliterated-v2",
    "score": 0.204
  },
  {
    "model": "iRyanBell/ARC1-II",
    "score": 0.204
  },
  {
    "model": "ibm-granite/granite-3.0-3b-a800m-base",
    "score": 0.204
  },
  {
    "model": "icefog72/Ice0.70.1-01.02-RP",
    "score": 0.204
  },
  {
    "model": "icefog72/Ice0.80-03.02-RP",
    "score": 0.204
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-PRP-8B",
    "score": 0.204
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-TSN-v20-8B",
    "score": 0.204
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-v9-TitanFusion-Mix-8B",
    "score": 0.204
  },
  {
    "model": "jaspionjader/bh-10",
    "score": 0.204
  },
  {
    "model": "jaspionjader/bh-20",
    "score": 0.204
  },
  {
    "model": "jaspionjader/bh-19",
    "score": 0.204
  },
  {
    "model": "jaspionjader/bh-23",
    "score": 0.204
  },
  {
    "model": "jaspionjader/bh-29",
    "score": 0.204
  },
  {
    "model": "jaspionjader/bh-5",
    "score": 0.204
  },
  {
    "model": "jaspionjader/bh-8",
    "score": 0.204
  },
  {
    "model": "jaspionjader/bh-9",
    "score": 0.204
  },
  {
    "model": "jaspionjader/slu-10",
    "score": 0.204
  },
  {
    "model": "jaspionjader/slu-14",
    "score": 0.204
  },
  {
    "model": "jaspionjader/slu-6",
    "score": 0.204
  },
  {
    "model": "jeffmeloy/Qwen2.5-7B-nerd-uncensored-v1.1",
    "score": 0.204
  },
  {
    "model": "jeffmeloy/Qwen2.5-7B-nerd-uncensored-v1.7",
    "score": 0.204
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.9-gamma-0.01",
    "score": 0.204
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.1-gamma-0.01",
    "score": 0.204
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.3-gamma-0.01",
    "score": 0.204
  },
  {
    "model": "kevin009/llamaRAGdrama",
    "score": 0.204
  },
  {
    "model": "khoantap/llama-linear-1-0.5-0.5-merge",
    "score": 0.204
  },
  {
    "model": "maldv/badger-mu-llama-3-8b",
    "score": 0.204
  },
  {
    "model": "marcuscedricridia/Hush-Qwen2.5-7B-RP-v1.4-1M",
    "score": 0.204
  },
  {
    "model": "marcuscedricridia/etr1o-v1.1",
    "score": 0.204
  },
  {
    "model": "mrdayl/OpenThink",
    "score": 0.204
  },
  {
    "model": "netcat420/MFANNv0.23",
    "score": 0.204
  },
  {
    "model": "netcat420/Qwen2.5-7B-nerd-uncensored-v0.9-MFANN",
    "score": 0.204
  },
  {
    "model": "newsbang/Homer-7B-v0.2",
    "score": 0.204
  },
  {
    "model": "nlpguy/Mistral-NeMo-Minitron-Upscale-v2",
    "score": 0.204
  },
  {
    "model": "nlpguy/Mistral-NeMo-Minitron-Upscale-v3",
    "score": 0.204
  },
  {
    "model": "nothingiisreal/MN-12B-Starcannon-v3",
    "score": 0.204
  },
  {
    "model": "nvidia/Minitron-4B-Base",
    "score": 0.204
  },
  {
    "model": "ontocord/wide_3b_sft_stage1.2-ss1-expert_news",
    "score": 0.204
  },
  {
    "model": "openai-community/gpt2-large",
    "score": 0.204
  },
  {
    "model": "pankajmathur/orca_mini_v6_8b",
    "score": 0.204
  },
  {
    "model": "postbot/gpt2-medium-emailgen",
    "score": 0.204
  },
  {
    "model": "prithivMLmods/QwQ-LCoT-14B-Conversational",
    "score": 0.204
  },
  {
    "model": "prithivMLmods/QwQ-LCoT-7B-Instruct",
    "score": 0.204
  },
  {
    "model": "pszemraj/Mistral-v0.3-6B",
    "score": 0.204
  },
  {
    "model": "qingy2024/QwQ-14B-Math-v0.2",
    "score": 0.204
  },
  {
    "model": "qingy2024/Qwen2.5-Math-14B-Instruct-Alpha",
    "score": 0.204
  },
  {
    "model": "rhplus0831/maid-yuzu-v7",
    "score": 0.204
  },
  {
    "model": "saltlux/luxia-21.4b-alignment-v1.2",
    "score": 0.204
  },
  {
    "model": "sci-m-wang/Mistral-7B-Instruct-sa-v0.1",
    "score": 0.204
  },
  {
    "model": "sci-m-wang/deepseek-llm-7b-chat-sa-v0.1",
    "score": 0.204
  },
  {
    "model": "sequelbox/Llama3.1-8B-PlumMath",
    "score": 0.204
  },
  {
    "model": "sethuiyer/Llama-3.1-8B-Experimental-1206-Instruct",
    "score": 0.204
  },
  {
    "model": "suayptalha/HomerCreativeAnvita-Mix-Qw7B",
    "score": 0.204
  },
  {
    "model": "tangledgroup/tangled-llama-pints-1.5b-v0.2-instruct",
    "score": 0.204
  },
  {
    "model": "tannedbum/L3-Nymeria-Maid-8B",
    "score": 0.204
  },
  {
    "model": "tiiuae/falcon-11B",
    "score": 0.204
  },
  {
    "model": "tiiuae/falcon-7b",
    "score": 0.204
  },
  {
    "model": "togethercomputer/RedPajama-INCITE-Chat-3B-v1",
    "score": 0.204
  },
  {
    "model": "unsloth/Llama-3.2-1B-Instruct",
    "score": 0.204
  },
  {
    "model": "win10/Breeze-13B-32k-Instruct-v1_0",
    "score": 0.204
  },
  {
    "model": "xukp20/Llama-3-8B-Instruct-SPPO-Iter3_bt_2b-table",
    "score": 0.204
  },
  {
    "model": "xukp20/Llama-3-8B-Instruct-SPPO-score-Iter3_bt_2b-table-0.001",
    "score": 0.204
  },
  {
    "model": "yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_bt_8b-table-0.002",
    "score": 0.204
  },
  {
    "model": "zelk12/Test01012025155054",
    "score": 0.204
  },
  {
    "model": "zelk12/Test01012025155054t0.5_gemma-2",
    "score": 0.204
  },
  {
    "model": "AALF/FuseChat-Llama-3.1-8B-SFT-preview",
    "score": 0.2
  },
  {
    "model": "AGI-0/Art-v0-3B",
    "score": 0.2
  },
  {
    "model": "Alepach/notHumpback-M1",
    "score": 0.2
  },
  {
    "model": "Alibaba-NLP/gte-Qwen2-7B-instruct",
    "score": 0.2
  },
  {
    "model": "Artples/L-MChat-Small",
    "score": 0.2
  },
  {
    "model": "BEE-spoke-data/smol_llama-220M-GQA",
    "score": 0.2
  },
  {
    "model": "BEE-spoke-data/smol_llama-220M-GQA-fineweb_edu",
    "score": 0.2
  },
  {
    "model": "BEE-spoke-data/smol_llama-220M-openhermes",
    "score": 0.2
  },
  {
    "model": "Ba2han/Llama-Phi-3_DoRA",
    "score": 0.2
  },
  {
    "model": "BrainWave-ML/llama3.2-3B-maths-orpo",
    "score": 0.2
  },
  {
    "model": "CohereForAI/c4ai-command-r-v01",
    "score": 0.2
  },
  {
    "model": "CreitinGameplays/Llama-3.1-8B-R1-v0.1",
    "score": 0.2
  },
  {
    "model": "Daemontatox/CogitoDistil",
    "score": 0.2
  },
  {
    "model": "DavieLion/Llama-3.2-1B-SPIN-iter3",
    "score": 0.2
  },
  {
    "model": "DavieLion/Llama-3.2-1B-SPIN-iter3",
    "score": 0.2
  },
  {
    "model": "DeepAutoAI/d2nwg_causal_gpt2",
    "score": 0.2
  },
  {
    "model": "DeepMount00/Qwen2.5-7B-Instruct-MathCoder",
    "score": 0.2
  },
  {
    "model": "DeepMount00/mergekit-ties-okvgjfz",
    "score": 0.2
  },
  {
    "model": "Delta-Vector/Control-8B-V1.1",
    "score": 0.2
  },
  {
    "model": "Delta-Vector/Odin-9B",
    "score": 0.2
  },
  {
    "model": "DoppelReflEx/MN-12B-Mimicore-Orochi-v4-Experiment",
    "score": 0.2
  },
  {
    "model": "DoppelReflEx/MN-12B-Unleashed-Twilight",
    "score": 0.2
  },
  {
    "model": "DreadPoor/Again-8B-Model_Stock",
    "score": 0.2
  },
  {
    "model": "DreadPoor/RPMash_V3-8B-Model_Stock",
    "score": 0.2
  },
  {
    "model": "DreadPoor/TEST02-Ignore",
    "score": 0.2
  },
  {
    "model": "EleutherAI/pythia-1b",
    "score": 0.2
  },
  {
    "model": "Enno-Ai/EnnoAi-Pro-French-Llama-3-8B-v0.4",
    "score": 0.2
  },
  {
    "model": "Enno-Ai/EnnoAi-Pro-Llama-3-8B-v0.3",
    "score": 0.2
  },
  {
    "model": "EnnoAi/EnnoAi-7B-French-Instruct-202502",
    "score": 0.2
  },
  {
    "model": "EpistemeAI/Reasoning-Llama-3.2-1B-Instruct-v1.3",
    "score": 0.2
  },
  {
    "model": "Eric111/CatunaMayo-DPO",
    "score": 0.2
  },
  {
    "model": "FINGU-AI/Ultimos-32B",
    "score": 0.2
  },
  {
    "model": "Felladrin/Llama-160M-Chat-v1",
    "score": 0.2
  },
  {
    "model": "Felladrin/Minueza-32M-UltraChat",
    "score": 0.2
  },
  {
    "model": "FlofloB/10k_continued_pretraining_Qwen2.5-0.5B-Instruct_Unsloth_merged_16bit",
    "score": 0.2
  },
  {
    "model": "FlofloB/smollm2-135M_pretrained_200k_fineweb_uncovai_selected",
    "score": 0.2
  },
  {
    "model": "FlofloB/smollm2-135M_pretrained_800k_fineweb",
    "score": 0.2
  },
  {
    "model": "FlofloB/smollm2_pretrained_200k_fineweb",
    "score": 0.2
  },
  {
    "model": "HeraiHench/Marge-Qwen-Math-7B",
    "score": 0.2
  },
  {
    "model": "HuggingFaceTB/SmolLM-1.7B-Instruct",
    "score": 0.2
  },
  {
    "model": "HuggingFaceTB/SmolLM-360M-Instruct",
    "score": 0.2
  },
  {
    "model": "INSAIT-Institute/BgGPT-Gemma-2-27B-IT-v1.0",
    "score": 0.2
  },
  {
    "model": "Invalid-Null/PeiYangMe-0.7",
    "score": 0.2
  },
  {
    "model": "JayHyeon/Qwen-0.5B-IRPO-5epoch",
    "score": 0.2
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_3e-6-1ep_0alp_0lam",
    "score": 0.2
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_5e-6-3ep_0alp_0lam",
    "score": 0.2
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-7e-5-5ep",
    "score": 0.2
  },
  {
    "model": "JayHyeon/Qwen_0.5-IRPO_3e-6-1ep_1alp_0lam",
    "score": 0.2
  },
  {
    "model": "JayHyeon/Qwen_0.5-MDPO_0.1_3e-6-3ep_0alp_0lam",
    "score": 0.2
  },
  {
    "model": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-bert_p-beta10-gamma0.3-lr1.0e-6-scale-log",
    "score": 0.2
  },
  {
    "model": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-rouge2-beta10-gamma0.3-lr1.0e-6-scale-log",
    "score": 0.2
  },
  {
    "model": "Josephgflowers/Differential-Attention-Liquid-Metal-Tinyllama",
    "score": 0.2
  },
  {
    "model": "Josephgflowers/Tinyllama-STEM-Cinder-Agent-v1",
    "score": 0.2
  },
  {
    "model": "KingNish/qwen-1b-continued-v2.1",
    "score": 0.2
  },
  {
    "model": "Lawnakk/BBALAW1.3",
    "score": 0.2
  },
  {
    "model": "LenguajeNaturalAI/leniachat-qwen2-1.5B-v0",
    "score": 0.2
  },
  {
    "model": "LeroyDyer/Mixtral_AI_SwahiliTron_7b",
    "score": 0.2
  },
  {
    "model": "LeroyDyer/SpydazWeb_AI_HumanAI_012_INSTRUCT_IA",
    "score": 0.2
  },
  {
    "model": "LeroyDyer/SpydazWeb_AI_HumanAI_012_INSTRUCT_IA",
    "score": 0.2
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_OmG_Math",
    "score": 0.2
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_ChatML_002",
    "score": 0.2
  },
  {
    "model": "Lil-R/2_PRYMMAL-ECE-7B-SLERP-V1",
    "score": 0.2
  },
  {
    "model": "Lil-R/2_PRYMMAL-ECE-7B-SLERP-V2",
    "score": 0.2
  },
  {
    "model": "Lil-R/2_PRYMMAL-ECE-7B-SLERP-V3",
    "score": 0.2
  },
  {
    "model": "Lyte/Llama-3.2-1B-Instruct-COT-RL-Expriement1-EP04",
    "score": 0.2
  },
  {
    "model": "Mxode/NanoLM-0.3B-Instruct-v2",
    "score": 0.2
  },
  {
    "model": "Mxode/NanoLM-0.3B-Instruct-v1.1",
    "score": 0.2
  },
  {
    "model": "Mxode/NanoLM-1B-Instruct-v1.1",
    "score": 0.2
  },
  {
    "model": "Mxode/NanoLM-1B-Instruct-v2",
    "score": 0.2
  },
  {
    "model": "NAPS-ai/naps-gemma-2-27b-v0.1.0",
    "score": 0.2
  },
  {
    "model": "NAPS-ai/naps-gemma-2-27b-v-0.1.0",
    "score": 0.2
  },
  {
    "model": "NLPark/AnFeng_v3.1-Avocet",
    "score": 0.2
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_Mediver_V1.01",
    "score": 0.2
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_Smarteaz_0.2_R1",
    "score": 0.2
  },
  {
    "model": "Nexesenex/Llama_3.2_1b_Odyssea_V1",
    "score": 0.2
  },
  {
    "model": "Nexesenex/Llama_3.2_1b_Odyssea_V1.01",
    "score": 0.2
  },
  {
    "model": "Nexesenex/Llama_3.2_1b_Synopsys_0.11",
    "score": 0.2
  },
  {
    "model": "Novaciano/ASTAROTH-3.2-1B",
    "score": 0.2
  },
  {
    "model": "OnlyCheeini/greesychat-turbo",
    "score": 0.2
  },
  {
    "model": "PranavHarshan/MedNarra-X1",
    "score": 0.2
  },
  {
    "model": "PuxAI/LUA_model",
    "score": 0.2
  },
  {
    "model": "PygmalionAI/pygmalion-6b",
    "score": 0.2
  },
  {
    "model": "Qwen/QwQ-32B",
    "score": 0.2
  },
  {
    "model": "Qwen/Qwen1.5-32B-Chat",
    "score": 0.2
  },
  {
    "model": "Qwen/Qwen2-0.5B-Instruct",
    "score": 0.2
  },
  {
    "model": "Qwen/Qwen2-57B-A14B-Instruct",
    "score": 0.2
  },
  {
    "model": "Qwen/Qwen2-Math-7B",
    "score": 0.2
  },
  {
    "model": "RLHFlow/LLaMA3-iterative-DPO-final",
    "score": 0.2
  },
  {
    "model": "Sakalti/SJT-1.5B-Alpha-1.1",
    "score": 0.2
  },
  {
    "model": "Sakalti/SJT-2B",
    "score": 0.2
  },
  {
    "model": "Sakalti/SJT-3.7B",
    "score": 0.2
  },
  {
    "model": "Sakalti/mergekit-della_linear-vmeykci",
    "score": 0.2
  },
  {
    "model": "Solshine/Brimful-merged-replete",
    "score": 0.2
  },
  {
    "model": "Supichi/BBA-123",
    "score": 0.2
  },
  {
    "model": "T145/Llama-3.1-8B-Zeus",
    "score": 0.2
  },
  {
    "model": "THUDM/glm-4-9b-chat",
    "score": 0.2
  },
  {
    "model": "TIGER-Lab/AceCodeRM-7B",
    "score": 0.2
  },
  {
    "model": "TeeZee/DoubleBagel-57B-v1.0",
    "score": 0.2
  },
  {
    "model": "Telugu-LLM-Labs/Indic-gemma-2b-finetuned-sft-Navarasa-2.0",
    "score": 0.2
  },
  {
    "model": "TheDrummer/Llama-3SOME-8B-v2",
    "score": 0.2
  },
  {
    "model": "TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T",
    "score": 0.2
  },
  {
    "model": "Triangle104/DS-Distilled-Hermes-Llama-3.1",
    "score": 0.2
  },
  {
    "model": "Triangle104/L3.1-8B-Dusky-Ink_v0.r1",
    "score": 0.2
  },
  {
    "model": "Triangle104/LThreePointOne-8B-HermesInk",
    "score": 0.2
  },
  {
    "model": "Triangle104/Pans_Gutenbergum_V0.2",
    "score": 0.2
  },
  {
    "model": "Tsunami-th/Tsunami-0.5-7B-Instruct",
    "score": 0.2
  },
  {
    "model": "ValiantLabs/Llama3.1-8B-Cobalt",
    "score": 0.2
  },
  {
    "model": "ValiantLabs/Llama3.1-8B-Cobalt",
    "score": 0.2
  },
  {
    "model": "Vikhrmodels/Vikhr-Nemo-12B-Instruct-R-21-09-24",
    "score": 0.2
  },
  {
    "model": "WizardLMTeam/WizardLM-13B-V1.0",
    "score": 0.2
  },
  {
    "model": "Xiaojian9992024/Phi-4-mini-UNOFFICAL",
    "score": 0.2
  },
  {
    "model": "Xiaojian9992024/Qwen2.5-7B-MS-Destroyer",
    "score": 0.2
  },
  {
    "model": "Xiaojian9992024/Qwen2.5-Ultra-1.5B-25.02-Exp",
    "score": 0.2
  },
  {
    "model": "Youlln/ECE-PRYMMAL-YL-1B-SLERP-V1",
    "score": 0.2
  },
  {
    "model": "Youlln/ECE-PRYMMAL-YL-1B-SLERP-V2",
    "score": 0.2
  },
  {
    "model": "abhishek/autotrain-llama3-70b-orpo-v2",
    "score": 0.2
  },
  {
    "model": "adriszmar/QAIMath-Qwen2.5-7B-TIES",
    "score": 0.2
  },
  {
    "model": "adriszmar/QAIMath-Qwen2.5-7B-TIES",
    "score": 0.2
  },
  {
    "model": "aixonlab/Aether-12b",
    "score": 0.2
  },
  {
    "model": "allknowingroger/Gemma2Slerp1-2.6B",
    "score": 0.2
  },
  {
    "model": "allknowingroger/Mistralmash2-7B-s",
    "score": 0.2
  },
  {
    "model": "allknowingroger/MultiCalm-7B-slerp",
    "score": 0.2
  },
  {
    "model": "allknowingroger/MultiMash11-13B-slerp",
    "score": 0.2
  },
  {
    "model": "allknowingroger/MultiMash2-12B-slerp",
    "score": 0.2
  },
  {
    "model": "allknowingroger/MultiMash6-12B-slerp",
    "score": 0.2
  },
  {
    "model": "allknowingroger/MultiMash8-13B-slerp",
    "score": 0.2
  },
  {
    "model": "allknowingroger/Multimash3-12B-slerp",
    "score": 0.2
  },
  {
    "model": "allknowingroger/Multimerge-19B-pass",
    "score": 0.2
  },
  {
    "model": "allknowingroger/Neuralmultiverse-7B-slerp",
    "score": 0.2
  },
  {
    "model": "anthracite-org/magnum-v2-12b",
    "score": 0.2
  },
  {
    "model": "anthracite-org/magnum-v2.5-12b-kto",
    "score": 0.2
  },
  {
    "model": "assskelad/smollm2-360M-sft_SmallThoughts",
    "score": 0.2
  },
  {
    "model": "bamec66557/MISCHIEVOUS-12B-Mix_III_ex_V",
    "score": 0.2
  },
  {
    "model": "belztjti/dffghgjh",
    "score": 0.2
  },
  {
    "model": "bfuzzy1/acheron-m1a-llama",
    "score": 0.2
  },
  {
    "model": "braindao/DeepSeek-R1-Distill-Qwen-1.5B-Reflective",
    "score": 0.2
  },
  {
    "model": "braindao/DeepSeek-R1-Distill-Qwen-14B-Blunt-Uncensored-Reflective",
    "score": 0.2
  },
  {
    "model": "braindao/DeepSeek-R1-Distill-Qwen-14B-Blunt-Uncensored-Blunt-Reflective",
    "score": 0.2
  },
  {
    "model": "braindao/DeepSeek-R1-Distill-Qwen-14B-Reflective",
    "score": 0.2
  },
  {
    "model": "braindao/DeepSeek-R1-Distill-Qwen-7B-ORPO-Uncensored",
    "score": 0.2
  },
  {
    "model": "brgx53/Barracuda-PRYMMAL-ECE-TW3",
    "score": 0.2
  },
  {
    "model": "bunnycore/QwenMosaic-7B",
    "score": 0.2
  },
  {
    "model": "cpayne1303/cp2024",
    "score": 0.2
  },
  {
    "model": "cpayne1303/cp2024-instruct",
    "score": 0.2
  },
  {
    "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
    "score": 0.2
  },
  {
    "model": "djuna/G2-GSHT",
    "score": 0.2
  },
  {
    "model": "djuna/MN-Chinofun-12B-4",
    "score": 0.2
  },
  {
    "model": "dnhkng/RYS-Llama-3-8B-Instruct",
    "score": 0.2
  },
  {
    "model": "ehristoforu/Falcon3-8B-Franken-Basestruct",
    "score": 0.2
  },
  {
    "model": "ehristoforu/Falcon3-MoE-2x7B-Insruct",
    "score": 0.2
  },
  {
    "model": "fblgit/cybertron-v4-qw7B-MGS",
    "score": 0.2
  },
  {
    "model": "formulae/mita-gen3-7b-2-26-2025",
    "score": 0.2
  },
  {
    "model": "formulae/mita-gen3-v1.2-7b-2-26-2025",
    "score": 0.2
  },
  {
    "model": "formulae/mita-v1.1-7b-2-24-2025",
    "score": 0.2
  },
  {
    "model": "fulim/FineLlama-3.1-8B",
    "score": 0.2
  },
  {
    "model": "gaverfraxz/Meta-Llama-3.1-8B-Instruct-HalfAbliterated-TIES",
    "score": 0.2
  },
  {
    "model": "google/recurrentgemma-2b-it",
    "score": 0.2
  },
  {
    "model": "h2oai/h2o-danube3-4b-chat",
    "score": 0.2
  },
  {
    "model": "hotmailuser/Deepseek-qwen-modelstock-2B",
    "score": 0.2
  },
  {
    "model": "hotmailuser/QwenSlerp3-14B",
    "score": 0.2
  },
  {
    "model": "hotmailuser/QwenStock-0.5B",
    "score": 0.2
  },
  {
    "model": "icefog72/IceTea21EnergyDrinkRPV13-DPOv3.5",
    "score": 0.2
  },
  {
    "model": "internlm/internlm2-1_8b",
    "score": 0.2
  },
  {
    "model": "internlm/internlm2-7b",
    "score": 0.2
  },
  {
    "model": "internlm/internlm2-chat-1_8b",
    "score": 0.2
  },
  {
    "model": "jaredjoss/pythia-410m-roberta-lr_8e7-kl_01-steps_12000-rlhf-model",
    "score": 0.2
  },
  {
    "model": "jaspionjader/PRP-Kosmos-EVAA-light-8B",
    "score": 0.2
  },
  {
    "model": "jaspionjader/bh-15",
    "score": 0.2
  },
  {
    "model": "jaspionjader/bh-16",
    "score": 0.2
  },
  {
    "model": "jaspionjader/bh-31",
    "score": 0.2
  },
  {
    "model": "jaspionjader/kstc-6-8b",
    "score": 0.2
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.1-gamma-0.01",
    "score": 0.2
  },
  {
    "model": "khoantap/llama-linear-0.5-1-0.5-merge",
    "score": 0.2
  },
  {
    "model": "lalainy/ECE-PRYMMAL-0.5B-FT-V5-MUSR",
    "score": 0.2
  },
  {
    "model": "lalainy/ECE-PRYMMAL-YL-1B-SLERP-V4",
    "score": 0.2
  },
  {
    "model": "lt-asset/nova-1.3b",
    "score": 0.2
  },
  {
    "model": "macadeliccc/magistrate-3.2-3b-base",
    "score": 0.2
  },
  {
    "model": "macadeliccc/magistrate-3.2-3b-it",
    "score": 0.2
  },
  {
    "model": "marcuscedricridia/Hush-Qwen2.5-7B-MST",
    "score": 0.2
  },
  {
    "model": "marcuscedricridia/etr1o-explicit-v1.2",
    "score": 0.2
  },
  {
    "model": "marcuscedricridia/olmner-o1-7b",
    "score": 0.2
  },
  {
    "model": "matouLeLoup/ECE-PRYMMAL-0.5B-FT-V5-MUSR-Mathis",
    "score": 0.2
  },
  {
    "model": "meta-llama/Llama-2-13b-chat-hf",
    "score": 0.2
  },
  {
    "model": "microsoft/Phi-3-mini-128k-instruct",
    "score": 0.2
  },
  {
    "model": "microsoft/Phi-3-mini-4k-instruct",
    "score": 0.2
  },
  {
    "model": "microsoft/Phi-3-mini-4k-instruct",
    "score": 0.2
  },
  {
    "model": "microsoft/phi-1",
    "score": 0.2
  },
  {
    "model": "mistral-community/mixtral-8x22B-v0.3",
    "score": 0.2
  },
  {
    "model": "mixtao/MixTAO-7Bx2-MoE-v8.1",
    "score": 0.2
  },
  {
    "model": "mkurman/phi4-MedIT-10B-o1",
    "score": 0.2
  },
  {
    "model": "nazimali/Mistral-Nemo-Kurdish",
    "score": 0.2
  },
  {
    "model": "nbeerbower/Nemo-Loony-12B-experimental",
    "score": 0.2
  },
  {
    "model": "nbeerbower/SmolNemo-12B-FFT-experimental",
    "score": 0.2
  },
  {
    "model": "nbeerbower/mistral-nemo-gutenberg-12B-v3",
    "score": 0.2
  },
  {
    "model": "nbeerbower/mistral-nemo-narwhal-12B",
    "score": 0.2
  },
  {
    "model": "necva/IE-cont-Llama3.1-8B",
    "score": 0.2
  },
  {
    "model": "netcat420/MFANN-Llama3.1-Abliterated-SLERP-V4",
    "score": 0.2
  },
  {
    "model": "netcat420/MFANN-llama3.1-abliterated-v2",
    "score": 0.2
  },
  {
    "model": "netcat420/Qwen2.5-7b-nerd-uncensored-MFANN-slerp",
    "score": 0.2
  },
  {
    "model": "newsbang/Homer-v0.5-Qwen2.5-7B",
    "score": 0.2
  },
  {
    "model": "nvidia/AceMath-7B-RM",
    "score": 0.2
  },
  {
    "model": "ontocord/merged_0.2_expert_0.8-stack_2x",
    "score": 0.2
  },
  {
    "model": "ontocord/starcoder2-29b-ls",
    "score": 0.2
  },
  {
    "model": "ontocord/wide_3b-merge_test",
    "score": 0.2
  },
  {
    "model": "ontocord/wide_3b_sft_stage1.1-ss1-with_generics_intr_math_stories.no_issue",
    "score": 0.2
  },
  {
    "model": "ontocord/wide_3b_sft_stage1.1-ss1-with_generics_intr_math_stories.no_issue",
    "score": 0.2
  },
  {
    "model": "ontocord/wide_3b_sft_stage1.1-ss1-with_generics_intr_stories.no_issue",
    "score": 0.2
  },
  {
    "model": "ontocord/wide_3b_sft_stage1.1-ss1-with_r1_generics_intr_math_stories.no_issue",
    "score": 0.2
  },
  {
    "model": "ontocord/wide_3b_sft_stage1.2-ss1-expert_formatted_text",
    "score": 0.2
  },
  {
    "model": "ontocord/wide_3b_sft_stage1.2-ss1-expert_how-to",
    "score": 0.2
  },
  {
    "model": "oopere/pruned10-llama-3.2-3B",
    "score": 0.2
  },
  {
    "model": "oopere/pruned20-llama-3.2-3b",
    "score": 0.2
  },
  {
    "model": "open-atlas/Atlas-Flash-1.5B-Preview",
    "score": 0.2
  },
  {
    "model": "openbmb/MiniCPM-S-1B-sft-llama-format",
    "score": 0.2
  },
  {
    "model": "princeton-nlp/Mistral-7B-Base-SFT-DPO",
    "score": 0.2
  },
  {
    "model": "princeton-nlp/Mistral-7B-Instruct-DPO",
    "score": 0.2
  },
  {
    "model": "princeton-nlp/Sheared-LLaMA-2.7B",
    "score": 0.2
  },
  {
    "model": "prithivMLmods/Calcium-Opus-14B-Elite-1M",
    "score": 0.2
  },
  {
    "model": "prithivMLmods/Calcium-Opus-14B-Merge",
    "score": 0.2
  },
  {
    "model": "prithivMLmods/Llama-3.1-5B-Instruct",
    "score": 0.2
  },
  {
    "model": "prithivMLmods/Llama-Express.1-Math",
    "score": 0.2
  },
  {
    "model": "prithivMLmods/QwQ-R1-Distill-1.5B-CoT",
    "score": 0.2
  },
  {
    "model": "prithivMLmods/Qwen2.5-1.5B-DeepSeek-R1-Instruct",
    "score": 0.2
  },
  {
    "model": "prithivMLmods/Sqweeks-7B-Instruct",
    "score": 0.2
  },
  {
    "model": "rhysjones/phi-2-orange-v2",
    "score": 0.2
  },
  {
    "model": "schnapss/testmerge-7b",
    "score": 0.2
  },
  {
    "model": "tangledgroup/tangled-llama-pints-1.5b-v0.1-instruct",
    "score": 0.2
  },
  {
    "model": "thirdeyeai/elevate360m",
    "score": 0.2
  },
  {
    "model": "tiiuae/Falcon3-7B-Instruct",
    "score": 0.2
  },
  {
    "model": "tinycompany/BiBo-v0.3",
    "score": 0.2
  },
  {
    "model": "togethercomputer/GPT-NeoXT-Chat-Base-20B",
    "score": 0.2
  },
  {
    "model": "togethercomputer/RedPajama-INCITE-Base-3B-v1",
    "score": 0.2
  },
  {
    "model": "trthminh1112/autotrain-llama32-1b-finetune",
    "score": 0.2
  },
  {
    "model": "unsloth/Llama-3.2-1B-Instruct-no-system-message",
    "score": 0.2
  },
  {
    "model": "unsloth/Phi-3-mini-4k-instruct",
    "score": 0.2
  },
  {
    "model": "vicgalle/Configurable-Hermes-2-Pro-Llama-3-8B",
    "score": 0.2
  },
  {
    "model": "vonjack/SmolLM2-360M-Merged",
    "score": 0.2
  },
  {
    "model": "win10/Norns-Qwen2.5-12B",
    "score": 0.2
  },
  {
    "model": "xkp24/Llama-3-8B-Instruct-SPPO-Iter2_bt_8b-table",
    "score": 0.2
  },
  {
    "model": "xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_bt_2b-table-0.001",
    "score": 0.2
  },
  {
    "model": "xukp20/Llama-3-8B-Instruct-SPPO-Iter3_bt_8b-table",
    "score": 0.2
  },
  {
    "model": "AI4free/t2",
    "score": 0.196
  },
  {
    "model": "Alepach/notHumpback-M1-v2",
    "score": 0.196
  },
  {
    "model": "Ayush-Singh/Llama1B-sft-2",
    "score": 0.196
  },
  {
    "model": "BEE-spoke-data/tFINE-900m-e16-d32-flan",
    "score": 0.196
  },
  {
    "model": "BlackBeenie/Bloslain-8B-v0.2",
    "score": 0.196
  },
  {
    "model": "BlackBeenie/llama-3.1-8B-Galore-openassistant-guanaco",
    "score": 0.196
  },
  {
    "model": "ClaudioItaly/Book-Gut12B",
    "score": 0.196
  },
  {
    "model": "CohereForAI/aya-expanse-8b",
    "score": 0.196
  },
  {
    "model": "DZgas/GIGABATEMAN-7B",
    "score": 0.196
  },
  {
    "model": "Daemontatox/TinySphinx",
    "score": 0.196
  },
  {
    "model": "DavidAU/DeepSeek-R1-Distill-Qwen-25.5B-Brainstorm",
    "score": 0.196
  },
  {
    "model": "DavidAU/L3-SMB-Instruct-12.2B-F32",
    "score": 0.196
  },
  {
    "model": "Davidsv/SUONG-1",
    "score": 0.196
  },
  {
    "model": "DavieLion/Lllma-3.2-1B",
    "score": 0.196
  },
  {
    "model": "DoppelReflEx/MN-12B-FoxFrame3-test",
    "score": 0.196
  },
  {
    "model": "DoppelReflEx/MN-12B-Mimicore-Orochi",
    "score": 0.196
  },
  {
    "model": "DoppelReflEx/MN-12B-Mimicore-Nocturne",
    "score": 0.196
  },
  {
    "model": "EleutherAI/gpt-neo-1.3B",
    "score": 0.196
  },
  {
    "model": "EleutherAI/gpt-neo-125m",
    "score": 0.196
  },
  {
    "model": "EleutherAI/pythia-1.4b",
    "score": 0.196
  },
  {
    "model": "Epiculous/Violet_Twilight-v0.2",
    "score": 0.196
  },
  {
    "model": "EpistemeAI/FineLlama3.1-8B-Instruct",
    "score": 0.196
  },
  {
    "model": "EpistemeAI2/Fireball-Alpaca-Llama3.1.01-8B-Philos",
    "score": 0.196
  },
  {
    "model": "FlofloB/smollm2-135M_pretrained_1000k_fineweb",
    "score": 0.196
  },
  {
    "model": "FlofloB/smollm2-135M_pretrained_600k_fineweb",
    "score": 0.196
  },
  {
    "model": "HeraiHench/Double-Down-Qwen-Math-7B",
    "score": 0.196
  },
  {
    "model": "HuggingFaceTB/SmolLM-360M",
    "score": 0.196
  },
  {
    "model": "JackFram/llama-68m",
    "score": 0.196
  },
  {
    "model": "Jacoby746/Inf-Silent-Kunoichi-v0.2-2x7B",
    "score": 0.196
  },
  {
    "model": "Jacoby746/Proto-Athena-v0.2-4x7B",
    "score": 0.196
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-Instruct-SFT-MDPO-1epoch_v1",
    "score": 0.196
  },
  {
    "model": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-bleu-beta0.1-no-length-scale-gamma0.4",
    "score": 0.196
  },
  {
    "model": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-rougeL-beta10-gamma0.3-lr1.0e-6-scale-log",
    "score": 0.196
  },
  {
    "model": "Kukedlc/NeuralSynthesis-7B-v0.1",
    "score": 0.196
  },
  {
    "model": "Kukedlc/Qwen-2.5-7b-Spanish-o1-CoT",
    "score": 0.196
  },
  {
    "model": "LeroyDyer/SpydazWeb_AI_HumanAGI_001_M2",
    "score": 0.196
  },
  {
    "model": "LeroyDyer/SpydazWeb_AI_HumanAI_010_CHAT",
    "score": 0.196
  },
  {
    "model": "LeroyDyer/SpydazWeb_AI_HumanAI_TextVision",
    "score": 0.196
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_OmG_001",
    "score": 0.196
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_AGI_RP_R1",
    "score": 0.196
  },
  {
    "model": "Lil-R/PRYMMAL-ECE-1B-SLERP-V1",
    "score": 0.196
  },
  {
    "model": "LilRg/PRYMMAL-6B-slerp",
    "score": 0.196
  },
  {
    "model": "LimYeri/CodeMind-Llama3-8B-unsloth_v4-one-DPO-merged",
    "score": 0.196
  },
  {
    "model": "MarinaraSpaghetti/NemoReRemix-12B",
    "score": 0.196
  },
  {
    "model": "MarinaraSpaghetti/Nemomix-v4.0-12B",
    "score": 0.196
  },
  {
    "model": "MaziyarPanahi/Calme-4x7B-MoE-v0.1",
    "score": 0.196
  },
  {
    "model": "Mxode/NanoLM-0.3B-Instruct-v1",
    "score": 0.196
  },
  {
    "model": "NYTK/PULI-GPTrio",
    "score": 0.196
  },
  {
    "model": "NbAiLab/nb-llama-3.1-8B-Instruct",
    "score": 0.196
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_Dolermed_V1.01",
    "score": 0.196
  },
  {
    "model": "Nexesenex/Llama_3.2_1b_Syneridol_0.2",
    "score": 0.196
  },
  {
    "model": "Nitral-AI/Captain-Eris_Violet-GRPO-v0.420",
    "score": 0.196
  },
  {
    "model": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT",
    "score": 0.196
  },
  {
    "model": "Orenguteng/Llama-3.1-8B-Lexi-Uncensored",
    "score": 0.196
  },
  {
    "model": "PJMixers-Dev/L3.2-Instruct-Thinking-v0.1-1B",
    "score": 0.196
  },
  {
    "model": "Parissa3/test-model",
    "score": 0.196
  },
  {
    "model": "PranavHarshan/LaMistral-V4",
    "score": 0.196
  },
  {
    "model": "Quazim0t0/Motion-8B-Linear",
    "score": 0.196
  },
  {
    "model": "Qwen/Qwen2.5-14B-Instruct-1M",
    "score": 0.196
  },
  {
    "model": "Sakalti/SJT-1.5B-Alpha",
    "score": 0.196
  },
  {
    "model": "Sakalti/SJT-2B-V1.1",
    "score": 0.196
  },
  {
    "model": "Sakalti/SJT-7.5B",
    "score": 0.196
  },
  {
    "model": "Sakalti/SJT-Moe2x7.5B",
    "score": 0.196
  },
  {
    "model": "SentientAGI/Dobby-Mini-Leashed-Llama-3.1-8B",
    "score": 0.196
  },
  {
    "model": "Shreyash2010/Uma-4x4B-Instruct-v0.1",
    "score": 0.196
  },
  {
    "model": "SicariusSicariiStuff/2B-ad",
    "score": 0.196
  },
  {
    "model": "SkyOrbis/SKY-Ko-Qwen2.5-3B-Instruct",
    "score": 0.196
  },
  {
    "model": "Stark2008/GutenLaserPi",
    "score": 0.196
  },
  {
    "model": "Tijmen2/cosmosage-v3",
    "score": 0.196
  },
  {
    "model": "Trappu/Magnum-Picaro-0.7-v2-12b",
    "score": 0.196
  },
  {
    "model": "Trappu/Nemo-Picaro-12B",
    "score": 0.196
  },
  {
    "model": "Triangle104/Minerva-1.5b",
    "score": 0.196
  },
  {
    "model": "Triangle104/Minerva-7b",
    "score": 0.196
  },
  {
    "model": "VAGOsolutions/SauerkrautLM-7b-LaserChat",
    "score": 0.196
  },
  {
    "model": "Weyaxi/Einstein-v6.1-Llama3-8B",
    "score": 0.196
  },
  {
    "model": "Xiaojian9992024/Llama3.2-1B-THREADRIPPER",
    "score": 0.196
  },
  {
    "model": "Xkev/Llama-3.2V-11B-cot",
    "score": 0.196
  },
  {
    "model": "Yash21/TinyYi-7B-Test",
    "score": 0.196
  },
  {
    "model": "Youlln/ECE-MIRAGE-1-12B",
    "score": 0.196
  },
  {
    "model": "Youlln/ECE-MIRAGE-1-15B",
    "score": 0.196
  },
  {
    "model": "abhishek/autotrain-0tmgq-5tpbg",
    "score": 0.196
  },
  {
    "model": "abhishek/autotrain-0tmgq-5tpbg",
    "score": 0.196
  },
  {
    "model": "akhadangi/Llama3.2.1B.0.1-First",
    "score": 0.196
  },
  {
    "model": "allenai/OLMo-7B-hf",
    "score": 0.196
  },
  {
    "model": "allenai/OLMoE-1B-7B-0924-Instruct",
    "score": 0.196
  },
  {
    "model": "allknowingroger/Meme-7B-slerp",
    "score": 0.196
  },
  {
    "model": "allknowingroger/MultiMash5-12B-slerp",
    "score": 0.196
  },
  {
    "model": "allknowingroger/MultiMash7-12B-slerp",
    "score": 0.196
  },
  {
    "model": "allknowingroger/MultiMash9-13B-slerp",
    "score": 0.196
  },
  {
    "model": "allknowingroger/MultiMerge-7B-slerp",
    "score": 0.196
  },
  {
    "model": "allknowingroger/MultiverseEx26-7B-slerp",
    "score": 0.196
  },
  {
    "model": "allknowingroger/ROGERphi-7B-slerp",
    "score": 0.196
  },
  {
    "model": "allknowingroger/YamMaths-7B-slerp",
    "score": 0.196
  },
  {
    "model": "allknowingroger/Yunconglong-13B-slerp",
    "score": 0.196
  },
  {
    "model": "allknowingroger/limyClown-7B-slerp",
    "score": 0.196
  },
  {
    "model": "allura-org/L3.1-8b-RP-Ink",
    "score": 0.196
  },
  {
    "model": "braindao/DeepSeek-R1-Distill-Qwen-14B-Blunt-Uncensored",
    "score": 0.196
  },
  {
    "model": "braindao/DeepSeek-R1-Distill-Qwen-7B-Reflective",
    "score": 0.196
  },
  {
    "model": "bunnycore/FwF-Qwen-7B-0.2",
    "score": 0.196
  },
  {
    "model": "bunnycore/Llama-3.2-3B-ProdigyPlusPlus",
    "score": 0.196
  },
  {
    "model": "bunnycore/Qwen2.5-7B-RRP-1M-Thinker",
    "score": 0.196
  },
  {
    "model": "cloudyu/Yi-34Bx2-MoE-60B-DPO",
    "score": 0.196
  },
  {
    "model": "deepseek-ai/deepseek-llm-7b-chat",
    "score": 0.196
  },
  {
    "model": "dnhkng/RYS-XLarge2",
    "score": 0.196
  },
  {
    "model": "dustinwloring1988/Reflexis-8b-chat-v7",
    "score": 0.196
  },
  {
    "model": "fblgit/miniclaus-qw1.5B-UNAMGS-GRPO",
    "score": 0.196
  },
  {
    "model": "flammenai/Mahou-1.5-mistral-nemo-12B",
    "score": 0.196
  },
  {
    "model": "formulae/mita-v1-7b",
    "score": 0.196
  },
  {
    "model": "gmonsoon/SahabatAI-Rebase-8B-Test",
    "score": 0.196
  },
  {
    "model": "huihui-ai/Qwen2.5-14B-Instruct-abliterated-v2",
    "score": 0.196
  },
  {
    "model": "ibm-granite/granite-3.0-3b-a800m-instruct",
    "score": 0.196
  },
  {
    "model": "icefog72/Ice0.76-02.02-RP",
    "score": 0.196
  },
  {
    "model": "inumulaisk/eval_model",
    "score": 0.196
  },
  {
    "model": "jaspionjader/bh-12",
    "score": 0.196
  },
  {
    "model": "jaspionjader/bh-3",
    "score": 0.196
  },
  {
    "model": "jaspionjader/bh-37",
    "score": 0.196
  },
  {
    "model": "jaspionjader/slu-17",
    "score": 0.196
  },
  {
    "model": "jeanmichela/o-distil-qwen",
    "score": 0.196
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.7-gamma-0.01",
    "score": 0.196
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_ties-density-0.3",
    "score": 0.196
  },
  {
    "model": "jsfs11/L3-8B-Stheno-slerp",
    "score": 0.196
  },
  {
    "model": "lesubra/merge-test",
    "score": 0.196
  },
  {
    "model": "marcuscedricridia/Cheng-1",
    "score": 0.196
  },
  {
    "model": "marcuscedricridia/Hush-Qwen2.5-7B-MST-v1.3",
    "score": 0.196
  },
  {
    "model": "marcuscedricridia/cursa-o1-7b",
    "score": 0.196
  },
  {
    "model": "marcuscedricridia/cursa-o1-7b-v1.1",
    "score": 0.196
  },
  {
    "model": "meditsolutions/Llama-3.2-SUN-2.5B-chat",
    "score": 0.196
  },
  {
    "model": "meta-llama/Llama-2-7b-chat-hf",
    "score": 0.196
  },
  {
    "model": "microsoft/Phi-4-mini-instruct",
    "score": 0.196
  },
  {
    "model": "mistralai/Mixtral-8x22B-v0.1",
    "score": 0.196
  },
  {
    "model": "mlabonne/OrpoLlama-3-8B",
    "score": 0.196
  },
  {
    "model": "nbeerbower/DoublePotato-Mistral-Nemo-13B",
    "score": 0.196
  },
  {
    "model": "nbeerbower/Hermes2-Gutenberg2-Mistral-7B",
    "score": 0.196
  },
  {
    "model": "nidum/Nidum-Limitless-Gemma-2B",
    "score": 0.196
  },
  {
    "model": "noname0202/llama-math-1b-r32-0to512tokens-test",
    "score": 0.196
  },
  {
    "model": "noname0202/llama-math-1b-r8-512tokens-test",
    "score": 0.196
  },
  {
    "model": "notbdq/Qwen2.5-14B-Instruct-1M-GRPO-Reasoning",
    "score": 0.196
  },
  {
    "model": "ontocord/RedPajama3b_v1-autoredteam_helpfulness-train",
    "score": 0.196
  },
  {
    "model": "ontocord/wide_3b_sft_stage1.1-ss1-with_generics_intr.no_issue",
    "score": 0.196
  },
  {
    "model": "ontocord/wide_3b_sft_stage1.1-ss1-with_generics_intr_math.no_issue",
    "score": 0.196
  },
  {
    "model": "ontocord/wide_3b_sft_stage1.1-ss1-with_generics_math.no_issue",
    "score": 0.196
  },
  {
    "model": "pankajmathur/orca_mini_v5_8b",
    "score": 0.196
  },
  {
    "model": "pankajmathur/orca_mini_v9_1_1B-Instruct",
    "score": 0.196
  },
  {
    "model": "pints-ai/1.5-Pints-16K-v0.1",
    "score": 0.196
  },
  {
    "model": "princeton-nlp/Llama-3-Instruct-8B-CPO-v0.2",
    "score": 0.196
  },
  {
    "model": "prithivMLmods/Taurus-Opus-7B",
    "score": 0.196
  },
  {
    "model": "qingy2024/Qwen2.5-Math-14B-Instruct-Preview",
    "score": 0.196
  },
  {
    "model": "qq8933/OpenLongCoT-Base-Gemma2-2B",
    "score": 0.196
  },
  {
    "model": "realtreetune/rho-1b-sft-MATH",
    "score": 0.196
  },
  {
    "model": "redrix/AngelSlayer-12B-Unslop-Mell-RPMax-DARKNESS",
    "score": 0.196
  },
  {
    "model": "sequelbox/gemma-2-9B-MOTH",
    "score": 0.196
  },
  {
    "model": "sethuiyer/Llama-3.1-8B-Experimental-1208-Instruct",
    "score": 0.196
  },
  {
    "model": "sethuiyer/Llamaverse-3.1-8B-Instruct",
    "score": 0.196
  },
  {
    "model": "shivam9980/NEPALI-LLM",
    "score": 0.196
  },
  {
    "model": "silma-ai/SILMA-Kashif-2B-Instruct-v1.0",
    "score": 0.196
  },
  {
    "model": "sometimesanotion/IF-reasoning-experiment-80",
    "score": 0.196
  },
  {
    "model": "sumink/Qmerft",
    "score": 0.196
  },
  {
    "model": "sumink/Qwenmplus",
    "score": 0.196
  },
  {
    "model": "swap-uniba/LLaMAntino-3-ANITA-8B-Inst-DPO-ITA",
    "score": 0.196
  },
  {
    "model": "teknium/OpenHermes-2.5-Mistral-7B",
    "score": 0.196
  },
  {
    "model": "theprint/CleverBoi-Llama-3.1-8B-v2",
    "score": 0.196
  },
  {
    "model": "theprint/ReWiz-Nemo-12B-Instruct",
    "score": 0.196
  },
  {
    "model": "tiiuae/Falcon3-3B-Instruct",
    "score": 0.196
  },
  {
    "model": "vicgalle/Configurable-Yi-1.5-9B-Chat",
    "score": 0.196
  },
  {
    "model": "win10/ArliAI-RPMax-v1.3-merge-13.3B",
    "score": 0.196
  },
  {
    "model": "xxx777xxxASD/L3.1-ClaudeMaid-4x8B",
    "score": 0.196
  },
  {
    "model": "yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_bt_2b-table-0.001",
    "score": 0.196
  },
  {
    "model": "stabilityai/stablelm-2-zephyr-1_6b",
    "score": 0.192
  },
  {
    "model": "Aashraf995/Creative-7B-nerd",
    "score": 0.192
  },
  {
    "model": "Azure99/blossom-v5-llama3-8b",
    "score": 0.192
  },
  {
    "model": "BlackBeenie/Neos-Phi-3-14B-v0.1",
    "score": 0.192
  },
  {
    "model": "ContactDoctor/Bio-Medical-Llama-3-8B",
    "score": 0.192
  },
  {
    "model": "DavidAU/L3-Stheno-v3.2-12.2B-Instruct",
    "score": 0.192
  },
  {
    "model": "DavidAU/L3.1-Dark-Planet-SpinFire-Uncensored-8B",
    "score": 0.192
  },
  {
    "model": "DavieLion/Llama-3.2-1B-SPIN-iter2",
    "score": 0.192
  },
  {
    "model": "DreadPoor/CoolerCoder-8B-LINEAR",
    "score": 0.192
  },
  {
    "model": "Epiculous/Crimson_Dawn-v0.2",
    "score": 0.192
  },
  {
    "model": "EpistemeAI/Alpaca-Llama3.1-8B",
    "score": 0.192
  },
  {
    "model": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.003-128K-code-ds",
    "score": 0.192
  },
  {
    "model": "EpistemeAI/Polypsyche-Llama-3.1-8B-Instruct-Agent-0.003-128K-code-ds-auto-Logic",
    "score": 0.192
  },
  {
    "model": "EpistemeAI2/Fireball-Alpaca-Llama3.1.04-8B-Philos",
    "score": 0.192
  },
  {
    "model": "EpistemeAI2/Fireball-MathMistral-Nemo-Base-2407-v2dpo",
    "score": 0.192
  },
  {
    "model": "Etherll/Replete-LLM-V3-Llama-3.1-8b",
    "score": 0.192
  },
  {
    "model": "FlofloB/83k_continued_pretraining_Qwen2.5-0.5B-Instruct_Unsloth_merged_16bit",
    "score": 0.192
  },
  {
    "model": "FlofloB/smollm2-135M_pretrained_600k_fineweb_uncovai_selected",
    "score": 0.192
  },
  {
    "model": "FlofloB/smollm2-135M_pretrained_800k_fineweb_uncovai_selected",
    "score": 0.192
  },
  {
    "model": "HuggingFaceTB/SmolLM-135M",
    "score": 0.192
  },
  {
    "model": "JayHyeon/Qwen-0.5B-eDPO-1epoch",
    "score": 0.192
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPOP_5e-6-1ep_0alp_5lam",
    "score": 0.192
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_5e-6-1ep_0alp_0lam",
    "score": 0.192
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-IRPO_5e-6-3ep_1alp_0lam",
    "score": 0.192
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-5e-5-2ep",
    "score": 0.192
  },
  {
    "model": "Jimmy19991222/Llama-3-Instruct-8B-SimPO-v0.2",
    "score": 0.192
  },
  {
    "model": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-bert-f1-beta10-gamma0.3-lr1.0e-6-1minus-rerun",
    "score": 0.192
  },
  {
    "model": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-rouge2-beta10-1minus-gamma0.3-rerun",
    "score": 0.192
  },
  {
    "model": "LLM4Binary/llm4decompile-1.3b-v2",
    "score": 0.192
  },
  {
    "model": "LeroyDyer/CheckPoint_A",
    "score": 0.192
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_002",
    "score": 0.192
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_Top_Teacher_",
    "score": 0.192
  },
  {
    "model": "Locutusque/Hercules-6.0-Llama-3.1-8B",
    "score": 0.192
  },
  {
    "model": "ManoloPueblo/ContentCuisine_1-7B-slerp",
    "score": 0.192
  },
  {
    "model": "MaziyarPanahi/Calme-4x7B-MoE-v0.2",
    "score": 0.192
  },
  {
    "model": "Minami-su/Amara-o2-7B-Qwen",
    "score": 0.192
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_DobHerWild_R1_v1.1R",
    "score": 0.192
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_Hermedive_V1.01",
    "score": 0.192
  },
  {
    "model": "Nexesenex/Llama_3.2_1b_Sydonia_0.1",
    "score": 0.192
  },
  {
    "model": "Nexusflow/NexusRaven-V2-13B",
    "score": 0.192
  },
  {
    "model": "Nitral-AI/Captain-Eris-BMO_Violent-GRPO-v0.420",
    "score": 0.192
  },
  {
    "model": "Novaciano/Cultist-3.2-1B",
    "score": 0.192
  },
  {
    "model": "Novaciano/HarmfulProject-3.2-1B",
    "score": 0.192
  },
  {
    "model": "OpenBuddy/openbuddy-llama3.1-8b-v22.3-131k",
    "score": 0.192
  },
  {
    "model": "Pretergeek/OpenChat-3.5-0106_10.7B_48Layers-Appended",
    "score": 0.192
  },
  {
    "model": "Pretergeek/OpenChat-3.5-0106_10.7B_48Layers-Interleaved",
    "score": 0.192
  },
  {
    "model": "Pretergeek/OpenChat-3.5-0106_8.11B_36Layers-Appended",
    "score": 0.192
  },
  {
    "model": "Pretergeek/OpenChat-3.5-0106_32K-PoSE",
    "score": 0.192
  },
  {
    "model": "Pretergeek/OpenChat-3.5-0106_8.11B_36Layers-Interleaved",
    "score": 0.192
  },
  {
    "model": "Pretergeek/OpenChat-3.5-0106_8.99B_40Layers-Interleaved",
    "score": 0.192
  },
  {
    "model": "Pretergeek/OpenChat-3.5-0106_8.99B_40Layers-Appended",
    "score": 0.192
  },
  {
    "model": "Pretergeek/OpenChat-3.5-0106_9.86B_44Layers-Appended",
    "score": 0.192
  },
  {
    "model": "Quazim0t0/Mouse-9B",
    "score": 0.192
  },
  {
    "model": "Sakalti/Saba1-1.8B",
    "score": 0.192
  },
  {
    "model": "Sakalti/Saba1.5-1.5B",
    "score": 0.192
  },
  {
    "model": "Svak/MN-12B-Inferor-v0.0",
    "score": 0.192
  },
  {
    "model": "T145/ZEUS-8B-V17-abliterated-V4",
    "score": 0.192
  },
  {
    "model": "TIGER-Lab/AceCoder-Qwen2.5-Coder-7B-Ins-Rule",
    "score": 0.192
  },
  {
    "model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    "score": 0.192
  },
  {
    "model": "TinyLlama/TinyLlama_v1.1",
    "score": 0.192
  },
  {
    "model": "Triangle104/Hermes-Llama-3.2-CoT",
    "score": 0.192
  },
  {
    "model": "UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter2",
    "score": 0.192
  },
  {
    "model": "Xiaojian9992024/Llama3.2-1B-THREADRIPPER-v0.2",
    "score": 0.192
  },
  {
    "model": "Youlln/ECE-PRYMMAL0.5-FT",
    "score": 0.192
  },
  {
    "model": "ZeroXClem/Qwen2.5-7B-Qandora-CySec",
    "score": 0.192
  },
  {
    "model": "allenai/Llama-3.1-Tulu-3-8B-RM",
    "score": 0.192
  },
  {
    "model": "allknowingroger/MultiMash10-13B-slerp",
    "score": 0.192
  },
  {
    "model": "allknowingroger/NeuralWestSeverus-7B-slerp",
    "score": 0.192
  },
  {
    "model": "allknowingroger/Ph3merge2-14B",
    "score": 0.192
  },
  {
    "model": "allknowingroger/Phi3mash1-17B-pass",
    "score": 0.192
  },
  {
    "model": "allknowingroger/RogerMerge-7B-slerp",
    "score": 0.192
  },
  {
    "model": "allura-org/Teleut-7b",
    "score": 0.192
  },
  {
    "model": "bunnycore/Blabbertron-1.0",
    "score": 0.192
  },
  {
    "model": "bunnycore/QandoraExp-7B-Persona",
    "score": 0.192
  },
  {
    "model": "cckm/tinymistral_950m",
    "score": 0.192
  },
  {
    "model": "cloudyu/Mixtral_7Bx2_MoE",
    "score": 0.192
  },
  {
    "model": "cluebbers/Llama-3.1-8B-paraphrase-type-generation-etpc",
    "score": 0.192
  },
  {
    "model": "cognitivecomputations/Dolphin3.0-Llama3.1-8B",
    "score": 0.192
  },
  {
    "model": "cognitivecomputations/dolphin-2.9.2-qwen2-7b",
    "score": 0.192
  },
  {
    "model": "ehristoforu/trd-7b-it",
    "score": 0.192
  },
  {
    "model": "ell44ot/gemma-2b-def",
    "score": 0.192
  },
  {
    "model": "facebook/opt-30b",
    "score": 0.192
  },
  {
    "model": "facebook/opt-1.3b",
    "score": 0.192
  },
  {
    "model": "fblgit/cybertron-v4-qw7B-UNAMGS",
    "score": 0.192
  },
  {
    "model": "fblgit/miniclaus-qw1.5B-UNAMGS",
    "score": 0.192
  },
  {
    "model": "fluently-lm/Llama-TI-8B-Instruct",
    "score": 0.192
  },
  {
    "model": "gmonsoon/SahabatAI-Llama-11B-Test",
    "score": 0.192
  },
  {
    "model": "godlikehhd/qwen_2.5-1.5b-cherry_new",
    "score": 0.192
  },
  {
    "model": "hon9kon9ize/CantoneseLLMChat-v1.0-7B",
    "score": 0.192
  },
  {
    "model": "hotmailuser/FalconSlerp2-7B",
    "score": 0.192
  },
  {
    "model": "icefog72/Ice0.32-10.11-RP",
    "score": 0.192
  },
  {
    "model": "icefog72/Ice0.37-18.11-RP",
    "score": 0.192
  },
  {
    "model": "icefog72/Ice0.50.1-16.01-RP",
    "score": 0.192
  },
  {
    "model": "irahulpandey/mistralai-7B-slerp-v0.1",
    "score": 0.192
  },
  {
    "model": "jaspionjader/bh-13",
    "score": 0.192
  },
  {
    "model": "jaspionjader/slu-11",
    "score": 0.192
  },
  {
    "model": "jebish7/Llama-3-Nanda-10B-Chat",
    "score": 0.192
  },
  {
    "model": "jebish7/gemma-2-2b-it",
    "score": 0.192
  },
  {
    "model": "jeffmeloy/Qwen2.5-7B-nerd-uncensored-v1.3",
    "score": 0.192
  },
  {
    "model": "jeffmeloy/Qwen2.5-7B-nerd-uncensored-v1.2",
    "score": 0.192
  },
  {
    "model": "jiviai/medX_v2",
    "score": 0.192
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_ties-density-0.5",
    "score": 0.192
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_ties-density-0.7",
    "score": 0.192
  },
  {
    "model": "marcuscedricridia/olmner-sbr-7b",
    "score": 0.192
  },
  {
    "model": "mattshumer/Reflection-Llama-3.1-70B",
    "score": 0.192
  },
  {
    "model": "nbeerbower/Dumpling-Qwen2.5-7B-1k-r16",
    "score": 0.192
  },
  {
    "model": "nbeerbower/Flammades-Mistral-Nemo-12B",
    "score": 0.192
  },
  {
    "model": "nbeerbower/Mistral-Nemo-Gutenberg-Doppel-12B-v2",
    "score": 0.192
  },
  {
    "model": "nbeerbower/Mistral-Nemo-Prism-12B",
    "score": 0.192
  },
  {
    "model": "nbeerbower/Mistral-Nemo-Prism-12B-v7",
    "score": 0.192
  },
  {
    "model": "netcat420/DeepSeek-R1-Distill-Qwen-MFANN-Slerp-7b",
    "score": 0.192
  },
  {
    "model": "netcat420/MFANN-SFT",
    "score": 0.192
  },
  {
    "model": "netcat420/MFANN-phigments-slerp-V3.2",
    "score": 0.192
  },
  {
    "model": "netcat420/MFANN3bv0.15",
    "score": 0.192
  },
  {
    "model": "netcat420/MFANN3bv1.4",
    "score": 0.192
  },
  {
    "model": "netcat420/MFANNv0.25",
    "score": 0.192
  },
  {
    "model": "ngxson/MiniThinky-1B-Llama-3.2",
    "score": 0.192
  },
  {
    "model": "nvidia/Hymba-1.5B-Instruct",
    "score": 0.192
  },
  {
    "model": "openchat/openchat-3.5-0106",
    "score": 0.192
  },
  {
    "model": "pankajmathur/orca_mini_v5_8b_dpo",
    "score": 0.192
  },
  {
    "model": "princeton-nlp/Llama-3-8B-ProLong-64k-Instruct",
    "score": 0.192
  },
  {
    "model": "princeton-nlp/Llama-3-Instruct-8B-DPO",
    "score": 0.192
  },
  {
    "model": "prithivMLmods/Bellatrix-1.5B-xElite",
    "score": 0.192
  },
  {
    "model": "prithivMLmods/Triangulum-10B",
    "score": 0.192
  },
  {
    "model": "refuelai/Llama-3-Refueled",
    "score": 0.192
  },
  {
    "model": "rsh345/mistral-ft-optimized-1218-NeuralHermes-2.5-Mistral-7B",
    "score": 0.192
  },
  {
    "model": "skymizer/Llama2-7b-sft-chat-custom-template-dpo",
    "score": 0.192
  },
  {
    "model": "sometimesanotion/Qwen2.5-7B-Gordion-v0.1-Reason",
    "score": 0.192
  },
  {
    "model": "sumink/llmer",
    "score": 0.192
  },
  {
    "model": "theprint/ReWiz-Worldbuilder-7B",
    "score": 0.192
  },
  {
    "model": "tinycompany/SigmaBoi-base",
    "score": 0.192
  },
  {
    "model": "tinycompany/SigmaBoi-ib",
    "score": 0.192
  },
  {
    "model": "tinycompany/SigmaBoi-nomic-moe",
    "score": 0.192
  },
  {
    "model": "tinycompany/SigmaBoi-nomic1.5",
    "score": 0.192
  },
  {
    "model": "tinycompany/SigmaBoi-nomic1.5-fp32",
    "score": 0.192
  },
  {
    "model": "vicgalle/CarbonBeagle-11B",
    "score": 0.192
  },
  {
    "model": "voidful/smol-360m-ft",
    "score": 0.192
  },
  {
    "model": "win10/EVA-Norns-Qwen2.5-v0.1",
    "score": 0.192
  },
  {
    "model": "xkp24/Llama-3-8B-Instruct-SPPO-Iter2_bt_2b-table",
    "score": 0.192
  },
  {
    "model": "yuchenxie/ArlowGPT-3B-Multilingual",
    "score": 0.192
  },
  {
    "model": "01-ai/Yi-34B",
    "score": 0.188
  },
  {
    "model": "Artples/L-MChat-7b",
    "score": 0.188
  },
  {
    "model": "Ateron/Way_of_MagPicaro",
    "score": 0.188
  },
  {
    "model": "Aurel9/testmerge-7b",
    "score": 0.188
  },
  {
    "model": "BAAI/Infinity-Instruct-3M-0625-Yi-1.5-9B",
    "score": 0.188
  },
  {
    "model": "BEE-spoke-data/tFINE-900m-instruct-orpo",
    "score": 0.188
  },
  {
    "model": "BlackBeenie/Llama-3.1-8B-pythonic-passthrough-merge",
    "score": 0.188
  },
  {
    "model": "CYFRAGOVPL/PLLuM-12B-chat",
    "score": 0.188
  },
  {
    "model": "Columbia-NLP/LION-LLaMA-3-8b-sft-v1.0",
    "score": 0.188
  },
  {
    "model": "Daemontatox/AetherUncensored",
    "score": 0.188
  },
  {
    "model": "Daemontatox/mini-Cogito-R1",
    "score": 0.188
  },
  {
    "model": "DavidAU/DeepSeek-BlackRoot-R1-Distill-Llama-3.1-8B",
    "score": 0.188
  },
  {
    "model": "DavidAU/DeepSeek-MOE-4X8B-R1-Distill-Llama-3.1-Deep-Thinker-Uncensored-24B",
    "score": 0.188
  },
  {
    "model": "DavidAU/DeepSeek-MOE-4X8B-R1-Distill-Llama-3.1-Mad-Scientist-24B",
    "score": 0.188
  },
  {
    "model": "DavidAU/Qwen2.5-MOE-2X1.5B-DeepSeek-Uncensored-Censored-4B",
    "score": 0.188
  },
  {
    "model": "DeepAutoAI/Explore_Llama-3.2-1B-Inst",
    "score": 0.188
  },
  {
    "model": "DevQuasar/DevQuasar-R1-Uncensored-Llama-8B",
    "score": 0.188
  },
  {
    "model": "DoppelReflEx/MN-12B-FoxFrame-test",
    "score": 0.188
  },
  {
    "model": "DreadPoor/Irina-8B-model_stock",
    "score": 0.188
  },
  {
    "model": "EleutherAI/gpt-neox-20b",
    "score": 0.188
  },
  {
    "model": "EpistemeAI/Polypsyche-Llama-3.1-8B-Instruct-Agent-0.003-128K-code-ds-auto-divergent",
    "score": 0.188
  },
  {
    "model": "EpistemeAI2/Fireball-Alpaca-Llama3.1.08-8B-C-R1-KTO-Reflection",
    "score": 0.188
  },
  {
    "model": "Goekdeniz-Guelmez/josie-7b-v6.0-step2000",
    "score": 0.188
  },
  {
    "model": "Goekdeniz-Guelmez/josie-7b-v6.0-step2000",
    "score": 0.188
  },
  {
    "model": "GritLM/GritLM-7B-KTO",
    "score": 0.188
  },
  {
    "model": "Hastagaras/Llama-3.1-Jamet-8B-MK.I",
    "score": 0.188
  },
  {
    "model": "HuggingFaceTB/SmolLM2-135M-Instruct",
    "score": 0.188
  },
  {
    "model": "HuggingFaceTB/SmolLM2-135M-Instruct",
    "score": 0.188
  },
  {
    "model": "HumanLLMs/Humanish-LLama3-8B-Instruct",
    "score": 0.188
  },
  {
    "model": "JayHyeon/Qwen-0.5B-IRPO-1epoch",
    "score": 0.188
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-Instruct-SFT",
    "score": 0.188
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-Instruct-SFT-IRPO-1epoch_v1",
    "score": 0.188
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-Instruct-SFT-DPO-1epoch_v1",
    "score": 0.188
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_3e-6-1ep_0alp_0lam",
    "score": 0.188
  },
  {
    "model": "JayHyeon/Qwen_0.5-VIPO_5e-7-3ep_10vpo_const",
    "score": 0.188
  },
  {
    "model": "JayHyeon/Qwen_0.5-VIPO_5e-7-3ep_1vpo_const",
    "score": 0.188
  },
  {
    "model": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-bert_f1-beta10-gamma0.3-lr1.0e-6-scale-log",
    "score": 0.188
  },
  {
    "model": "Khetterman/DarkAtom-12B-v3",
    "score": 0.188
  },
  {
    "model": "KingNish/qwen-1b-continued-v2.2",
    "score": 0.188
  },
  {
    "model": "Kukedlc/NeuralSynthesis-7B-v0.3",
    "score": 0.188
  },
  {
    "model": "Kukedlc/NeuralSynthesis-7b-v0.4-slerp",
    "score": 0.188
  },
  {
    "model": "L-RAGE/3_PRYMMAL-ECE-7B-SLERP-V1",
    "score": 0.188
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_X1",
    "score": 0.188
  },
  {
    "model": "Marsouuu/MiniQwenMathExpert-ECE-PRYMMAL-Martial",
    "score": 0.188
  },
  {
    "model": "Marsouuu/lareneg1_78B-ECE-PRYMMAL-Martial",
    "score": 0.188
  },
  {
    "model": "MaziyarPanahi/Llama-3-8B-Instruct-v0.8",
    "score": 0.188
  },
  {
    "model": "MaziyarPanahi/Llama-3-8B-Instruct-v0.9",
    "score": 0.188
  },
  {
    "model": "MaziyarPanahi/calme-2.2-phi3-4b",
    "score": 0.188
  },
  {
    "model": "MaziyarPanahi/calme-2.3-qwen2-72b",
    "score": 0.188
  },
  {
    "model": "NeverSleep/Lumimaid-v0.2-8B",
    "score": 0.188
  },
  {
    "model": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
    "score": 0.188
  },
  {
    "model": "OEvortex/Emotional-llama-8B",
    "score": 0.188
  },
  {
    "model": "OliveiraJLT/Sagui-7B-Instruct-v0.1",
    "score": 0.188
  },
  {
    "model": "OpenBuddy/openbuddy-llama3-8b-v21.2-32k",
    "score": 0.188
  },
  {
    "model": "OpenLLM-France/Lucie-7B-Instruct",
    "score": 0.188
  },
  {
    "model": "OpenScholar/Llama-3.1_OpenScholar-8B",
    "score": 0.188
  },
  {
    "model": "Quazim0t0/Aura-8B-Linear",
    "score": 0.188
  },
  {
    "model": "Quazim0t0/Charlie-8B-Linear",
    "score": 0.188
  },
  {
    "model": "Ro-xe/FMixIA-FrankenMerge-9.5B-PT-9",
    "score": 0.188
  },
  {
    "model": "Sao10K/L3-8B-Stheno-v3.3-32K",
    "score": 0.188
  },
  {
    "model": "SicariusSicariiStuff/Impish_LLAMA_3B",
    "score": 0.188
  },
  {
    "model": "SicariusSicariiStuff/Winged_Imp_8B",
    "score": 0.188
  },
  {
    "model": "SicariusSicariiStuff/Wingless_Imp_8B",
    "score": 0.188
  },
  {
    "model": "SicariusSicariiStuff/Zion_Alpha",
    "score": 0.188
  },
  {
    "model": "SpaceYL/ECE_Poirot",
    "score": 0.188
  },
  {
    "model": "SultanR/SmolTulu-1.7b-Instruct",
    "score": 0.188
  },
  {
    "model": "SultanR/SmolTulu-1.7b-it-v0",
    "score": 0.188
  },
  {
    "model": "Supichi/BBAI_78B_Calme_3_1_Ties",
    "score": 0.188
  },
  {
    "model": "Supichi/BBAI_QWEEN_V000000_LUMEN_14B",
    "score": 0.188
  },
  {
    "model": "T145/ZEUS-8B-V2-ORPO",
    "score": 0.188
  },
  {
    "model": "Triangle104/Distilled-DarkPlanet-Allades-8B",
    "score": 0.188
  },
  {
    "model": "UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter1",
    "score": 0.188
  },
  {
    "model": "UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter3",
    "score": 0.188
  },
  {
    "model": "UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter3",
    "score": 0.188
  },
  {
    "model": "UKzExecution/LlamaExecutor-8B-3.0.5",
    "score": 0.188
  },
  {
    "model": "VAGOsolutions/SauerkrautLM-1.5b",
    "score": 0.188
  },
  {
    "model": "Weyaxi/Bagel-Hermes-2x34B",
    "score": 0.188
  },
  {
    "model": "Youlln/ECE-PRYMMAL-0.5B-SLERP-V2",
    "score": 0.188
  },
  {
    "model": "ZeroXClem/Qwen-2.5-Aether-SlerpFusion-7B",
    "score": 0.188
  },
  {
    "model": "allenai/OLMoE-1B-7B-0924",
    "score": 0.188
  },
  {
    "model": "allknowingroger/MultiMash-12B-slerp",
    "score": 0.188
  },
  {
    "model": "allknowingroger/Qwenslerp3-7B",
    "score": 0.188
  },
  {
    "model": "allura-org/MN-12b-RP-Ink",
    "score": 0.188
  },
  {
    "model": "anthracite-org/magnum-v3-9b-chatml",
    "score": 0.188
  },
  {
    "model": "asharsha30/LLAMA_Harsha_8_B_ORDP_10k",
    "score": 0.188
  },
  {
    "model": "automerger/YamshadowExperiment28-7B",
    "score": 0.188
  },
  {
    "model": "bfuzzy1/acheron-m",
    "score": 0.188
  },
  {
    "model": "bigscience/bloom-1b1",
    "score": 0.188
  },
  {
    "model": "bigscience/bloom-1b7",
    "score": 0.188
  },
  {
    "model": "bunnycore/Qwen-2.5-7B-Deep-Sky-T1",
    "score": 0.188
  },
  {
    "model": "bunnycore/Qwen2.5-7B-Instruct-Fusion",
    "score": 0.188
  },
  {
    "model": "byroneverson/Yi-1.5-9B-Chat-abliterated",
    "score": 0.188
  },
  {
    "model": "ehristoforu/qwen2.5-with-lora-think-3b-it",
    "score": 0.188
  },
  {
    "model": "ehristoforu/tmoe-v2",
    "score": 0.188
  },
  {
    "model": "ghost-x/ghost-8b-beta-1608",
    "score": 0.188
  },
  {
    "model": "godlikehhd/alpaca_data_ifd_min_2600",
    "score": 0.188
  },
  {
    "model": "godlikehhd/alpaca_data_ins_min_2600",
    "score": 0.188
  },
  {
    "model": "godlikehhd/qwen-2.5-1.5b-cherry",
    "score": 0.188
  },
  {
    "model": "google/mt5-base",
    "score": 0.188
  },
  {
    "model": "hotmailuser/FalconSlerp-3B",
    "score": 0.188
  },
  {
    "model": "ibm-granite/granite-3.1-3b-a800m-base",
    "score": 0.188
  },
  {
    "model": "icefog72/Ice0.31-08.11-RP",
    "score": 0.188
  },
  {
    "model": "icefog72/Ice0.41-22.11-RP",
    "score": 0.188
  },
  {
    "model": "icefog72/Ice0.53-16.01-RP",
    "score": 0.188
  },
  {
    "model": "icefog72/Ice0.66-25.01-RP",
    "score": 0.188
  },
  {
    "model": "intervitens/mini-magnum-12b-v1.1",
    "score": 0.188
  },
  {
    "model": "jaspionjader/bh-4",
    "score": 0.188
  },
  {
    "model": "jaspionjader/bh-6",
    "score": 0.188
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.9-gamma-0.01",
    "score": 0.188
  },
  {
    "model": "kms7530/chemeng_qwen-math-7b_24_1_100_1_nonmath",
    "score": 0.188
  },
  {
    "model": "kz919/QwQ-0.5B-Distilled-SFT",
    "score": 0.188
  },
  {
    "model": "lesubra/ECE-EIFFEL-3B",
    "score": 0.188
  },
  {
    "model": "llnYou/ECE-PRYMMAL-YL-1B-SLERP-V5",
    "score": 0.188
  },
  {
    "model": "marcuscedricridia/Hush-Qwen2.5-7B-MST-v1.1",
    "score": 0.188
  },
  {
    "model": "marcuscedricridia/absolute-o1-7b",
    "score": 0.188
  },
  {
    "model": "marcuscedricridia/pre-cursa-o1-v1.3",
    "score": 0.188
  },
  {
    "model": "marcuscedricridia/pre-cursa-o1-v1.6",
    "score": 0.188
  },
  {
    "model": "mergekit-community/SuperQwen-2.5-1.5B",
    "score": 0.188
  },
  {
    "model": "mistralai/Mistral-7B-Instruct-v0.3",
    "score": 0.188
  },
  {
    "model": "nbeerbower/Mahou-1.5-mistral-nemo-12B-lorablated",
    "score": 0.188
  },
  {
    "model": "nbeerbower/Mistral-Nemo-Moderne-12B-FFT-experimental",
    "score": 0.188
  },
  {
    "model": "nbeerbower/Nemoties-ChatML-12B",
    "score": 0.188
  },
  {
    "model": "nbeerbower/mistral-nemo-bophades3-12B",
    "score": 0.188
  },
  {
    "model": "netcat420/MFANN3bv0.24",
    "score": 0.188
  },
  {
    "model": "netcat420/MFANNv0.22.1",
    "score": 0.188
  },
  {
    "model": "netcat420/qwen2.5-MFANN-7b-SLERPv1.1",
    "score": 0.188
  },
  {
    "model": "ngxson/MiniThinky-v2-1B-Llama-3.2",
    "score": 0.188
  },
  {
    "model": "nothingiisreal/L3.1-8B-Celeste-V1.5",
    "score": 0.188
  },
  {
    "model": "ontocord/RedPajama-3B-v1-AutoRedteam-Harmless-only",
    "score": 0.188
  },
  {
    "model": "oopere/Llama-FinSent-S",
    "score": 0.188
  },
  {
    "model": "oopere/Llama-FinSent-S",
    "score": 0.188
  },
  {
    "model": "oopere/pruned40-llama-3.2-3b",
    "score": 0.188
  },
  {
    "model": "princeton-nlp/Llama-3-Instruct-8B-RRHF",
    "score": 0.188
  },
  {
    "model": "princeton-nlp/Llama-3-Instruct-8B-SimPO-v0.2",
    "score": 0.188
  },
  {
    "model": "princeton-nlp/Mistral-7B-Instruct-SimPO",
    "score": 0.188
  },
  {
    "model": "prithivMLmods/Calcium-Opus-14B-Elite-Stock",
    "score": 0.188
  },
  {
    "model": "prithivMLmods/Qwen2.5-14B-DeepSeek-R1-1M",
    "score": 0.188
  },
  {
    "model": "sabersalehk/Llama3-SimPO",
    "score": 0.188
  },
  {
    "model": "sci-m-wang/Phi-3-mini-4k-instruct-sa-v0.1",
    "score": 0.188
  },
  {
    "model": "shastraai/Shastra-LLAMA2-Math-Commonsense-SFT",
    "score": 0.188
  },
  {
    "model": "someon98/qwen-CoMa-0.5b",
    "score": 0.188
  },
  {
    "model": "suayptalha/Falcon3-Jessi-v0.4-7B-Slerp",
    "score": 0.188
  },
  {
    "model": "theprint/RuDolph-Hermes-7B",
    "score": 0.188
  },
  {
    "model": "tiiuae/Falcon3-Mamba-7B-Base",
    "score": 0.188
  },
  {
    "model": "tinycompany/ShawtyIsBad-e5-large",
    "score": 0.188
  },
  {
    "model": "tinycompany/ShawtyIsBad-nomic-moe",
    "score": 0.188
  },
  {
    "model": "tinycompany/SigmaBoi-bge-m3",
    "score": 0.188
  },
  {
    "model": "tinycompany/SigmaBoi-bgem3",
    "score": 0.188
  },
  {
    "model": "vicgalle/ConfigurableBeagle-11B",
    "score": 0.188
  },
  {
    "model": "xukp20/Llama-3-8B-Instruct-SPPO-score-Iter3_bt_8b-table-0.002",
    "score": 0.188
  },
  {
    "model": "xukp20/llama-3-8b-instruct-sppo-iter1-gp-2b-tau01-table",
    "score": 0.188
  },
  {
    "model": "yfzp/Llama-3-8B-Instruct-SPPO-Iter1_bt_2b-table",
    "score": 0.188
  },
  {
    "model": "yfzp/Llama-3-8B-Instruct-SPPO-Iter1_gp_2b-table",
    "score": 0.188
  },
  {
    "model": "yfzp/Llama-3-8B-Instruct-SPPO-Iter1_gp_8b-table",
    "score": 0.188
  },
  {
    "model": "ymcki/gemma-2-2b-ORPO-jpn-it-abliterated-18-merge",
    "score": 0.188
  },
  {
    "model": "yuvraj17/Llama3-8B-SuperNova-Spectrum-dare_ties",
    "score": 0.188
  },
  {
    "model": "yuvraj17/Llama3-8B-abliterated-Spectrum-slerp",
    "score": 0.188
  },
  {
    "model": "mistralai/Mistral-7B-Instruct-v0.1",
    "score": 0.184
  },
  {
    "model": "Daemontatox/Cogito-MIS",
    "score": 0.184
  },
  {
    "model": "DeepAutoAI/Explore_Llama-3.2-1B-Inst_v1",
    "score": 0.184
  },
  {
    "model": "DreadPoor/AnotherTest",
    "score": 0.184
  },
  {
    "model": "EleutherAI/gpt-j-6b",
    "score": 0.184
  },
  {
    "model": "EleutherAI/pythia-410m",
    "score": 0.184
  },
  {
    "model": "EpistemeAI/Athene-codegemma-2-7b-it-alpaca-v1.3",
    "score": 0.184
  },
  {
    "model": "EpistemeAI/Polypsyche-Llama-3.1-8B-Instruct-Agent-0.003-128K-code-ds-auto-Empathy",
    "score": 0.184
  },
  {
    "model": "Etherll/Chocolatine-3B-Instruct-DPO-Revised-Ties",
    "score": 0.184
  },
  {
    "model": "Etherll/Chocolatine-3B-Instruct-DPO-Revised-Ties-v2",
    "score": 0.184
  },
  {
    "model": "FlofloB/100k_fineweb_continued_pretraining_Qwen2.5-0.5B-Instruct_Unsloth_merged_16bit",
    "score": 0.184
  },
  {
    "model": "FlofloB/smollm2-135M_pretrained_1400k_fineweb_uncovai_human_removed",
    "score": 0.184
  },
  {
    "model": "FuJhen/ft-openhermes-25-mistral-7b-irca-dpo-pairs",
    "score": 0.184
  },
  {
    "model": "GuilhermeNaturaUmana/Nature-Reason-1.2-reallysmall",
    "score": 0.184
  },
  {
    "model": "GuilhermeNaturaUmana/Nature-Reason-1.2-reallysmall",
    "score": 0.184
  },
  {
    "model": "JackFram/llama-160m",
    "score": 0.184
  },
  {
    "model": "Jacoby746/Proto-Harpy-Spark-v0.1-7B",
    "score": 0.184
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPOP_5e-6-2ep_0alp_5lam",
    "score": 0.184
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_0.5_1e-7-2ep_0alp_0lam",
    "score": 0.184
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-5e-5",
    "score": 0.184
  },
  {
    "model": "JayHyeon/Qwen_0.5-MDPO_0.5_3e-7-3ep_0alp_0lam",
    "score": 0.184
  },
  {
    "model": "Kquant03/CognitiveFusion2-4x7B-BF16",
    "score": 0.184
  },
  {
    "model": "LLM360/K2",
    "score": 0.184
  },
  {
    "model": "Lawnakk/BBALAW1",
    "score": 0.184
  },
  {
    "model": "LeroyDyer/CheckPoint_R1",
    "score": 0.184
  },
  {
    "model": "LeroyDyer/LCARS_TOP_SCORE",
    "score": 0.184
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_Math_Student",
    "score": 0.184
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_Top_Student",
    "score": 0.184
  },
  {
    "model": "LilRg/ECE-1B-merge-PRYMMAL",
    "score": 0.184
  },
  {
    "model": "Luni/StarDust-12b-v1",
    "score": 0.184
  },
  {
    "model": "NAPS-ai/naps-llama-3_1-8b-instruct-v0.3",
    "score": 0.184
  },
  {
    "model": "Nekochu/Llama-3.1-8B-french-DPO",
    "score": 0.184
  },
  {
    "model": "Nexesenex/Llama_3.2_1b_RandomLego_RP_R1_0.1",
    "score": 0.184
  },
  {
    "model": "Nitral-AI/Captain-Eris_BMO-Violent-12B",
    "score": 0.184
  },
  {
    "model": "OEvortex/HelpingAI2.5-10B",
    "score": 0.184
  },
  {
    "model": "OmnicromsBrain/NeuralStar_FusionWriter_4x7b",
    "score": 0.184
  },
  {
    "model": "Open-Orca/Mistral-7B-OpenOrca",
    "score": 0.184
  },
  {
    "model": "PocketDoc/Dans-SakuraKaze-V1.0.0-12b",
    "score": 0.184
  },
  {
    "model": "Quazim0t0/ThinkPhi1.1-Tensors",
    "score": 0.184
  },
  {
    "model": "Qwen/Qwen1.5-14B",
    "score": 0.184
  },
  {
    "model": "Qwen/Qwen1.5-32B",
    "score": 0.184
  },
  {
    "model": "Qwen/Qwen2.5-0.5B-Instruct",
    "score": 0.184
  },
  {
    "model": "Qwen/Qwen2.5-0.5B-Instruct",
    "score": 0.184
  },
  {
    "model": "Qwen/Qwen2.5-3B",
    "score": 0.184
  },
  {
    "model": "Sakalti/Magro-7B-v1.1",
    "score": 0.184
  },
  {
    "model": "Sakalti/SJT-2.4B",
    "score": 0.184
  },
  {
    "model": "Sakalti/SakaMoe-3x1.6B-Instruct",
    "score": 0.184
  },
  {
    "model": "Sakalti/magro-7B",
    "score": 0.184
  },
  {
    "model": "Sao10K/MN-12B-Lyra-v3",
    "score": 0.184
  },
  {
    "model": "Stark2008/VisFlamCat",
    "score": 0.184
  },
  {
    "model": "T145/KRONOS-8B-V3",
    "score": 0.184
  },
  {
    "model": "T145/KRONOS-8B-V7",
    "score": 0.184
  },
  {
    "model": "ToastyPigeon/Sto-vo-kor-12B",
    "score": 0.184
  },
  {
    "model": "Triangle104/DS-R1-Distill-Q2.5-7B-RP",
    "score": 0.184
  },
  {
    "model": "Triangle104/Distilled-DarkPlanet-Allades-8B_TIES",
    "score": 0.184
  },
  {
    "model": "Tsunami-th/Tsunami-0.5x-7B-Instruct",
    "score": 0.184
  },
  {
    "model": "VAGOsolutions/Llama-3-SauerkrautLM-8b-Instruct",
    "score": 0.184
  },
  {
    "model": "VAGOsolutions/SauerkrautLM-7b-HerO",
    "score": 0.184
  },
  {
    "model": "VIRNECT/llama-3-Korean-8B",
    "score": 0.184
  },
  {
    "model": "VIRNECT/llama-3-Korean-8B",
    "score": 0.184
  },
  {
    "model": "ValiantLabs/Llama3.2-3B-Enigma",
    "score": 0.184
  },
  {
    "model": "YoungPanda/qwenqwen",
    "score": 0.184
  },
  {
    "model": "ZHLiu627/zephyr-7b-gemma-rpo-avg",
    "score": 0.184
  },
  {
    "model": "agentlans/Qwen2.5-0.5B-Instruct-CrashCourse-dropout",
    "score": 0.184
  },
  {
    "model": "allenai/Llama-3.1-Tulu-3-8B-SFT",
    "score": 0.184
  },
  {
    "model": "allura-org/Mistral-Small-Sisyphus-24b-2503",
    "score": 0.184
  },
  {
    "model": "belztjti/dtfgv",
    "score": 0.184
  },
  {
    "model": "braindao/DeepSeek-R1-Distill-Qwen-7B",
    "score": 0.184
  },
  {
    "model": "bunnycore/Qandora-2.5-7B-Creative",
    "score": 0.184
  },
  {
    "model": "bunnycore/Qwen2.5-7B-MixStock-Sce-V0.3",
    "score": 0.184
  },
  {
    "model": "carsenk/phi3.5_mini_exp_825_uncensored",
    "score": 0.184
  },
  {
    "model": "cluebbers/Llama-3.1-8B-paraphrase-type-generation-apty-sigmoid",
    "score": 0.184
  },
  {
    "model": "cognitivecomputations/dolphin-2.9.2-qwen2-72b",
    "score": 0.184
  },
  {
    "model": "djuna/MN-Chinofun-12B-3",
    "score": 0.184
  },
  {
    "model": "flammenai/flammen15-gutenberg-DPO-v1-7B",
    "score": 0.184
  },
  {
    "model": "godlikehhd/alpaca_data_full_3B",
    "score": 0.184
  },
  {
    "model": "godlikehhd/alpaca_data_sampled_ifd_5200",
    "score": 0.184
  },
  {
    "model": "google/gemma-2b-it",
    "score": 0.184
  },
  {
    "model": "google/mt5-small",
    "score": 0.184
  },
  {
    "model": "google/recurrentgemma-9b",
    "score": 0.184
  },
  {
    "model": "ibm-granite/granite-3.0-2b-instruct",
    "score": 0.184
  },
  {
    "model": "ibm-granite/granite-3.1-2b-base",
    "score": 0.184
  },
  {
    "model": "ibm-granite/granite-7b-instruct",
    "score": 0.184
  },
  {
    "model": "icefog72/Ice0.27-06.11-RP",
    "score": 0.184
  },
  {
    "model": "icefog72/Ice0.34b-14.11-RP",
    "score": 0.184
  },
  {
    "model": "icefog72/Ice0.40-20.11-RP",
    "score": 0.184
  },
  {
    "model": "icefog72/Ice0.39-19.11-RP",
    "score": 0.184
  },
  {
    "model": "icefog72/Ice0.51.1-16.01-RP",
    "score": 0.184
  },
  {
    "model": "icefog72/IceDrunkenCherryRP-7b",
    "score": 0.184
  },
  {
    "model": "icefog72/IceSakeRP-7b",
    "score": 0.184
  },
  {
    "model": "icefog72/IceSakeV6RP-7b",
    "score": 0.184
  },
  {
    "model": "jaspionjader/bh-7",
    "score": 0.184
  },
  {
    "model": "jeffmeloy/Qwen2.5-7B-olm-v1.5",
    "score": 0.184
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_ties-density-0.9",
    "score": 0.184
  },
  {
    "model": "jpacifico/Lucie-7B-Instruct-DPO-v1.1.3",
    "score": 0.184
  },
  {
    "model": "llmat/Mistral-v0.3-7B-ORPO",
    "score": 0.184
  },
  {
    "model": "llmat/Mistral-v0.3-7B-ORPO",
    "score": 0.184
  },
  {
    "model": "lmsys/vicuna-7b-v1.3",
    "score": 0.184
  },
  {
    "model": "marcuscedricridia/pre-cursa-o1-v1.2",
    "score": 0.184
  },
  {
    "model": "marcuscedricridia/pre-cursa-o1-v1.4",
    "score": 0.184
  },
  {
    "model": "meditsolutions/Llama-3.2-SUN-2.4B-v1.0.0",
    "score": 0.184
  },
  {
    "model": "migtissera/Tess-3-Mistral-Nemo-12B",
    "score": 0.184
  },
  {
    "model": "nbeerbower/Mistral-Gutenberg-Doppel-7B-FFT",
    "score": 0.184
  },
  {
    "model": "nbeerbower/mistral-nemo-kartoffel-12B",
    "score": 0.184
  },
  {
    "model": "nbeerbower/mistral-nemo-wissenschaft-12B",
    "score": 0.184
  },
  {
    "model": "netcat420/MFANNv0.20",
    "score": 0.184
  },
  {
    "model": "netcat420/MFANNv0.21",
    "score": 0.184
  },
  {
    "model": "newsbang/Homer-v0.4-Qwen2.5-7B",
    "score": 0.184
  },
  {
    "model": "nguyentd/FinancialAdvice-Qwen2.5-7B",
    "score": 0.184
  },
  {
    "model": "noname0202/llama-math-1b-r32-test",
    "score": 0.184
  },
  {
    "model": "nothingiisreal/MN-12B-Starcannon-v2",
    "score": 0.184
  },
  {
    "model": "olabs-ai/reflection_model",
    "score": 0.184
  },
  {
    "model": "ontocord/wide_3b_sft_stage1.1-ss1-no_redteam_skg_poem.no_issue",
    "score": 0.184
  },
  {
    "model": "openai-community/gpt2-xl",
    "score": 0.184
  },
  {
    "model": "openchat/openchat-3.5-1210",
    "score": 0.184
  },
  {
    "model": "princeton-nlp/Llama-3-Instruct-8B-CPO",
    "score": 0.184
  },
  {
    "model": "princeton-nlp/Mistral-7B-Base-SFT-RRHF",
    "score": 0.184
  },
  {
    "model": "prithivMLmods/FastThink-0.5B-Tiny",
    "score": 0.184
  },
  {
    "model": "prithivMLmods/GWQ2b",
    "score": 0.184
  },
  {
    "model": "riaz/FineLlama-3.1-8B",
    "score": 0.184
  },
  {
    "model": "riaz/FineLlama-3.1-8B",
    "score": 0.184
  },
  {
    "model": "rombodawg/Rombos-LLM-V2.5.1-Qwen-3b",
    "score": 0.184
  },
  {
    "model": "rombodawg/Rombos-LLM-V2.5.1-Qwen-3b",
    "score": 0.184
  },
  {
    "model": "sequelbox/Llama3.1-8B-PlumChat",
    "score": 0.184
  },
  {
    "model": "sometimesanotion/Qwen2.5-7B-Gordion-v0.1-Prose",
    "score": 0.184
  },
  {
    "model": "tinycompany/ShawtyIsBad-ib",
    "score": 0.184
  },
  {
    "model": "togethercomputer/GPT-JT-6B-v1",
    "score": 0.184
  },
  {
    "model": "vhab10/Llama-3.1-8B-Base-Instruct-SLERP",
    "score": 0.184
  },
  {
    "model": "vicgalle/Roleplay-Llama-3-8B",
    "score": 0.184
  },
  {
    "model": "win10/Norns-Qwen2.5-7B",
    "score": 0.184
  },
  {
    "model": "xinchen9/Llama3.1_CoT",
    "score": 0.184
  },
  {
    "model": "xukp20/Llama-3-8B-Instruct-SPPO-Iter3_gp_2b-table",
    "score": 0.184
  },
  {
    "model": "yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_gp_2b-table-0.001",
    "score": 0.184
  },
  {
    "model": "yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_gp_8b-table-0.002",
    "score": 0.184
  },
  {
    "model": "ylalain/ECE-PRYMMAL-YL-1B-SLERP-V8",
    "score": 0.184
  },
  {
    "model": "ymcki/gemma-2-2b-ORPO-jpn-it-abliterated-18",
    "score": 0.184
  },
  {
    "model": "01-ai/Yi-34B-200K",
    "score": 0.18
  },
  {
    "model": "AGI-0/smartllama3.1-8B-001",
    "score": 0.18
  },
  {
    "model": "microsoft/phi-2",
    "score": 0.18
  },
  {
    "model": "AALF/FuseChat-Llama-3.1-8B-Instruct-preview",
    "score": 0.18
  },
  {
    "model": "01-ai/Yi-1.5-9B",
    "score": 0.18
  },
  {
    "model": "Amu/t1-1.5B",
    "score": 0.18
  },
  {
    "model": "AuraIndustries/Aura-8B",
    "score": 0.18
  },
  {
    "model": "BAAI/Infinity-Instruct-3M-0625-Mistral-7B",
    "score": 0.18
  },
  {
    "model": "CYFRAGOVPL/Llama-PLLuM-8B-base",
    "score": 0.18
  },
  {
    "model": "CYFRAGOVPL/Llama-PLLuM-8B-chat",
    "score": 0.18
  },
  {
    "model": "CYFRAGOVPL/PLLuM-12B-nc-base",
    "score": 0.18
  },
  {
    "model": "Changgil/K2S3-v0.1",
    "score": 0.18
  },
  {
    "model": "CoolSpring/Qwen2-0.5B-Abyme-merge2",
    "score": 0.18
  },
  {
    "model": "CortexLM/btlm-7b-base-v0.2",
    "score": 0.18
  },
  {
    "model": "Danielbrdz/Barcenas-Llama3-8b-ORPO",
    "score": 0.18
  },
  {
    "model": "Dans-DiscountModels/12b-mn-dans-reasoning-test-2",
    "score": 0.18
  },
  {
    "model": "DavidAU/L3-Lumimaid-12.2B-v0.1-OAS-Instruct",
    "score": 0.18
  },
  {
    "model": "DeepMount00/Qwen2-1.5B-Ita",
    "score": 0.18
  },
  {
    "model": "DreadPoor/Nother_One-8B-Model_Stock",
    "score": 0.18
  },
  {
    "model": "EpistemeAI/Athena-gemma-2-2b-it-Philos",
    "score": 0.18
  },
  {
    "model": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.004-128K-code-COT",
    "score": 0.18
  },
  {
    "model": "EpistemeAI2/Athene-codegemma-2-7b-it-alpaca-v1.2",
    "score": 0.18
  },
  {
    "model": "EpistemeAI2/Fireball-Alpaca-Llama3.1.03-8B-Philos",
    "score": 0.18
  },
  {
    "model": "EpistemeAI2/Fireball-Alpaca-Llama3.1.06-8B-Philos-dpo",
    "score": 0.18
  },
  {
    "model": "FINGU-AI/L3-8B",
    "score": 0.18
  },
  {
    "model": "FuseAI/FuseChat-Llama-3.1-8B-Instruct",
    "score": 0.18
  },
  {
    "model": "GritLM/GritLM-8x7B-KTO",
    "score": 0.18
  },
  {
    "model": "HoangHa/Pensez-Llama3.1-8B",
    "score": 0.18
  },
  {
    "model": "HuggingFaceTB/SmolLM2-1.7B",
    "score": 0.18
  },
  {
    "model": "JayHyeon/Qwen-0.5B-eDPO-5epoch",
    "score": 0.18
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-1e-4-3ep",
    "score": 0.18
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-4-5ep",
    "score": 0.18
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep",
    "score": 0.18
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_3e-6-2ep_0alp_0lam",
    "score": 0.18
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-7e-5",
    "score": 0.18
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-7e-5-2ep",
    "score": 0.18
  },
  {
    "model": "JayHyeon/Qwen_0.5-DPOP_3e-6-2ep_0alp_5lam",
    "score": 0.18
  },
  {
    "model": "JayHyeon/Qwen_0.5-DPOP_3e-6-3ep_0alp_5lam",
    "score": 0.18
  },
  {
    "model": "JayHyeon/Qwen_0.5-IRPO_3e-6-3ep_1alp_0lam",
    "score": 0.18
  },
  {
    "model": "JayHyeon/Qwen_0.5-MDPO_0.3_3e-6-3ep_0alp_0lam",
    "score": 0.18
  },
  {
    "model": "JayHyeon/Qwen_0.5-MDPO_0.5_7e-6-3ep_0alp_0lam",
    "score": 0.18
  },
  {
    "model": "JayHyeon/Qwen_0.5-VIPO_5e-7-3ep_30vpo_const",
    "score": 0.18
  },
  {
    "model": "Kimargin/GPT-NEO-1.3B-wiki",
    "score": 0.18
  },
  {
    "model": "KingNish/qwen-1b-continued",
    "score": 0.18
  },
  {
    "model": "KingNish/qwen-1b-continued-v2",
    "score": 0.18
  },
  {
    "model": "Kquant03/L3-Pneuma-8B",
    "score": 0.18
  },
  {
    "model": "LenguajeNaturalAI/leniachat-gemma-2b-v0",
    "score": 0.18
  },
  {
    "model": "LeroyDyer/CheckPoint_B",
    "score": 0.18
  },
  {
    "model": "LeroyDyer/SpydazWeb_AI_HumanAI_011_INSTRUCT",
    "score": 0.18
  },
  {
    "model": "LimYeri/CodeMind-Llama3-8B-unsloth_v3-merged",
    "score": 0.18
  },
  {
    "model": "Lyte/Llama-3.1-8B-Instruct-Reasoner-1o1_v0.3",
    "score": 0.18
  },
  {
    "model": "Magpie-Align/Llama-3-8B-Magpie-Align-SFT-v0.3",
    "score": 0.18
  },
  {
    "model": "NCSOFT/Llama-VARCO-8B-Instruct",
    "score": 0.18
  },
  {
    "model": "NJS26/NJS_777",
    "score": 0.18
  },
  {
    "model": "NbAiLab/nb-llama-3.1-8B-sft",
    "score": 0.18
  },
  {
    "model": "Nexesenex/Llama_3.2_1b_OpenTree_R1_0.1",
    "score": 0.18
  },
  {
    "model": "Nexesenex/Llama_3.2_3b_Kermes_v2",
    "score": 0.18
  },
  {
    "model": "Novaciano/La_Mejor_Mezcla-3.2-1B",
    "score": 0.18
  },
  {
    "model": "Novaciano/Sigil-Of-Satan-3.2-1B",
    "score": 0.18
  },
  {
    "model": "OEvortex/HelpingAI-3B-reloaded",
    "score": 0.18
  },
  {
    "model": "Omkar1102/code-yi",
    "score": 0.18
  },
  {
    "model": "Omkar1102/code-yi",
    "score": 0.18
  },
  {
    "model": "OpenLLM-France/Lucie-7B-Instruct-human-data",
    "score": 0.18
  },
  {
    "model": "PocketDoc/Dans-PersonalityEngine-V1.1.0-12b",
    "score": 0.18
  },
  {
    "model": "Qwen/Qwen2-1.5B-Instruct",
    "score": 0.18
  },
  {
    "model": "Qwen/Qwen2-1.5B",
    "score": 0.18
  },
  {
    "model": "Ro-xe/FMixIA-7B-SLERP-27",
    "score": 0.18
  },
  {
    "model": "Sakalti/Saka-1.5B",
    "score": 0.18
  },
  {
    "model": "SenseLLM/ReflectionCoder-DS-33B",
    "score": 0.18
  },
  {
    "model": "SeppeV/SmolLM_pretrained_with_sft_trained_with_1pc_data_on_a_preference_dpo",
    "score": 0.18
  },
  {
    "model": "StelleX/Qwen2.5_Math_7B_Cot",
    "score": 0.18
  },
  {
    "model": "T145/KRONOS-8B-V1-P3",
    "score": 0.18
  },
  {
    "model": "T145/KRONOS-8B-V6",
    "score": 0.18
  },
  {
    "model": "THUDM/glm-4-9b",
    "score": 0.18
  },
  {
    "model": "Triangle104/DS-R1-Llama-8B-Harmony",
    "score": 0.18
  },
  {
    "model": "Triangle104/Q2.5-EvaHumane-RP",
    "score": 0.18
  },
  {
    "model": "UCLA-AGI/Mistral7B-PairRM-SPPO-Iter1",
    "score": 0.18
  },
  {
    "model": "VAGOsolutions/SauerkrautLM-gemma-2-2b-it",
    "score": 0.18
  },
  {
    "model": "Youlln/ECE-PRYMMAL1B-FT-V1",
    "score": 0.18
  },
  {
    "model": "Youlln/ECE-Qwen0.5B-FT-V2",
    "score": 0.18
  },
  {
    "model": "ZHLiu627/zephyr-7b-gemma-dpo-avg",
    "score": 0.18
  },
  {
    "model": "allknowingroger/MixTAO-19B-pass",
    "score": 0.18
  },
  {
    "model": "allknowingroger/Qwen2.5-7B-task7",
    "score": 0.18
  },
  {
    "model": "ashercn97/a1-v0.0.1",
    "score": 0.18
  },
  {
    "model": "axolotl-ai-co/romulus-mistral-nemo-12b-simpo",
    "score": 0.18
  },
  {
    "model": "bluuwhale/L3-SthenoMaid-8B-V1",
    "score": 0.18
  },
  {
    "model": "bunnycore/Llama-3.2-3B-Della",
    "score": 0.18
  },
  {
    "model": "bunnycore/QandoraExp-7B",
    "score": 0.18
  },
  {
    "model": "cognitivecomputations/dolphin-2.9.4-gemma2-2b",
    "score": 0.18
  },
  {
    "model": "cpayne1303/llama-43m-beta",
    "score": 0.18
  },
  {
    "model": "cpayne1303/llama-43m-beta",
    "score": 0.18
  },
  {
    "model": "databricks/dbrx-base",
    "score": 0.18
  },
  {
    "model": "databricks/dolly-v1-6b",
    "score": 0.18
  },
  {
    "model": "deepseek-ai/deepseek-moe-16b-base",
    "score": 0.18
  },
  {
    "model": "ehristoforu/SoRu-0009",
    "score": 0.18
  },
  {
    "model": "failspy/Meta-Llama-3-8B-Instruct-abliterated-v3",
    "score": 0.18
  },
  {
    "model": "fblgit/UNA-SimpleSmaug-34b-v1beta",
    "score": 0.18
  },
  {
    "model": "godlikehhd/alpaca_data_ifd_max_2600",
    "score": 0.18
  },
  {
    "model": "godlikehhd/ifd_new_correct_all_sample_2500_qwen",
    "score": 0.18
  },
  {
    "model": "google/gemma-2-2b-it",
    "score": 0.18
  },
  {
    "model": "google/gemma-2-9b",
    "score": 0.18
  },
  {
    "model": "huggyllama/llama-7b",
    "score": 0.18
  },
  {
    "model": "huu-ontocord/wide_3b_orpo_stage1.1-ss1-orpo3",
    "score": 0.18
  },
  {
    "model": "ibm-granite/granite-3.1-8b-instruct",
    "score": 0.18
  },
  {
    "model": "ibm-granite/granite-3.2-8b-instruct",
    "score": 0.18
  },
  {
    "model": "icefog72/Ice0.78-02.02-RP",
    "score": 0.18
  },
  {
    "model": "jebish7/Nemotron-4-Mini-Hindi-4B-Base",
    "score": 0.18
  },
  {
    "model": "jeffmeloy/Qwen2.5-7B-olm-v1.1",
    "score": 0.18
  },
  {
    "model": "jiangxinyang-shanda/Homer-LLama3-8B",
    "score": 0.18
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.3",
    "score": 0.18
  },
  {
    "model": "jpacifico/Lucie-7B-Instruct-DPO-v1.1",
    "score": 0.18
  },
  {
    "model": "jsfs11/MixtureofMerges-MoE-4x7b-v4",
    "score": 0.18
  },
  {
    "model": "jsfs11/MixtureofMerges-MoE-4x7b-v5",
    "score": 0.18
  },
  {
    "model": "khoantap/llama-breadcrumbs-ties-merge",
    "score": 0.18
  },
  {
    "model": "khoantap/llama-slerp-merge",
    "score": 0.18
  },
  {
    "model": "kms7530/chemeng_llama-3-8b-Instruct-bnb-4bit_24_1_100_1",
    "score": 0.18
  },
  {
    "model": "ladydaina/ECE-FDF",
    "score": 0.18
  },
  {
    "model": "leafspark/Llama-3.1-8B-MultiReflection-Instruct",
    "score": 0.18
  },
  {
    "model": "lkoenig/BBAI_200_Gemma",
    "score": 0.18
  },
  {
    "model": "llnYou/ECE-PRYMMAL-YL-1B-SLERP-V6",
    "score": 0.18
  },
  {
    "model": "lunahr/thea-3b-50r-u1",
    "score": 0.18
  },
  {
    "model": "magnifi/Phi3_intent_v56_3_w_unknown_5_lr_0.002",
    "score": 0.18
  },
  {
    "model": "maldv/badger-kappa-llama-3-8b",
    "score": 0.18
  },
  {
    "model": "marcuscedricridia/cursa-o1-7b-v1.2-normalize-false",
    "score": 0.18
  },
  {
    "model": "marcuscedricridia/olmner-7b",
    "score": 0.18
  },
  {
    "model": "ministral/Ministral-3b-instruct",
    "score": 0.18
  },
  {
    "model": "moeru-ai/L3.1-Moe-4x8B-v0.1",
    "score": 0.18
  },
  {
    "model": "mosama/Qwen2.5-1.5B-Instruct-CoT-Reflection",
    "score": 0.18
  },
  {
    "model": "nbeerbower/BigKartoffel-mistral-nemo-20B",
    "score": 0.18
  },
  {
    "model": "nbeerbower/Dumpling-Qwen2.5-1.5B",
    "score": 0.18
  },
  {
    "model": "nbeerbower/Mistral-Nemo-Prism-12B-v2",
    "score": 0.18
  },
  {
    "model": "nbeerbower/gemma2-gutenberg-27B",
    "score": 0.18
  },
  {
    "model": "neopolita/jessi-v0.1-bf16-falcon3-7b-instruct",
    "score": 0.18
  },
  {
    "model": "neopolita/jessi-v0.6-falcon3-7b-instruct",
    "score": 0.18
  },
  {
    "model": "netcat420/MFANN3bv0.19",
    "score": 0.18
  },
  {
    "model": "netcat420/MFANN3bv0.20",
    "score": 0.18
  },
  {
    "model": "netcat420/Qwen2.5-Coder-Scholar-7B-Abliterated-MFANN",
    "score": 0.18
  },
  {
    "model": "netcat420/qwen2.5-MFANN-7b-SLERP-V1.2",
    "score": 0.18
  },
  {
    "model": "netcat420/qwen2.5-MFANN-7b-v1.1",
    "score": 0.18
  },
  {
    "model": "noname0202/llama-math-1b-r16-0to512tokens-test",
    "score": 0.18
  },
  {
    "model": "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
    "score": 0.18
  },
  {
    "model": "occiglot/occiglot-7b-es-en-instruct",
    "score": 0.18
  },
  {
    "model": "oobabooga/CodeBooga-34B-v0.1",
    "score": 0.18
  },
  {
    "model": "pankajmathur/orca_mini_v9_5_1B-Instruct_preview",
    "score": 0.18
  },
  {
    "model": "pankajmathur/orca_mini_v9_5_3B-Instruct",
    "score": 0.18
  },
  {
    "model": "princeton-nlp/Llama-3-Base-8B-SFT-IPO",
    "score": 0.18
  },
  {
    "model": "princeton-nlp/Mistral-7B-Instruct-CPO",
    "score": 0.18
  },
  {
    "model": "princeton-nlp/Mistral-7B-Instruct-RRHF",
    "score": 0.18
  },
  {
    "model": "prithivMLmods/Bellatrix-Tiny-1.5B-R1",
    "score": 0.18
  },
  {
    "model": "qingy2024/Qwarkstar-4B",
    "score": 0.18
  },
  {
    "model": "rombodawg/Rombos-Coder-V2.5-Qwen-7b",
    "score": 0.18
  },
  {
    "model": "shivam9980/mistral-7b-news-cnn-merged",
    "score": 0.18
  },
  {
    "model": "sumink/ftgpt",
    "score": 0.18
  },
  {
    "model": "sunbaby/BrainCog-8B-0.1-Instruct",
    "score": 0.18
  },
  {
    "model": "theprint/Code-Llama-Bagel-8B",
    "score": 0.18
  },
  {
    "model": "theprint/ReWiz-7B",
    "score": 0.18
  },
  {
    "model": "theprint/ReWiz-Llama-3.2-3B",
    "score": 0.18
  },
  {
    "model": "vicgalle/Merge-Mixtral-Prometheus-8x7B",
    "score": 0.18
  },
  {
    "model": "vonjack/Qwen2.5-Coder-0.5B-Merged",
    "score": 0.18
  },
  {
    "model": "xkp24/Llama-3-8B-Instruct-SPPO-Iter2_gp_8b-table",
    "score": 0.18
  },
  {
    "model": "xukp20/Llama-3-8B-Instruct-SPPO-Iter3_gp_8b-table",
    "score": 0.18
  },
  {
    "model": "AGI-0/Artificium-llama3.1-8B-001",
    "score": 0.176
  },
  {
    "model": "01-ai/Yi-9B",
    "score": 0.176
  },
  {
    "model": "Azure99/blossom-v5-32b",
    "score": 0.176
  },
  {
    "model": "BAAI/Infinity-Instruct-7M-0729-mistral-7B",
    "score": 0.176
  },
  {
    "model": "BAAI/Infinity-Instruct-7M-Gen-mistral-7B",
    "score": 0.176
  },
  {
    "model": "BramVanroy/fietje-2-chat",
    "score": 0.176
  },
  {
    "model": "CausalLM/14B",
    "score": 0.176
  },
  {
    "model": "Daemontatox/AetherTOT",
    "score": 0.176
  },
  {
    "model": "Daemontatox/AetherTOT",
    "score": 0.176
  },
  {
    "model": "Daemontatox/PixelParse_AI",
    "score": 0.176
  },
  {
    "model": "DavidAU/L3-Stheno-Maid-Blackroot-Grand-HORROR-16B",
    "score": 0.176
  },
  {
    "model": "DavidAU/Qwen2.5-MOE-2X7B-DeepSeek-Abliterated-Censored-19B",
    "score": 0.176
  },
  {
    "model": "DebateLabKIT/Llama-3.1-Argunaut-1-8B-SFT",
    "score": 0.176
  },
  {
    "model": "DeepMount00/Llama-3-8b-Ita",
    "score": 0.176
  },
  {
    "model": "DeepMount00/Qwen2-1.5B-Ita_v6",
    "score": 0.176
  },
  {
    "model": "DoppelReflEx/MN-12B-LilithFrame-Experiment-2",
    "score": 0.176
  },
  {
    "model": "DoppelReflEx/MN-12B-Mimicore-Orochi-v3-Experiment",
    "score": 0.176
  },
  {
    "model": "Edgerunners/meta-llama-3-8b-instruct-hf-ortho-baukit-34fail-3000total-bf16",
    "score": 0.176
  },
  {
    "model": "Epiculous/Azure_Dusk-v0.2",
    "score": 0.176
  },
  {
    "model": "EpistemeAI/Fireball-12B-v1.13a-philosophers",
    "score": 0.176
  },
  {
    "model": "EpistemeAI/Fireball-Alpaca-Llama-3.1-8B-Philos-DPO-200",
    "score": 0.176
  },
  {
    "model": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Math",
    "score": 0.176
  },
  {
    "model": "EpistemeAI2/Fireball-Alpaca-Llama3.1-8B-Philos",
    "score": 0.176
  },
  {
    "model": "FuseAI/FuseChat-7B-v2.0",
    "score": 0.176
  },
  {
    "model": "HuggingFaceH4/zephyr-7b-alpha",
    "score": 0.176
  },
  {
    "model": "Jacoby746/Inf-Silent-Kunoichi-v0.1-2x7B",
    "score": 0.176
  },
  {
    "model": "JayHyeon/Qwen-0.5B-DPO-5epoch",
    "score": 0.176
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-1e-4",
    "score": 0.176
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-1e-5-2ep",
    "score": 0.176
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_1e-7-3ep_0alp_0lam",
    "score": 0.176
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_0.5_1e-7-1ep_0alp_0lam",
    "score": 0.176
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-IRPO_5e-7-3ep_1alp_0lam",
    "score": 0.176
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_2e-6-3ep_0alp_0lam",
    "score": 0.176
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_5e-6-2ep_0alp_0lam",
    "score": 0.176
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_5e-7_1ep_0alp_0lam",
    "score": 0.176
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-3ep",
    "score": 0.176
  },
  {
    "model": "JayHyeon/Qwen_0.5-DPOP_1e-7-3ep_0alp_5lam",
    "score": 0.176
  },
  {
    "model": "JayHyeon/Qwen_0.5-DPOP_3e-7-2ep_0alp_5lam",
    "score": 0.176
  },
  {
    "model": "JayHyeon/Qwen_0.5-IRPO_3e-7-1ep_1alp_0lam",
    "score": 0.176
  },
  {
    "model": "JayHyeon/Qwen_0.5-MDPO_0.5_6e-6-3ep_0alp_0lam",
    "score": 0.176
  },
  {
    "model": "JayHyeon/Qwen_0.5-VDPO_5e-7-1ep_10vpo_const",
    "score": 0.176
  },
  {
    "model": "Josephgflowers/TinyLlama-v1.1-Cinders-World",
    "score": 0.176
  },
  {
    "model": "KingNish/Qwen2.5-0.5b-Test-ft",
    "score": 0.176
  },
  {
    "model": "KingNish/Reasoning-0.5b",
    "score": 0.176
  },
  {
    "model": "LEESM/llama-2-7b-hf-lora-oki100p",
    "score": 0.176
  },
  {
    "model": "LeroyDyer/SpydazWeb_HumanAI_M1",
    "score": 0.176
  },
  {
    "model": "LeroyDyer/SpydazWeb_HumanAI_M3",
    "score": 0.176
  },
  {
    "model": "Magpie-Align/Llama-3-8B-Magpie-Align-SFT-v0.1",
    "score": 0.176
  },
  {
    "model": "MaziyarPanahi/Llama-3-8B-Instruct-v0.10",
    "score": 0.176
  },
  {
    "model": "MaziyarPanahi/Qwen1.5-MoE-A2.7B-Wikihow",
    "score": 0.176
  },
  {
    "model": "ModelCloud/Llama-3.2-1B-Instruct-gptqmodel-4bit-vortex-v1",
    "score": 0.176
  },
  {
    "model": "Nekochu/Llama-3.1-8B-German-ORPO",
    "score": 0.176
  },
  {
    "model": "Nexesenex/Llama_3.2_1b_AquaSyn_0.11",
    "score": 0.176
  },
  {
    "model": "Nitral-AI/Nera_Noctis-12B",
    "score": 0.176
  },
  {
    "model": "Norquinal/Delta",
    "score": 0.176
  },
  {
    "model": "NousResearch/DeepHermes-3-Mistral-24B-Preview",
    "score": 0.176
  },
  {
    "model": "NousResearch/Hermes-2-Pro-Llama-3-8B",
    "score": 0.176
  },
  {
    "model": "NousResearch/Nous-Hermes-2-Mistral-7B-DPO",
    "score": 0.176
  },
  {
    "model": "NousResearch/Nous-Hermes-2-SOLAR-10.7B",
    "score": 0.176
  },
  {
    "model": "NousResearch/Yarn-Llama-2-7b-128k",
    "score": 0.176
  },
  {
    "model": "Novaciano/Cerberus-3.2-1B",
    "score": 0.176
  },
  {
    "model": "Novaciano/FuseChat-3.2-1B-GRPO_Creative_RP",
    "score": 0.176
  },
  {
    "model": "OpenBuddy/openbuddy-llama3.2-1b-v23.1-131k",
    "score": 0.176
  },
  {
    "model": "Q-bert/MetaMath-1B",
    "score": 0.176
  },
  {
    "model": "Qwen/Qwen1.5-1.8B",
    "score": 0.176
  },
  {
    "model": "Qwen/Qwen2.5-0.5B",
    "score": 0.176
  },
  {
    "model": "Qwen/Qwen2.5-Coder-7B-Instruct",
    "score": 0.176
  },
  {
    "model": "Qwen/Qwen2.5-Coder-7B-Instruct",
    "score": 0.176
  },
  {
    "model": "Qwen/Qwen2.5-Math-7B-Instruct",
    "score": 0.176
  },
  {
    "model": "Replete-AI/Replete-Coder-Qwen2-1.5b",
    "score": 0.176
  },
  {
    "model": "SaisExperiments/Evil-Alpaca-3B-L3.2",
    "score": 0.176
  },
  {
    "model": "SaisExperiments/Gemma-2-2B-Stheno-Filtered",
    "score": 0.176
  },
  {
    "model": "Supichi/NJS26",
    "score": 0.176
  },
  {
    "model": "T145/ZEUS-8B-V17-abliterated-V2",
    "score": 0.176
  },
  {
    "model": "TencentARC/Mistral_Pro_8B_v0.1",
    "score": 0.176
  },
  {
    "model": "Triangle104/Porpoise-R1-Llama3.2-3b",
    "score": 0.176
  },
  {
    "model": "ValiantLabs/Llama3.2-3B-Esper2",
    "score": 0.176
  },
  {
    "model": "Weyaxi/Einstein-v6.1-developed-by-Weyaxi-Llama3-8B",
    "score": 0.176
  },
  {
    "model": "Youlln/3PRYMMAL-PHI3-3B-SLERP",
    "score": 0.176
  },
  {
    "model": "Yuma42/KangalKhan-RawRuby-7B",
    "score": 0.176
  },
  {
    "model": "abhishek/autotrain-llama3-orpo-v2",
    "score": 0.176
  },
  {
    "model": "allenai/OLMo-7B-Instruct-hf",
    "score": 0.176
  },
  {
    "model": "allenai/OLMoE-1B-7B-0125-Instruct",
    "score": 0.176
  },
  {
    "model": "allknowingroger/LimyQstar-7B-slerp",
    "score": 0.176
  },
  {
    "model": "allknowingroger/Ph3merge3-14B",
    "score": 0.176
  },
  {
    "model": "allura-org/MoE-Girl-1BA-7BT",
    "score": 0.176
  },
  {
    "model": "appvoid/arco-2",
    "score": 0.176
  },
  {
    "model": "appvoid/arco-2-instruct",
    "score": 0.176
  },
  {
    "model": "baebee/mergekit-model_stock-nzjnheg",
    "score": 0.176
  },
  {
    "model": "bamec66557/VICIOUS_MESH-12B-EPSILON",
    "score": 0.176
  },
  {
    "model": "berkeley-nest/Starling-LM-7B-alpha",
    "score": 0.176
  },
  {
    "model": "bigscience/bloom-560m",
    "score": 0.176
  },
  {
    "model": "braindao/DeepSeek-R1-Distill-Qwen-14B-Blunt-Uncensored-Blunt",
    "score": 0.176
  },
  {
    "model": "brgx53/3Blareneg-ECE-PRYMMAL-Martial",
    "score": 0.176
  },
  {
    "model": "bunnycore/CyberCore-Qwen-2.1-7B",
    "score": 0.176
  },
  {
    "model": "bunnycore/QandoraExp-7B-v2",
    "score": 0.176
  },
  {
    "model": "chargoddard/prometheus-2-llama-3-8b",
    "score": 0.176
  },
  {
    "model": "chujiezheng/Mistral7B-PairRM-SPPO-ExPO",
    "score": 0.176
  },
  {
    "model": "dustinwloring1988/Reflexis-8b-chat-v1",
    "score": 0.176
  },
  {
    "model": "failspy/Llama-3-8B-Instruct-abliterated",
    "score": 0.176
  },
  {
    "model": "fluently-lm/Llama-TI-8B",
    "score": 0.176
  },
  {
    "model": "grimjim/HuatuoSkywork-o1-Llama-3.1-8B",
    "score": 0.176
  },
  {
    "model": "h2oai/h2o-danube3-4b-base",
    "score": 0.176
  },
  {
    "model": "hotmailuser/FalconSlerp3-7B",
    "score": 0.176
  },
  {
    "model": "huihui-ai/Qwen2.5-7B-Instruct-abliterated-v2",
    "score": 0.176
  },
  {
    "model": "ibm-granite/granite-3.0-1b-a400m-base",
    "score": 0.176
  },
  {
    "model": "ibm-granite/granite-3.0-2b-base",
    "score": 0.176
  },
  {
    "model": "ibm-granite/granite-3.0-8b-instruct",
    "score": 0.176
  },
  {
    "model": "jaspionjader/PRP-Kosmos-EVAA-8B",
    "score": 0.176
  },
  {
    "model": "jaspionjader/bh-63",
    "score": 0.176
  },
  {
    "model": "jebcarter/psyonic-cetacean-20B",
    "score": 0.176
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.7",
    "score": 0.176
  },
  {
    "model": "jpacifico/Chocolatine-3B-Instruct-DPO-v1.0",
    "score": 0.176
  },
  {
    "model": "kavonalds/Lancer-1-1b-Instruct",
    "score": 0.176
  },
  {
    "model": "langgptai/Qwen-las-v0.1",
    "score": 0.176
  },
  {
    "model": "marcuscedricridia/olmner-della-7b",
    "score": 0.176
  },
  {
    "model": "marcuscedricridia/pre-cursa-o1",
    "score": 0.176
  },
  {
    "model": "meta-llama/Llama-2-7b-hf",
    "score": 0.176
  },
  {
    "model": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "score": 0.176
  },
  {
    "model": "mistralai/Mixtral-8x7B-v0.1",
    "score": 0.176
  },
  {
    "model": "mistralai/Mixtral-8x7B-v0.1",
    "score": 0.176
  },
  {
    "model": "mukaj/Llama-3.1-Hawkish-8B",
    "score": 0.176
  },
  {
    "model": "nbeerbower/DoppelKartoffel-Mistral-Nemo-23B",
    "score": 0.176
  },
  {
    "model": "nbeerbower/EVA-abliterated-TIES-Qwen2.5-1.5B",
    "score": 0.176
  },
  {
    "model": "nbeerbower/mistral-nemo-gutenberg-12B-v2",
    "score": 0.176
  },
  {
    "model": "necva/replica-IEPile",
    "score": 0.176
  },
  {
    "model": "neopolita/jessi-v0.4-falcon3-7b-instruct",
    "score": 0.176
  },
  {
    "model": "nlpguy/StableProse",
    "score": 0.176
  },
  {
    "model": "ontocord/wide_3b_sft_stag1.2-lyrical_news_software_howto_formattedtext-merge",
    "score": 0.176
  },
  {
    "model": "ontocord/wide_3b_sft_stage1.2-ss1-expert_software",
    "score": 0.176
  },
  {
    "model": "pankajmathur/orca_mini_v7_7b",
    "score": 0.176
  },
  {
    "model": "pankajmathur/orca_mini_v9_4_70B",
    "score": 0.176
  },
  {
    "model": "princeton-nlp/Mistral-7B-Instruct-ORPO",
    "score": 0.176
  },
  {
    "model": "sequelbox/Llama3.1-8B-MOTH",
    "score": 0.176
  },
  {
    "model": "sethuiyer/LlamaZero-3.1-8B-Experimental-1208",
    "score": 0.176
  },
  {
    "model": "sethuiyer/Qwen2.5-7B-Anvita",
    "score": 0.176
  },
  {
    "model": "sonthenguyen/ft-unsloth-zephyr-sft-bnb-4bit-20241014-170522",
    "score": 0.176
  },
  {
    "model": "sumink/llamamerge",
    "score": 0.176
  },
  {
    "model": "theo77186/Qwen2.5-Coder-7B-Instruct-20241106",
    "score": 0.176
  },
  {
    "model": "tiiuae/falcon-40b",
    "score": 0.176
  },
  {
    "model": "tinycompany/ShawtyIsBad-bgem3",
    "score": 0.176
  },
  {
    "model": "tinycompany/ShawtyIsBad-nomic1.5",
    "score": 0.176
  },
  {
    "model": "togethercomputer/LLaMA-2-7B-32K",
    "score": 0.176
  },
  {
    "model": "togethercomputer/RedPajama-INCITE-7B-Chat",
    "score": 0.176
  },
  {
    "model": "togethercomputer/Llama-2-7B-32K-Instruct",
    "score": 0.176
  },
  {
    "model": "utkmst/chimera-beta-test2-lora-merged",
    "score": 0.176
  },
  {
    "model": "uukuguy/speechless-llama2-hermes-orca-platypus-wizardlm-13b",
    "score": 0.176
  },
  {
    "model": "xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_gp_8b-table-0.002",
    "score": 0.176
  },
  {
    "model": "yasserrmd/Text2SQL-1.5B",
    "score": 0.176
  },
  {
    "model": "Alepach/notHumpback-M0",
    "score": 0.172
  },
  {
    "model": "Amaorynho/BBAI2006",
    "score": 0.172
  },
  {
    "model": "Amaorynho/BBAI_375",
    "score": 0.172
  },
  {
    "model": "Amu/t1-3B",
    "score": 0.172
  },
  {
    "model": "AtAndDev/Qwen2.5-1.5B-continuous-learnt",
    "score": 0.172
  },
  {
    "model": "AtAndDev/Qwen2.5-1.5B-continuous-learnt",
    "score": 0.172
  },
  {
    "model": "BramVanroy/GEITje-7B-ultra",
    "score": 0.172
  },
  {
    "model": "CYFRAGOVPL/PLLuM-12B-base",
    "score": 0.172
  },
  {
    "model": "CohereForAI/aya-expanse-32b",
    "score": 0.172
  },
  {
    "model": "Daemontatox/TinySphinx2.0",
    "score": 0.172
  },
  {
    "model": "DoppelReflEx/MN-12B-LilithFrame",
    "score": 0.172
  },
  {
    "model": "DoppelReflEx/MN-12B-LilithFrame",
    "score": 0.172
  },
  {
    "model": "EleutherAI/gpt-neo-2.7B",
    "score": 0.172
  },
  {
    "model": "EleutherAI/pythia-12b",
    "score": 0.172
  },
  {
    "model": "Enno-Ai/EnnoAi-Pro-Llama-3.1-8B-v0.9",
    "score": 0.172
  },
  {
    "model": "EnnoAi/EnnoAi-Pro-Llama-3.1-8B-v1.0",
    "score": 0.172
  },
  {
    "model": "Epiculous/NovaSpark",
    "score": 0.172
  },
  {
    "model": "EpistemeAI/Reasoning-Llama-3.2-1B-Instruct-v1.2",
    "score": 0.172
  },
  {
    "model": "EpistemeAI/Reasoning-Llama-3.1-CoT-RE1-NMT-V2-ORPO",
    "score": 0.172
  },
  {
    "model": "EpistemeAI2/Fireball-12B-v1.2",
    "score": 0.172
  },
  {
    "model": "FlofloB/smollm2-135M_pretrained_1200k_fineweb_uncovai_human_removed",
    "score": 0.172
  },
  {
    "model": "FuJhen/mistral_7b_v0.1_structedData_e2e",
    "score": 0.172
  },
  {
    "model": "GenVRadmin/llama38bGenZ_Vikas-Merged",
    "score": 0.172
  },
  {
    "model": "Hastagaras/L3.2-JametMini-3B-MK.III",
    "score": 0.172
  },
  {
    "model": "IlyaGusev/gemma-2-2b-it-abliterated",
    "score": 0.172
  },
  {
    "model": "Intel/neural-chat-7b-v3",
    "score": 0.172
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-1e-5-5ep",
    "score": 0.172
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5",
    "score": 0.172
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_3e-6-3ep_0alp_0lam",
    "score": 0.172
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-IRPO_1e-7-1ep_1alp_0lam",
    "score": 0.172
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-IRPO_1e-7-2ep_1alp_0lam",
    "score": 0.172
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-IRPO_3e-7-3ep_1alp_0lam",
    "score": 0.172
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_1e-6_2ep_0alp_0lam",
    "score": 0.172
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_5e-6-3ep_0alp_0lam",
    "score": 0.172
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-7e-5-3ep",
    "score": 0.172
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-MDPO-1epoch_v1",
    "score": 0.172
  },
  {
    "model": "JayHyeon/Qwen_0.5-IPO_5e-7-3ep_0alp_0lam",
    "score": 0.172
  },
  {
    "model": "JayHyeon/Qwen_0.5-IRPO_3e-7-3ep_1alp_0lam",
    "score": 0.172
  },
  {
    "model": "JayHyeon/Qwen_0.5-MDPO_0.5_3e-7-2ep_0alp_0lam",
    "score": 0.172
  },
  {
    "model": "JayHyeon/Qwen_0.5-MDPO_0.7_3e-6-3ep_0alp_0lam",
    "score": 0.172
  },
  {
    "model": "JayHyeon/Qwen_0.5-MDPO_0.7_5e-7-3ep_0alp_0lam",
    "score": 0.172
  },
  {
    "model": "JayHyeon/Qwen_0.5-VIPO_5e-7-3ep_3vpo_const",
    "score": 0.172
  },
  {
    "model": "Krystalan/DRT-o1-7B",
    "score": 0.172
  },
  {
    "model": "LeroyDyer/SpydazWebAI_Human_AGI",
    "score": 0.172
  },
  {
    "model": "LeroyDyer/SpydazWebAI_Human_AGI_001",
    "score": 0.172
  },
  {
    "model": "LeroyDyer/SpydazWeb_AI_HumanAI_001",
    "score": 0.172
  },
  {
    "model": "LeroyDyer/SpydazWeb_AI_HumanAI_007",
    "score": 0.172
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_X2",
    "score": 0.172
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_ChatQA_003",
    "score": 0.172
  },
  {
    "model": "Lil-R/2_PRYMMAL-ECE-2B-SLERP-V1",
    "score": 0.172
  },
  {
    "model": "Lil-R/2_PRYMMAL-ECE-2B-SLERP-V2",
    "score": 0.172
  },
  {
    "model": "LimYeri/CodeMind-Llama3.1-8B-unsloth-merged",
    "score": 0.172
  },
  {
    "model": "Locutusque/Llama-3-Yggdrasil-2.0-8B",
    "score": 0.172
  },
  {
    "model": "MEscriva/ECE-PRYMMAL-0.5B-FT-V5-MUSR-Mathis",
    "score": 0.172
  },
  {
    "model": "Magpie-Align/Llama-3-8B-Magpie-Align-v0.1",
    "score": 0.172
  },
  {
    "model": "Magpie-Align/Llama-3-8B-Magpie-Align-v0.1",
    "score": 0.172
  },
  {
    "model": "Magpie-Align/Llama-3.1-8B-Magpie-Align-v0.1",
    "score": 0.172
  },
  {
    "model": "ManoloPueblo/LLM_MERGE_CC2",
    "score": 0.172
  },
  {
    "model": "Mostafa8Mehrabi/llama-3.2-1b-Insomnia-ChatBot-merged",
    "score": 0.172
  },
  {
    "model": "NTQAI/Nxcode-CQ-7B-orpo",
    "score": 0.172
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_DeepDive_3_R1_Prev_v1.0",
    "score": 0.172
  },
  {
    "model": "Nexesenex/Llama_3.2_3b_Kermes_v2.1",
    "score": 0.172
  },
  {
    "model": "NikolaSigmoid/AceMath-1.5B-Instruct-1epoch",
    "score": 0.172
  },
  {
    "model": "NikolaSigmoid/DeepSeek-R1-Distill-Qwen-1.5B-500",
    "score": 0.172
  },
  {
    "model": "NikolaSigmoid/acemath-200",
    "score": 0.172
  },
  {
    "model": "Norquinal/Alpha",
    "score": 0.172
  },
  {
    "model": "Norquinal/Foxtrot",
    "score": 0.172
  },
  {
    "model": "Norquinal/Golf",
    "score": 0.172
  },
  {
    "model": "NousResearch/Yarn-Llama-2-7b-64k",
    "score": 0.172
  },
  {
    "model": "OpenAssistant/oasst-sft-1-pythia-12b",
    "score": 0.172
  },
  {
    "model": "OpenBuddy/openbuddy-llama3.1-8b-v22.2-131k",
    "score": 0.172
  },
  {
    "model": "OpenBuddy/openbuddy-qwen2.5llamaify-7b-v23.1-200k",
    "score": 0.172
  },
  {
    "model": "Qwen/Qwen2-0.5B",
    "score": 0.172
  },
  {
    "model": "Rakuten/RakutenAI-7B",
    "score": 0.172
  },
  {
    "model": "Replete-AI/L3.1-Pneuma-8B",
    "score": 0.172
  },
  {
    "model": "Replete-AI/Replete-Coder-Llama3-8B",
    "score": 0.172
  },
  {
    "model": "Sao10K/Fimbulvetr-11B-v2",
    "score": 0.172
  },
  {
    "model": "TencentARC/LLaMA-Pro-8B",
    "score": 0.172
  },
  {
    "model": "TinyLlama/TinyLlama-1.1B-Chat-v0.1",
    "score": 0.172
  },
  {
    "model": "Triangle104/DS-R1-Distill-Q2.5-14B-Harmony_V0.1",
    "score": 0.172
  },
  {
    "model": "Triangle104/Llama3.1-cc-Lit-8b",
    "score": 0.172
  },
  {
    "model": "UCLA-AGI/Mistral7B-PairRM-SPPO",
    "score": 0.172
  },
  {
    "model": "UCLA-AGI/Mistral7B-PairRM-SPPO-Iter2",
    "score": 0.172
  },
  {
    "model": "V3N0M/Jenna-Tiny-2.0",
    "score": 0.172
  },
  {
    "model": "Youlln/ECE-PRYMMAL-0.5B-FT-V3-MUSR",
    "score": 0.172
  },
  {
    "model": "Youlln/ECE.EIFFEIL.ia-0.5B-SLERP",
    "score": 0.172
  },
  {
    "model": "agentlans/Llama3.1-Daredevilish",
    "score": 0.172
  },
  {
    "model": "agentlans/Llama3.1-SuperDeepFuse-CrashCourse12K",
    "score": 0.172
  },
  {
    "model": "allenai/OLMo-1B-hf",
    "score": 0.172
  },
  {
    "model": "avemio/GRAG-NEMO-12B-ORPO-HESSIAN-AI",
    "score": 0.172
  },
  {
    "model": "aws-prototyping/MegaBeam-Mistral-7B-512k",
    "score": 0.172
  },
  {
    "model": "bamec66557/VICIOUS_MESH-12B-DELTA",
    "score": 0.172
  },
  {
    "model": "bamec66557/VICIOUS_MESH-12B-DIGAMMA",
    "score": 0.172
  },
  {
    "model": "bfuzzy1/acheron",
    "score": 0.172
  },
  {
    "model": "bfuzzy1/acheron-d",
    "score": 0.172
  },
  {
    "model": "bigscience/bloom-7b1",
    "score": 0.172
  },
  {
    "model": "braindao/DeepSeek-R1-Distill-Qwen-1.5B-Blunt",
    "score": 0.172
  },
  {
    "model": "braindao/DeepSeek-R1-Distill-Qwen-7B-Blunt",
    "score": 0.172
  },
  {
    "model": "bunnycore/Gemma-2-2B-Smart",
    "score": 0.172
  },
  {
    "model": "bunnycore/Qwen2.5-7B-R1-Bespoke-Stock",
    "score": 0.172
  },
  {
    "model": "cjvt/GaMS-1B",
    "score": 0.172
  },
  {
    "model": "collaiborateorg/Collaiborator-MEDLLM-Llama-3-8B-v2",
    "score": 0.172
  },
  {
    "model": "databricks/dolly-v2-3b",
    "score": 0.172
  },
  {
    "model": "databricks/dolly-v2-7b",
    "score": 0.172
  },
  {
    "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "score": 0.172
  },
  {
    "model": "dicta-il/dictalm2.0",
    "score": 0.172
  },
  {
    "model": "dustinwloring1988/Reflexis-8b-chat-v6",
    "score": 0.172
  },
  {
    "model": "ehristoforu/moremerge-upscaled",
    "score": 0.172
  },
  {
    "model": "ewre324/Thinker-Llama-3.2-3B-Instruct-Reasoning",
    "score": 0.172
  },
  {
    "model": "freewheelin/free-solar-evo-v0.1",
    "score": 0.172
  },
  {
    "model": "glaiveai/Reflection-Llama-3.1-70B",
    "score": 0.172
  },
  {
    "model": "godlikehhd/ifd_new_correct_sample_2500_qwen",
    "score": 0.172
  },
  {
    "model": "google/recurrentgemma-2b",
    "score": 0.172
  },
  {
    "model": "gradientai/Llama-3-8B-Instruct-Gradient-1048k",
    "score": 0.172
  },
  {
    "model": "haoranxu/ALMA-13B-R",
    "score": 0.172
  },
  {
    "model": "ibivibiv/colossus_120b",
    "score": 0.172
  },
  {
    "model": "ibm-granite/granite-3.0-8b-base",
    "score": 0.172
  },
  {
    "model": "ibm-granite/granite-3.1-1b-a400m-base",
    "score": 0.172
  },
  {
    "model": "icefog72/Ice0.29-06.11-RP",
    "score": 0.172
  },
  {
    "model": "icefog72/Ice0.34n-14.11-RP",
    "score": 0.172
  },
  {
    "model": "icefog72/Ice0.38-19.11-RP",
    "score": 0.172
  },
  {
    "model": "icefog72/Ice0.52.1-16.01-RP",
    "score": 0.172
  },
  {
    "model": "icefog72/Ice0.64-24.01-RP",
    "score": 0.172
  },
  {
    "model": "icefog72/Ice0.64.1-24.01-RP",
    "score": 0.172
  },
  {
    "model": "icefog72/Ice0.73-01.02-RP",
    "score": 0.172
  },
  {
    "model": "icefog72/IceCocoaRP-7b",
    "score": 0.172
  },
  {
    "model": "icefog72/IceSakeV4RP-7b",
    "score": 0.172
  },
  {
    "model": "icefog72/IceSakeV8RP-7b",
    "score": 0.172
  },
  {
    "model": "jebish7/aya-expanse-8b",
    "score": 0.172
  },
  {
    "model": "jeffmeloy/jeffmeloy_Qwen2.5-7B-minperplexity-1",
    "score": 0.172
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.1",
    "score": 0.172
  },
  {
    "model": "jpacifico/Lucie-7B-Instruct-Merged-Model_Stock-v1.0",
    "score": 0.172
  },
  {
    "model": "kms7530/chemeng_qwen-math-7b_24_1_100_1",
    "score": 0.172
  },
  {
    "model": "kyutai/helium-1-preview-2b",
    "score": 0.172
  },
  {
    "model": "lesubra/ECE-EIFFEL-3Bv3",
    "score": 0.172
  },
  {
    "model": "marcuscedricridia/Hush-Qwen2.5-7B-v1.1",
    "score": 0.172
  },
  {
    "model": "marcuscedricridia/stray-r1o-et",
    "score": 0.172
  },
  {
    "model": "matouLeLoup/ECE-PRYMMAL-0.5B-FT-EnhancedMUSREnsembleV3",
    "score": 0.172
  },
  {
    "model": "matouLeLoup/ECE-PRYMMAL-0.5B-FT-MUSR-ENSEMBLE-V2Mathis",
    "score": 0.172
  },
  {
    "model": "matouLeLoup/ECE-PRYMMAL-0.5B-FT-V4-MUSR-ENSEMBLE-Mathis",
    "score": 0.172
  },
  {
    "model": "meditsolutions/Llama-3.2-SUN-2.4B-checkpoint-26000",
    "score": 0.172
  },
  {
    "model": "meditsolutions/Llama-3.2-SUN-2.4B-checkpoint-34800",
    "score": 0.172
  },
  {
    "model": "meetkai/functionary-small-v3.1",
    "score": 0.172
  },
  {
    "model": "migtissera/Llama-3-8B-Synthia-v3.5",
    "score": 0.172
  },
  {
    "model": "mistralai/Mistral-Nemo-Instruct-2407",
    "score": 0.172
  },
  {
    "model": "nbeerbower/llama3.1-cc-8B",
    "score": 0.172
  },
  {
    "model": "neopolita/jessi-v0.5-falcon3-7b-instruct",
    "score": 0.172
  },
  {
    "model": "netcat420/MFANN3bv0.18",
    "score": 0.172
  },
  {
    "model": "oopere/pruned40-llama-3.2-1B",
    "score": 0.172
  },
  {
    "model": "oopere/pruned40-llama-1b",
    "score": 0.172
  },
  {
    "model": "oxyapi/oxy-1-small",
    "score": 0.172
  },
  {
    "model": "pankajmathur/orca_mini_v9_7_3B-Instruct",
    "score": 0.172
  },
  {
    "model": "princeton-nlp/Mistral-7B-Instruct-IPO",
    "score": 0.172
  },
  {
    "model": "princeton-nlp/Mistral-7B-Instruct-KTO",
    "score": 0.172
  },
  {
    "model": "prithivMLmods/SmolLM2-CoT-360M",
    "score": 0.172
  },
  {
    "model": "prithivMLmods/Qwen2.5-7B-DeepSeek-R1-1M",
    "score": 0.172
  },
  {
    "model": "prithivMLmods/Tulu-MathLingo-8B",
    "score": 0.172
  },
  {
    "model": "prithivMLmods/WebMind-7B-v0.1",
    "score": 0.172
  },
  {
    "model": "qingy2024/Qwen2.5-4B",
    "score": 0.172
  },
  {
    "model": "rombodawg/rombos_Replete-Coder-Llama3-8B",
    "score": 0.172
  },
  {
    "model": "saishshinde15/TethysAI_Vortex_Reasoning",
    "score": 0.172
  },
  {
    "model": "shyamieee/Padma-v7.0",
    "score": 0.172
  },
  {
    "model": "sometimesanotion/Qwen2.5-14B-Vimarckoso-v3-IF-Variant",
    "score": 0.172
  },
  {
    "model": "tensoropera/Fox-1-1.6B",
    "score": 0.172
  },
  {
    "model": "theprint/Boptruth-Agatha-7B",
    "score": 0.172
  },
  {
    "model": "thomas-yanxin/XinYuan-Qwen2-7B",
    "score": 0.172
  },
  {
    "model": "tinycompany/Tamed-Shawty",
    "score": 0.172
  },
  {
    "model": "tklohj/WindyFloLLM",
    "score": 0.172
  },
  {
    "model": "uukuguy/speechless-mistral-dolphin-orca-platypus-samantha-7b",
    "score": 0.172
  },
  {
    "model": "v000000/L3-8B-Stheno-v3.2-abliterated",
    "score": 0.172
  },
  {
    "model": "vonjack/MobileLLM-125M-HF",
    "score": 0.172
  },
  {
    "model": "wannaphong/KhanomTanLLM-Instruct",
    "score": 0.172
  },
  {
    "model": "xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_bt_8b-table-0.002",
    "score": 0.172
  },
  {
    "model": "xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_gp_2b-table-0.001",
    "score": 0.172
  },
  {
    "model": "xwen-team/Xwen-7B-Chat",
    "score": 0.172
  },
  {
    "model": "yifAI/Llama-3-8B-Instruct-SPPO-score-Iter3_gp_8b-table-0.002",
    "score": 0.172
  },
  {
    "model": "ymcki/gemma-2-2b-jpn-it-abliterated-17-ORPO",
    "score": 0.172
  },
  {
    "model": "yuvraj17/Llama3-8B-SuperNova-Spectrum-Hermes-DPO",
    "score": 0.172
  },
  {
    "model": "mistral-community/Mixtral-8x22B-v0.1",
    "score": 0.17
  },
  {
    "model": "AALF/gemma-2-27b-it-SimPO-37K",
    "score": 0.168
  },
  {
    "model": "BAAI/Infinity-Instruct-3M-0625-Qwen2-7B",
    "score": 0.168
  },
  {
    "model": "CausalLM/preview-1-hf",
    "score": 0.168
  },
  {
    "model": "CohereForAI/aya-23-35B",
    "score": 0.168
  },
  {
    "model": "CoolSpring/Qwen2-0.5B-Abyme-merge3",
    "score": 0.168
  },
  {
    "model": "DavidAU/DeepHermes-3-Llama-3-8B-Preview-16.5B-Brainstorm",
    "score": 0.168
  },
  {
    "model": "Etherll/Qwen2.5-Coder-7B-Instruct-Ties",
    "score": 0.168
  },
  {
    "model": "FlofloB/smollm2-135M_pretrained_1000k_fineweb_uncovai_selected",
    "score": 0.168
  },
  {
    "model": "Goekdeniz-Guelmez/Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v1",
    "score": 0.168
  },
  {
    "model": "Goekdeniz-Guelmez/Josiefied-Qwen2.5-0.5B-Instruct-abliterated-v1",
    "score": 0.168
  },
  {
    "model": "Goekdeniz-Guelmez/Josiefied-Qwen2.5-0.5B-Instruct-abliterated-v1",
    "score": 0.168
  },
  {
    "model": "HarbingerX/Zeitgeist-3b-V1",
    "score": 0.168
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-1e-4-2ep",
    "score": 0.168
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-1e-4-5ep",
    "score": 0.168
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-4-3ep",
    "score": 0.168
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPOP_5e-7-1ep_0alp_5lam",
    "score": 0.168
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_1e-7-2ep_0alp_0lam",
    "score": 0.168
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_2e-6-2ep_0alp_0lam",
    "score": 0.168
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_5e-6-2ep_0alp_0lam",
    "score": 0.168
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_5e-7_1ep_0alp_0lam",
    "score": 0.168
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_7e-7_1ep_0alp_0lam",
    "score": 0.168
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_1e-6_1ep_0alp_0lam",
    "score": 0.168
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_3e-6-3ep_0alp_0lam",
    "score": 0.168
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_7e-7_1ep_0alp_0lam",
    "score": 0.168
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-5e-5-5ep",
    "score": 0.168
  },
  {
    "model": "JayHyeon/Qwen_0.5-DPOP_3e-6-1ep_0alp_5lam",
    "score": 0.168
  },
  {
    "model": "JayHyeon/Qwen_0.5-DPOP_3e-7-1ep_0alp_5lam",
    "score": 0.168
  },
  {
    "model": "JayHyeon/Qwen_0.5-IRPO_3e-6-2ep_1alp_0lam",
    "score": 0.168
  },
  {
    "model": "JayHyeon/Qwen_0.5-IRPO_5e-7-1ep_1alp_0lam",
    "score": 0.168
  },
  {
    "model": "JayHyeon/Qwen_0.5-MDPO_0.1_5e-7-3ep_0alp_0lam",
    "score": 0.168
  },
  {
    "model": "JayHyeon/Qwen_0.5-MDPO_0.5_3e-7-1ep_0alp_0lam",
    "score": 0.168
  },
  {
    "model": "JayHyeon/Qwen_0.5-VDPO_5e-7-1ep_1vpo_const",
    "score": 0.168
  },
  {
    "model": "Josephgflowers/Tinyllama-r1",
    "score": 0.168
  },
  {
    "model": "LEESM/llama-3-8b-bnb-4b-kowiki231101",
    "score": 0.168
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_12",
    "score": 0.168
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_Student_Coder",
    "score": 0.168
  },
  {
    "model": "LimYeri/CodeMind-Llama3-8B-unsloth_v2-merged",
    "score": 0.168
  },
  {
    "model": "Locutusque/CollectiveLM-Falcon-3-7B",
    "score": 0.168
  },
  {
    "model": "Magpie-Align/Llama-3.1-8B-Magpie-Align-SFT-v0.1",
    "score": 0.168
  },
  {
    "model": "MagusCorp/grpo_lora_enem_llama3_7b",
    "score": 0.168
  },
  {
    "model": "Minami-su/test-7B-01",
    "score": 0.168
  },
  {
    "model": "NAPS-ai/naps-llama-3_1_instruct-v0.6.0",
    "score": 0.168
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_DeepDive_3_Prev_v1.0",
    "score": 0.168
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_Hermedive_R1_V1.03",
    "score": 0.168
  },
  {
    "model": "Nexesenex/Llama_3.2_1b_Dolto_0.1",
    "score": 0.168
  },
  {
    "model": "Nexesenex/Llama_3.2_3b_Kermes_v1",
    "score": 0.168
  },
  {
    "model": "Norquinal/Bravo",
    "score": 0.168
  },
  {
    "model": "Norquinal/Echo",
    "score": 0.168
  },
  {
    "model": "NousResearch/Yarn-Solar-10b-32k",
    "score": 0.168
  },
  {
    "model": "NousResearch/Yarn-Solar-10b-64k",
    "score": 0.168
  },
  {
    "model": "OEvortex/HelpingAI-15B",
    "score": 0.168
  },
  {
    "model": "PocketDoc/Dans-Instruct-CoreCurriculum-12b",
    "score": 0.168
  },
  {
    "model": "PocketDoc/Dans-PersonalityEngine-v1.0.0-8b",
    "score": 0.168
  },
  {
    "model": "Qwen/Qwen1.5-4B",
    "score": 0.168
  },
  {
    "model": "Replete-AI/L3-Pneuma-8B",
    "score": 0.168
  },
  {
    "model": "Replete-AI/Llama3-8B-Instruct-Replete-Adapted",
    "score": 0.168
  },
  {
    "model": "Sakalti/Llama3.2-3B-Uranus-1",
    "score": 0.168
  },
  {
    "model": "Sakalti/SJT-7B-V1.1",
    "score": 0.168
  },
  {
    "model": "Salesforce/LLaMA-3-8B-SFR-Iterative-DPO-R",
    "score": 0.168
  },
  {
    "model": "SicariusSicariiStuff/Impish_QWEN_7B-1M",
    "score": 0.168
  },
  {
    "model": "SkyOrbis/SKY-Ko-Qwen2.5-7B-Instruct-SFT-step-5000",
    "score": 0.168
  },
  {
    "model": "THUDM/glm-4-9b-chat-1m-hf",
    "score": 0.168
  },
  {
    "model": "Triangle104/Minerva-1.5b_V0.2",
    "score": 0.168
  },
  {
    "model": "Triangle104/Llama3.1-Allades-Lit-8b",
    "score": 0.168
  },
  {
    "model": "Triangle104/Pantheon_ChatWaifu_V0.2",
    "score": 0.168
  },
  {
    "model": "VAGOsolutions/SauerkrautLM-Gemma-2b",
    "score": 0.168
  },
  {
    "model": "VAGOsolutions/SauerkrautLM-Nemo-12b-Instruct",
    "score": 0.168
  },
  {
    "model": "ValiantLabs/Llama3.1-8B-Enigma",
    "score": 0.168
  },
  {
    "model": "Wladastic/Mini-Think-Base-1B",
    "score": 0.168
  },
  {
    "model": "Youlln/ECE-PRYMMAL-0.5B-FT-V4-MUSR",
    "score": 0.168
  },
  {
    "model": "ZeusLabs/L3-Aethora-15B-V2",
    "score": 0.168
  },
  {
    "model": "arisin/orca-platypus-13B-slerp",
    "score": 0.168
  },
  {
    "model": "bfuzzy1/llambses-1",
    "score": 0.168
  },
  {
    "model": "bigcode/starcoder2-15b",
    "score": 0.168
  },
  {
    "model": "braindao/DeepSeek-R1-Distill-Qwen-14B-Blunt",
    "score": 0.168
  },
  {
    "model": "bunnycore/Best-Mix-Llama-3.1-8B",
    "score": 0.168
  },
  {
    "model": "bunnycore/Qwen-2.5-7B-Exp-Sce",
    "score": 0.168
  },
  {
    "model": "bunnycore/Qwen2.5-7B-RRP-ID",
    "score": 0.168
  },
  {
    "model": "davidkim205/nox-solar-10.7b-v4",
    "score": 0.168
  },
  {
    "model": "ehristoforu/HappyLlama1",
    "score": 0.168
  },
  {
    "model": "ehristoforu/moremerge",
    "score": 0.168
  },
  {
    "model": "godlikehhd/alpaca_data_ifd_max_2600_3B",
    "score": 0.168
  },
  {
    "model": "godlikehhd/alpaca_data_score_max_2600_3B",
    "score": 0.168
  },
  {
    "model": "google/gemma-1.1-7b-it",
    "score": 0.168
  },
  {
    "model": "icefog72/Ice0.60.1-18.01-RP",
    "score": 0.168
  },
  {
    "model": "icefog72/Ice0.62-18.01-RP",
    "score": 0.168
  },
  {
    "model": "icefog72/Ice0.74-02.02-RP",
    "score": 0.168
  },
  {
    "model": "icefog72/Ice0.77-02.02-RP",
    "score": 0.168
  },
  {
    "model": "icefog72/IceCoffeeRP-7b",
    "score": 0.168
  },
  {
    "model": "jaspionjader/Kosmos-EVAA-TSN-8B",
    "score": 0.168
  },
  {
    "model": "jieliu/Storm-7B",
    "score": 0.168
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.5-gamma-0.01",
    "score": 0.168
  },
  {
    "model": "johnsutor/Llama-3-8B-Instruct_dare_linear",
    "score": 0.168
  },
  {
    "model": "khoantap/llama-evolve-ties-best-merge",
    "score": 0.168
  },
  {
    "model": "kno10/ende-chat-0.0.7",
    "score": 0.168
  },
  {
    "model": "lesubra/ECE-EIFFEL-3Bv2",
    "score": 0.168
  },
  {
    "model": "marcuscedricridia/Hush-Qwen2.5-7B-Preview",
    "score": 0.168
  },
  {
    "model": "meditsolutions/Llama-3.2-SUN-HDIC-1B-Instruct",
    "score": 0.168
  },
  {
    "model": "meditsolutions/MedIT-Mesh-3B-Instruct",
    "score": 0.168
  },
  {
    "model": "mergekit-community/JAJUKA-WEWILLNEVERFORGETYOU-3B",
    "score": 0.168
  },
  {
    "model": "mistralai/Ministral-8B-Instruct-2410",
    "score": 0.168
  },
  {
    "model": "mlx-community/Josiefied-Qwen2.5-0.5B-Instruct-abliterated-v1-float32",
    "score": 0.168
  },
  {
    "model": "monsterapi/gemma-2-2b-LoRA-MonsterInstruct",
    "score": 0.168
  },
  {
    "model": "mrdayl/OpenCognito",
    "score": 0.168
  },
  {
    "model": "natong19/Mistral-Nemo-Instruct-2407-abliterated",
    "score": 0.168
  },
  {
    "model": "nbeerbower/Kartoffel-Deepfry-12B",
    "score": 0.168
  },
  {
    "model": "netcat420/MFANN3bv1.2",
    "score": 0.168
  },
  {
    "model": "netcat420/Qwen2.5-7b-MFANN-slerp",
    "score": 0.168
  },
  {
    "model": "netcat420/Qwen2.5-Coder-Scholar-7B-Abliterated-MFANN-Slerp-Unretrained",
    "score": 0.168
  },
  {
    "model": "noname0202/gemma-2-2b-it-ties",
    "score": 0.168
  },
  {
    "model": "nvidia/AceMath-1.5B-Instruct",
    "score": 0.168
  },
  {
    "model": "nvidia/Minitron-8B-Base",
    "score": 0.168
  },
  {
    "model": "nvidia/Mistral-NeMo-Minitron-8B-Instruct",
    "score": 0.168
  },
  {
    "model": "nvidia/OpenMath2-Llama3.1-8B",
    "score": 0.168
  },
  {
    "model": "odyssey-labs/Astral-1-10B",
    "score": 0.168
  },
  {
    "model": "openchat/openchat-3.6-8b-20240522",
    "score": 0.168
  },
  {
    "model": "piotr25691/thea-rp-3b-25r",
    "score": 0.168
  },
  {
    "model": "princeton-nlp/Llama-3-8B-ProLong-512k-Instruct",
    "score": 0.168
  },
  {
    "model": "princeton-nlp/Llama-3-8B-ProLong-512k-Instruct",
    "score": 0.168
  },
  {
    "model": "princeton-nlp/Llama-3-Instruct-8B-RRHF-v0.2",
    "score": 0.168
  },
  {
    "model": "princeton-nlp/Llama-3-Instruct-8B-SLiC-HF-v0.2",
    "score": 0.168
  },
  {
    "model": "prithivMLmods/Bellatrix-Tiny-1B-v2",
    "score": 0.168
  },
  {
    "model": "prithivMLmods/Llama-3.1-8B-Open-SFT",
    "score": 0.168
  },
  {
    "model": "prithivMLmods/Megatron-Opus-7B-Exp",
    "score": 0.168
  },
  {
    "model": "prithivMLmods/Omni-Reasoner3-Merged",
    "score": 0.168
  },
  {
    "model": "prithivMLmods/QwQ-R1-Distill-7B-CoT",
    "score": 0.168
  },
  {
    "model": "qingy2019/OpenMath2-Llama3.1-8B",
    "score": 0.168
  },
  {
    "model": "sabersalehk/Llama3-001-300",
    "score": 0.168
  },
  {
    "model": "saishf/Fimbulvetr-Kuro-Lotus-10.7B",
    "score": 0.168
  },
  {
    "model": "stabilityai/StableBeluga2",
    "score": 0.168
  },
  {
    "model": "streamerbtw1002/Nexuim-R1-7B-Instruct",
    "score": 0.168
  },
  {
    "model": "teknium/OpenHermes-13B",
    "score": 0.168
  },
  {
    "model": "teknium/OpenHermes-7B",
    "score": 0.168
  },
  {
    "model": "theprint/CleverBoi-7B-v3",
    "score": 0.168
  },
  {
    "model": "theprint/Conversely-Mistral-7B",
    "score": 0.168
  },
  {
    "model": "theprint/ReWiz-Llama-3.1-8B-v2",
    "score": 0.168
  },
  {
    "model": "thinkcoder/llama3-8b-instruct-lora-8-sft",
    "score": 0.168
  },
  {
    "model": "thomas-yanxin/XinYuan-Qwen2-1_5B",
    "score": 0.168
  },
  {
    "model": "vicgalle/Merge-Mistral-Prometheus-7B",
    "score": 0.168
  },
  {
    "model": "xinchen9/Llama3.1_8B_Instruct_CoT",
    "score": 0.168
  },
  {
    "model": "xkp24/Llama-3-8B-Instruct-SPPO-Iter2_gp_2b-table",
    "score": 0.168
  },
  {
    "model": "xukp20/Llama-3-8B-Instruct-SPPO-score-Iter3_gp_2b-table-0.001",
    "score": 0.168
  },
  {
    "model": "yam-peleg/Hebrew-Mistral-7B-200K",
    "score": 0.168
  },
  {
    "model": "yam-peleg/Hebrew-Mistral-7B-200K",
    "score": 0.168
  },
  {
    "model": "ymcki/gemma-2-2b-jpn-it-abliterated-17-ORPO-alpaca",
    "score": 0.168
  },
  {
    "model": "3rd-Degree-Burn/Llama-3.1-8B-Squareroot",
    "score": 0.164
  },
  {
    "model": "3rd-Degree-Burn/Llama-Squared-8B",
    "score": 0.164
  },
  {
    "model": "AicoresSecurity/Cybernet-Sec-3B-R1-V1.1",
    "score": 0.164
  },
  {
    "model": "BAAI/Infinity-Instruct-3M-0625-Llama3-8B",
    "score": 0.164
  },
  {
    "model": "BSC-LT/salamandra-7b-instruct",
    "score": 0.164
  },
  {
    "model": "BenevolenceMessiah/Yi-Coder-9B-Chat-Instruct-TIES-MoE-v1.0",
    "score": 0.164
  },
  {
    "model": "DRXD1000/Phoenix-7B",
    "score": 0.164
  },
  {
    "model": "DUAL-GPO/zephyr-7b-ipo-0k-15k-i1",
    "score": 0.164
  },
  {
    "model": "Dans-DiscountModels/Dans-Instruct-Mix-8b-ChatML",
    "score": 0.164
  },
  {
    "model": "Dans-DiscountModels/Dans-Instruct-Mix-8b-ChatML-V0.2.0",
    "score": 0.164
  },
  {
    "model": "DavidAU/DeepSeek-Grand-Horror-SMB-R1-Distill-Llama-3.1-16B",
    "score": 0.164
  },
  {
    "model": "Deci/DeciLM-7B",
    "score": 0.164
  },
  {
    "model": "Delta-Vector/Tor-8B",
    "score": 0.164
  },
  {
    "model": "DoppelReflEx/MN-12B-Mimicore-WhiteSnake-v2-Experiment-4",
    "score": 0.164
  },
  {
    "model": "DreadPoor/Winter_Dusk-8B-TIES",
    "score": 0.164
  },
  {
    "model": "EpistemeAI/Llama-3.2-3B-Agent007-Coder",
    "score": 0.164
  },
  {
    "model": "EpistemeAI/ReasoningCore-3B-RE1-V2A",
    "score": 0.164
  },
  {
    "model": "GenVRadmin/AryaBhatta-GemmaOrca-Merged",
    "score": 0.164
  },
  {
    "model": "GoToCompany/llama3-8b-cpt-sahabatai-v1-instruct",
    "score": 0.164
  },
  {
    "model": "Goekdeniz-Guelmez/Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v2",
    "score": 0.164
  },
  {
    "model": "Goekdeniz-Guelmez/josie-7b-v6.0",
    "score": 0.164
  },
  {
    "model": "Gryphe/Pantheon-RP-1.6-12b-Nemo-KTO",
    "score": 0.164
  },
  {
    "model": "HPAI-BSC/Qwen2.5-Aloe-Beta-7B",
    "score": 0.164
  },
  {
    "model": "HarbingerX/Zeitgeist-3b-V1.2",
    "score": 0.164
  },
  {
    "model": "HuggingFaceH4/zephyr-orpo-141b-A35b-v0.1",
    "score": 0.164
  },
  {
    "model": "Intel/neural-chat-7b-v3-3",
    "score": 0.164
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-1e-5-3ep",
    "score": 0.164
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPOP_5e-7-2ep_0alp_5lam",
    "score": 0.164
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_7e-7_3ep_0alp_0lam",
    "score": 0.164
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_1e-6-3ep_0alp_0lam",
    "score": 0.164
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_2e-6_2ep_0alp_0lam",
    "score": 0.164
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_5e-7-3ep_0alp_0lam",
    "score": 0.164
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_7e-7-3ep_0alp_0lam",
    "score": 0.164
  },
  {
    "model": "JayHyeon/Qwen_0.5-MDPO_0.5_1e-5-3ep_0alp_0lam",
    "score": 0.164
  },
  {
    "model": "JayHyeon/Qwen_0.5-VDPO_5e-7-1ep_0alp_0lam",
    "score": 0.164
  },
  {
    "model": "JayHyeon/Qwen_0.5-VIPO_5e-7-3ep_0alp_0lam",
    "score": 0.164
  },
  {
    "model": "Kukedlc/NeuralExperiment-7b-MagicCoder-v7.5",
    "score": 0.164
  },
  {
    "model": "Kukedlc/NeuralLLaMa-3-8b-ORPO-v0.3",
    "score": 0.164
  },
  {
    "model": "LeroyDyer/LCARS_AI_001",
    "score": 0.164
  },
  {
    "model": "LeroyDyer/LCARS_AI_StarTrek_Computer",
    "score": 0.164
  },
  {
    "model": "LeroyDyer/SpydazWeb_AI_CyberTron_Ultra_7b",
    "score": 0.164
  },
  {
    "model": "LeroyDyer/SpydazWeb_AI_HumanAI_012_INSTRUCT_MX",
    "score": 0.164
  },
  {
    "model": "Marsouuu/MistralBase-4x7B-MoE-ECE-PRYMMAL-Martial",
    "score": 0.164
  },
  {
    "model": "MaziyarPanahi/Qwen2-7B-Instruct-v0.1",
    "score": 0.164
  },
  {
    "model": "MaziyarPanahi/calme-2.3-qwen2-7b",
    "score": 0.164
  },
  {
    "model": "Nekochu/Luminia-13B-v3",
    "score": 0.164
  },
  {
    "model": "Nexesenex/Dolphin3.0-Llama3.1-1B-abliterated",
    "score": 0.164
  },
  {
    "model": "Norquinal/Charlie",
    "score": 0.164
  },
  {
    "model": "Norquinal/Hotel",
    "score": 0.164
  },
  {
    "model": "NousResearch/Yarn-Llama-2-13b-128k",
    "score": 0.164
  },
  {
    "model": "Novaciano/Fusetrix-3.2-1B-GRPO_RP_Creative",
    "score": 0.164
  },
  {
    "model": "Novaciano/Fusetrix-Dolphin-3.2-1B-GRPO_Creative_RP",
    "score": 0.164
  },
  {
    "model": "OpenLLM-France/Lucie-7B-Instruct-v1.1",
    "score": 0.164
  },
  {
    "model": "PJMixers-Dev/LLaMa-3.2-Instruct-JankMix-v0.2-SFT-3B",
    "score": 0.164
  },
  {
    "model": "PJMixers-Dev/Qwen2.5-RomboTiesTest-7B",
    "score": 0.164
  },
  {
    "model": "Qwen/Qwen1.5-4B-Chat",
    "score": 0.164
  },
  {
    "model": "Qwen/Qwen1.5-7B",
    "score": 0.164
  },
  {
    "model": "Qwen/Qwen1.5-MoE-A2.7B-Chat",
    "score": 0.164
  },
  {
    "model": "Qwen/Qwen2.5-7B",
    "score": 0.164
  },
  {
    "model": "RESMPDEV/Qwen2-Wukong-0.5B",
    "score": 0.164
  },
  {
    "model": "Replete-AI/Replete-Coder-Instruct-8b-Merged",
    "score": 0.164
  },
  {
    "model": "Ro-xe/FMixIA-7B-DARE-0",
    "score": 0.164
  },
  {
    "model": "SaisExperiments/Gemma-2-2B-Opus-Instruct",
    "score": 0.164
  },
  {
    "model": "SaisExperiments/RightSheep-Llama3.2-3B",
    "score": 0.164
  },
  {
    "model": "SeaLLMs/SeaLLMs-v3-7B-Chat",
    "score": 0.164
  },
  {
    "model": "SenseLLM/ReflectionCoder-CL-34B",
    "score": 0.164
  },
  {
    "model": "SkyOrbis/SKY-Ko-Llama3.2-1B-lora-epoch5",
    "score": 0.164
  },
  {
    "model": "SkyOrbis/SKY-Ko-Llama3.2-1B-lora-v2-epoch3",
    "score": 0.164
  },
  {
    "model": "SultanR/SmolTulu-1.7b-Reinforced",
    "score": 0.164
  },
  {
    "model": "Svak/MN-12B-Inferor-v0.1",
    "score": 0.164
  },
  {
    "model": "T145/ZEUS-8B-V21",
    "score": 0.164
  },
  {
    "model": "TIGER-Lab/AceCoder-Qwen2.5-7B-Ins-Rule",
    "score": 0.164
  },
  {
    "model": "TheDrummer/Gemmasutra-Mini-2B-v1",
    "score": 0.164
  },
  {
    "model": "TheDrunkenSnail/Daughter-of-Rhodia-12B",
    "score": 0.164
  },
  {
    "model": "TheDrunkenSnail/Son-of-Rhodia",
    "score": 0.164
  },
  {
    "model": "Triangle104/Hermes-Llama-3.2-CoT-Summary",
    "score": 0.164
  },
  {
    "model": "Triangle104/L3.1-8B-Dusky-Ink",
    "score": 0.164
  },
  {
    "model": "Triangle104/Rombos-Novasky-7B_V1c",
    "score": 0.164
  },
  {
    "model": "UCLA-AGI/Mistral7B-PairRM-SPPO-Iter3",
    "score": 0.164
  },
  {
    "model": "VIRNECT/llama-3-Korean-8B-r-v-0.1",
    "score": 0.164
  },
  {
    "model": "Xiaojian9992024/Qwen2.5-THREADRIPPER-Small-AnniversaryEdition",
    "score": 0.164
  },
  {
    "model": "Xiaojian9992024/Reflection-L3.2-JametMiniMix-3B",
    "score": 0.164
  },
  {
    "model": "ZeroXClem/Llama-3.1-8B-AthenaSky-MegaMix",
    "score": 0.164
  },
  {
    "model": "abacusai/Llama-3-Smaug-8B",
    "score": 0.164
  },
  {
    "model": "ai21labs/Jamba-v0.1",
    "score": 0.164
  },
  {
    "model": "arcee-ai/Arcee-Maestro-7B-Preview",
    "score": 0.164
  },
  {
    "model": "argilla/notus-7b-v1",
    "score": 0.164
  },
  {
    "model": "argilla/notux-8x7b-v1",
    "score": 0.164
  },
  {
    "model": "awnr/Mistral-7B-v0.1-signtensors-1-over-4",
    "score": 0.164
  },
  {
    "model": "bamec66557/VICIOUS_MESH-12B-ALPHA",
    "score": 0.164
  },
  {
    "model": "bamec66557/VICIOUS_MESH-12B-GAMMA",
    "score": 0.164
  },
  {
    "model": "bamec66557/VICIOUS_MESH-12B-UNION",
    "score": 0.164
  },
  {
    "model": "bfuzzy1/Gunny",
    "score": 0.164
  },
  {
    "model": "bhuvneshsaini/merged_model",
    "score": 0.164
  },
  {
    "model": "bigscience/bloom-3b",
    "score": 0.164
  },
  {
    "model": "bunnycore/Qwen-2.5-7B-Deep-Stock-v1",
    "score": 0.164
  },
  {
    "model": "bunnycore/Qwen-2.5-7B-Deep-Stock-v5",
    "score": 0.164
  },
  {
    "model": "bunnycore/Qwen2.5-7B-CyberRombos",
    "score": 0.164
  },
  {
    "model": "cloudyu/Mixtral_11Bx2_MoE_19B",
    "score": 0.164
  },
  {
    "model": "cognitivecomputations/dolphin-2.9.4-llama3.1-8b",
    "score": 0.164
  },
  {
    "model": "deepseek-ai/deepseek-llm-7b-base",
    "score": 0.164
  },
  {
    "model": "dfurman/Llama-3-70B-Orpo-v0.1",
    "score": 0.164
  },
  {
    "model": "dustinwloring1988/Reflexis-8b-chat-v5",
    "score": 0.164
  },
  {
    "model": "dzakwan/dzakwan-MoE-4x7b-Beta",
    "score": 0.164
  },
  {
    "model": "ehristoforu/rufalcon3-3b-it",
    "score": 0.164
  },
  {
    "model": "google/gemma-2-2b-jpn-it",
    "score": 0.164
  },
  {
    "model": "google/gemma-2-2b-jpn-it",
    "score": 0.164
  },
  {
    "model": "google/gemma-2b",
    "score": 0.164
  },
  {
    "model": "h2oai/h2o-danube-1.8b-chat",
    "score": 0.164
  },
  {
    "model": "hatemmahmoud/qwen2.5-1.5b-sft-raft-grpo-hra-doc",
    "score": 0.164
  },
  {
    "model": "hotmailuser/FalconSlerp6-7B",
    "score": 0.164
  },
  {
    "model": "hotmailuser/Llama-Hermes-slerp-8B",
    "score": 0.164
  },
  {
    "model": "iFaz/llama31_8B_en_emo_v4",
    "score": 0.164
  },
  {
    "model": "icefog72/Ice0.51-16.01-RP",
    "score": 0.164
  },
  {
    "model": "icefog72/Ice0.52-16.01-RP",
    "score": 0.164
  },
  {
    "model": "icefog72/Ice0.62.1-24.01-RP",
    "score": 0.164
  },
  {
    "model": "icefog72/Ice0.65-25.01-RP",
    "score": 0.164
  },
  {
    "model": "icefog72/Ice0.67-25.01-RP",
    "score": 0.164
  },
  {
    "model": "icefog72/Ice0.7-29.09-RP",
    "score": 0.164
  },
  {
    "model": "insightfactory/Llama-3.2-3B-Instruct-unsloth-bnb-4bitlora_model",
    "score": 0.164
  },
  {
    "model": "jaspionjader/bh-1",
    "score": 0.164
  },
  {
    "model": "jayasuryajsk/Qwen2.5-3B-reasoner",
    "score": 0.164
  },
  {
    "model": "lesubra/ECE-PRYMMAL-3B-SLERP_2-V2",
    "score": 0.164
  },
  {
    "model": "lesubra/ECE-PRYMMAL-3B-SLERP_2-V1",
    "score": 0.164
  },
  {
    "model": "lightblue/suzume-llama-3-8B-multilingual-orpo-borda-full",
    "score": 0.164
  },
  {
    "model": "marcuscedricridia/Hush-Qwen2.5-7B-v1.2",
    "score": 0.164
  },
  {
    "model": "marcuscedricridia/r1o-et",
    "score": 0.164
  },
  {
    "model": "meta-llama/Llama-3.2-3B",
    "score": 0.164
  },
  {
    "model": "migtissera/Tess-3-7B-SFT",
    "score": 0.164
  },
  {
    "model": "mlabonne/NeuralBeagle14-7B",
    "score": 0.164
  },
  {
    "model": "mobiuslabsgmbh/DeepSeek-R1-ReDistill-Qwen-7B-v1.1",
    "score": 0.164
  },
  {
    "model": "mrdayl/OpenCognito-r2",
    "score": 0.164
  },
  {
    "model": "nbeerbower/Dumpling-Qwen2.5-7B-1k-r64-2e-5",
    "score": 0.164
  },
  {
    "model": "nlpguy/Lion-Lamarck-v.1.0.8",
    "score": 0.164
  },
  {
    "model": "ontocord/wide_3b_sft_stage1.2-ss1-expert_fictional_lyrical",
    "score": 0.164
  },
  {
    "model": "open-neo/Kyro-n1-3B",
    "score": 0.164
  },
  {
    "model": "open-neo/Kyro-n1-7B",
    "score": 0.164
  },
  {
    "model": "open-atlas/Atlas-Flash-7B-Preview",
    "score": 0.164
  },
  {
    "model": "pankajmathur/orca_mini_v3_13b",
    "score": 0.164
  },
  {
    "model": "rombodawg/rombos_Replete-Coder-Instruct-8b-Merged",
    "score": 0.164
  },
  {
    "model": "sabersalehk/Llama3_01_300",
    "score": 0.164
  },
  {
    "model": "theprint/WorldBuilder-12B",
    "score": 0.164
  },
  {
    "model": "tiiuae/Falcon3-1B-Base",
    "score": 0.164
  },
  {
    "model": "tiiuae/Falcon3-7B-Base",
    "score": 0.164
  },
  {
    "model": "tiiuae/falcon-mamba-7b",
    "score": 0.164
  },
  {
    "model": "weathermanj/Menda-3b-Optim-100",
    "score": 0.164
  },
  {
    "model": "winglian/Llama-3-8b-64k-PoSE",
    "score": 0.164
  },
  {
    "model": "mistralai/Mistral-7B-Instruct-v0.2",
    "score": 0.16
  },
  {
    "model": "3rd-Degree-Burn/Llama-3.1-8B-Squareroot-v1",
    "score": 0.16
  },
  {
    "model": "01-ai/Yi-6B",
    "score": 0.16
  },
  {
    "model": "AIDC-AI/Marco-o1",
    "score": 0.16
  },
  {
    "model": "Ahdoot/StructuredThinker-v0.3-MoreStructure",
    "score": 0.16
  },
  {
    "model": "BlackBeenie/Llama-3.1-8B-OpenO1-SFT-v0.1",
    "score": 0.16
  },
  {
    "model": "Bllossom/llama-3.2-Korean-Bllossom-AICA-5B",
    "score": 0.16
  },
  {
    "model": "CohereForAI/c4ai-command-r7b-12-2024",
    "score": 0.16
  },
  {
    "model": "Columbia-NLP/LION-LLaMA-3-8b-dpo-v1.0",
    "score": 0.16
  },
  {
    "model": "CombinHorizon/Rombos-Qwen2.5-7B-Inst-BaseMerge-TIES",
    "score": 0.16
  },
  {
    "model": "CoolSpring/Qwen2-0.5B-Abyme",
    "score": 0.16
  },
  {
    "model": "Corianas/Neural-Mistral-7B",
    "score": 0.16
  },
  {
    "model": "Corianas/llama-3-reactor",
    "score": 0.16
  },
  {
    "model": "Daemontatox/AetherDrake-SFT",
    "score": 0.16
  },
  {
    "model": "DeepAutoAI/Explore_Llama-3.2-1B-Inst_v0",
    "score": 0.16
  },
  {
    "model": "DoppelReflEx/MN-12B-Mimicore-Orochi-v2-Experiment",
    "score": 0.16
  },
  {
    "model": "EpistemeAI/Athena-gemma-2-2b-it",
    "score": 0.16
  },
  {
    "model": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-0.001-128K-auto",
    "score": 0.16
  },
  {
    "model": "EpistemeAI/Fireball-Alpaca-Llama3.1.08-8B-Philos-C-R2",
    "score": 0.16
  },
  {
    "model": "EpistemeAI/Fireball-Meta-Llama-3.2-8B-Instruct-agent-003-128k-code-DPO",
    "score": 0.16
  },
  {
    "model": "EpistemeAI/Fireball-R1-Llama-3.1-8B",
    "score": 0.16
  },
  {
    "model": "EpistemeAI2/Fireball-Llama-3.1-8B-Philos-Reflection",
    "score": 0.16
  },
  {
    "model": "FlofloB/smollm2-135M_pretrained_1400k_fineweb_uncovai_selected",
    "score": 0.16
  },
  {
    "model": "FuJhen/mistral-instruct-7B-DPO",
    "score": 0.16
  },
  {
    "model": "FuseAI/FuseChat-Llama-3.2-3B-Instruct",
    "score": 0.16
  },
  {
    "model": "Goekdeniz-Guelmez/Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v3",
    "score": 0.16
  },
  {
    "model": "HumanLLMs/Humanish-Mistral-Nemo-Instruct-2407",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-4",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_1e-6-1ep_0alp_0lam",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_2e-6-3ep_0alp_0lam",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_3e-7-3ep_0alp_0lam",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_5e-7_3ep_0alp_0lam",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_7e-7_2ep_0alp_0lam",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-IRPO_1e-7-3ep_1alp_0lam",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-IRPO_5e-7-1ep_1alp_0lam",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-IRPO_5e-7-2ep_1alp_0lam",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_0.5_1e-7-3ep_0alp_0lam",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_2e-6_1ep_0alp_0lam",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen_0.5-DPOP_5e-7-1ep_0alp_5lam",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen_0.5-DPOP_5e-7-3ep_0alp_5lam",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen_0.5-DPO_3e-7-1ep_0alp_0lam",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen_0.5-DPO_5e-7-1ep_0alp_0lam",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen_0.5-DPO_5e-7-3ep_0alp_0lam",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen_0.5-IRPO_1e-6-3ep_1alp_0lam",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen_0.5-IRPO_5e-7-2ep_1alp_0lam",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen_0.5-MDPO_0.3_5e-7-3ep_0alp_0lam",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen_0.5-VDPO_5e-7-3ep_0alp_0lam",
    "score": 0.16
  },
  {
    "model": "JayHyeon/Qwen_0.5-VIPO_5e-7-1ep_10vpo_const",
    "score": 0.16
  },
  {
    "model": "LEESM/llama-2-7b-hf-lora-oki10p",
    "score": 0.16
  },
  {
    "model": "LEESM/llama-3-Korean-Bllossom-8B-trexlab-oki10p",
    "score": 0.16
  },
  {
    "model": "LeroyDyer/SpydazWeb_AI_HumanAI_011_INSTRUCT_ML_r1",
    "score": 0.16
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_001",
    "score": 0.16
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_Math_003",
    "score": 0.16
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_Teacher_Coder",
    "score": 0.16
  },
  {
    "model": "Magpie-Align/MagpieLM-8B-Chat-v0.1",
    "score": 0.16
  },
  {
    "model": "Magpie-Align/MagpieLM-8B-SFT-v0.1",
    "score": 0.16
  },
  {
    "model": "ModelSpace/GemmaX2-28-9B-v0.1",
    "score": 0.16
  },
  {
    "model": "Nexesenex/Llama_3.1_8b_Medusa_v1.01",
    "score": 0.16
  },
  {
    "model": "NousResearch/Hermes-3-Llama-3.2-3B",
    "score": 0.16
  },
  {
    "model": "PocketDoc/Dans-PersonalityEngine-V1.2.0-24b",
    "score": 0.16
  },
  {
    "model": "Qwen/Qwen2-7B-Instruct",
    "score": 0.16
  },
  {
    "model": "Qwen/Qwen2.5-7B-Instruct",
    "score": 0.16
  },
  {
    "model": "Qwen/Qwen2.5-Coder-7B",
    "score": 0.16
  },
  {
    "model": "Qwen/Qwen2.5-Math-7B",
    "score": 0.16
  },
  {
    "model": "Rombo-Org/Rombo-LLM-V2.5-Qwen-7b",
    "score": 0.16
  },
  {
    "model": "Sakalti/Qwen2.5-1B-Instruct",
    "score": 0.16
  },
  {
    "model": "T145/ZEUS-8B-V24",
    "score": 0.16
  },
  {
    "model": "THUDM/glm-4-9b-chat-hf",
    "score": 0.16
  },
  {
    "model": "TIGER-Lab/Qwen2.5-Math-7B-CFT",
    "score": 0.16
  },
  {
    "model": "TheDrummer/Rocinante-12B-v1",
    "score": 0.16
  },
  {
    "model": "Triangle104/Dark-Chivalry_V1.0",
    "score": 0.16
  },
  {
    "model": "Unbabel/TowerInstruct-Mistral-7B-v0.2",
    "score": 0.16
  },
  {
    "model": "WizardLMTeam/WizardLM-70B-V1.0",
    "score": 0.16
  },
  {
    "model": "Xiaojian9992024/Qwen2.5-Dyanka-7B-Preview-v0.2",
    "score": 0.16
  },
  {
    "model": "Youlln/ECE-PRYMMAL0.5B-Youri",
    "score": 0.16
  },
  {
    "model": "ZeroXClem/Llama-3.1-8B-RainbowLight-EtherealMix",
    "score": 0.16
  },
  {
    "model": "abacusai/Liberated-Qwen1.5-14B",
    "score": 0.16
  },
  {
    "model": "argilla-warehouse/Llama-3.1-8B-MagPie-Ultra",
    "score": 0.16
  },
  {
    "model": "bamec66557/MISCHIEVOUS-12B-Mix_0.4v",
    "score": 0.16
  },
  {
    "model": "bamec66557/MISCHIEVOUS-12B-Mix_Neo",
    "score": 0.16
  },
  {
    "model": "bamec66557/Mistral-Nemo-VICIOUS_MESH-12B-2407",
    "score": 0.16
  },
  {
    "model": "bamec66557/NameLess-12B-prob",
    "score": 0.16
  },
  {
    "model": "bamec66557/VICIOUS_MESH-12B-BETA",
    "score": 0.16
  },
  {
    "model": "bamec66557/VICIOUS_MESH-12B-OMEGA",
    "score": 0.16
  },
  {
    "model": "bamec66557/mergekit-ties-sinbkow",
    "score": 0.16
  },
  {
    "model": "brgx53/3Bgeneral-ECE-PRYMMAL-Martial",
    "score": 0.16
  },
  {
    "model": "bunnycore/FuseCyberMix-Qwen-2.5-7B-Instruct",
    "score": 0.16
  },
  {
    "model": "bunnycore/Llama-3.2-3B-Bespoke-Thought",
    "score": 0.16
  },
  {
    "model": "cognitivecomputations/Dolphin3.0-Llama3.2-1B",
    "score": 0.16
  },
  {
    "model": "cognitivecomputations/Dolphin3.0-Qwen2.5-0.5B",
    "score": 0.16
  },
  {
    "model": "deepseek-ai/deepseek-moe-16b-chat",
    "score": 0.16
  },
  {
    "model": "djuna/MN-Chinofun-12B-2",
    "score": 0.16
  },
  {
    "model": "dustinwloring1988/Reflexis-8b-chat-v3",
    "score": 0.16
  },
  {
    "model": "ehristoforu/QwenQwen2.5-7B-IT",
    "score": 0.16
  },
  {
    "model": "ehristoforu/QwenQwen2.5-7B-IT-Dare",
    "score": 0.16
  },
  {
    "model": "ehristoforu/falcon3-ultraset",
    "score": 0.16
  },
  {
    "model": "fblgit/juanako-7b-UNA",
    "score": 0.16
  },
  {
    "model": "gmonsoon/StockSeaLLMs-7B-v1",
    "score": 0.16
  },
  {
    "model": "google/flan-t5-base",
    "score": 0.16
  },
  {
    "model": "google/flan-ul2",
    "score": 0.16
  },
  {
    "model": "google/gemma-7b-it",
    "score": 0.16
  },
  {
    "model": "iFaz/llama32_3B_en_emo_v2",
    "score": 0.16
  },
  {
    "model": "ibm/merlinite-7b",
    "score": 0.16
  },
  {
    "model": "icefog72/Ice0.55-17.01-RP",
    "score": 0.16
  },
  {
    "model": "icefog72/Ice0.60-18.01-RP",
    "score": 0.16
  },
  {
    "model": "icefog72/Ice0.61-18.01-RP",
    "score": 0.16
  },
  {
    "model": "icefog72/Ice0.68-25.01-RP",
    "score": 0.16
  },
  {
    "model": "icefog72/Ice0.69-25.01-RP",
    "score": 0.16
  },
  {
    "model": "icefog72/Ice0.70-25.01-RP",
    "score": 0.16
  },
  {
    "model": "icefog72/IceDrinkNameNotFoundRP-7b-Model_Stock",
    "score": 0.16
  },
  {
    "model": "icefog72/IceNalyvkaRP-7b",
    "score": 0.16
  },
  {
    "model": "icefog72/IceLemonTeaRP-32k-7b",
    "score": 0.16
  },
  {
    "model": "ilsp/Llama-Krikri-8B-Instruct",
    "score": 0.16
  },
  {
    "model": "informatiker/Qwen2-7B-Instruct-abliterated",
    "score": 0.16
  },
  {
    "model": "jebish7/Nemotron-Mini-4B-Instruct",
    "score": 0.16
  },
  {
    "model": "jlzhou/Qwen2.5-3B-Infinity-Instruct-0625",
    "score": 0.16
  },
  {
    "model": "jpacifico/Distilucie-7B-Math-Instruct-DPO-v0.1",
    "score": 0.16
  },
  {
    "model": "jpacifico/Lucie-Boosted-7B-Instruct",
    "score": 0.16
  },
  {
    "model": "kaist-ai/janus-dpo-7b",
    "score": 0.16
  },
  {
    "model": "lalainy/ECE-PRYMMAL-YL-6B-SLERP-V2",
    "score": 0.16
  },
  {
    "model": "lalainy/ECE-PRYMMAL-YL-6B-SLERP-V1",
    "score": 0.16
  },
  {
    "model": "marcuscedricridia/Hush-Qwen2.5-7B-v1.4",
    "score": 0.16
  },
  {
    "model": "marcuscedricridia/cursa-o1-7b-2-28-2025",
    "score": 0.16
  },
  {
    "model": "meditsolutions/Llama-3.2-SUN-1B-Instruct",
    "score": 0.16
  },
  {
    "model": "meditsolutions/SmolLM2-MedIT-Upscale-2B",
    "score": 0.16
  },
  {
    "model": "mergekit-community/mergekit-ties-rraxdhv",
    "score": 0.16
  },
  {
    "model": "microsoft/Orca-2-13b",
    "score": 0.16
  },
  {
    "model": "minghaowu/Qwen1.5-1.8B-OpenHermes-2.5",
    "score": 0.16
  },
  {
    "model": "mistral-community/Mistral-7B-v0.2",
    "score": 0.16
  },
  {
    "model": "mistralai/Mistral-7B-v0.3",
    "score": 0.16
  },
  {
    "model": "mistralai/Mistral-Nemo-Base-2407",
    "score": 0.16
  },
  {
    "model": "mrdayl/OpenCogito",
    "score": 0.16
  },
  {
    "model": "mrdayl/OpenCognito-r1",
    "score": 0.16
  },
  {
    "model": "natong19/Qwen2-7B-Instruct-abliterated",
    "score": 0.16
  },
  {
    "model": "netcat420/Llama3.1-MFANN-8b",
    "score": 0.16
  },
  {
    "model": "nlpguy/StarFusion-alpha1",
    "score": 0.16
  },
  {
    "model": "nvidia/Nemotron-Mini-4B-Instruct",
    "score": 0.16
  },
  {
    "model": "ontocord/RedPajama-3B-v1-AutoRedteam",
    "score": 0.16
  },
  {
    "model": "openchat/openchat_3.5",
    "score": 0.16
  },
  {
    "model": "pankajmathur/orca_mini_v5_8b_orpo",
    "score": 0.16
  },
  {
    "model": "princeton-nlp/Llama-3-Base-8B-SFT-KTO",
    "score": 0.16
  },
  {
    "model": "princeton-nlp/Llama-3-Base-8B-SFT-RDPO",
    "score": 0.16
  },
  {
    "model": "princeton-nlp/Llama-3-Instruct-8B-KTO",
    "score": 0.16
  },
  {
    "model": "prithivMLmods/Llama-3.2-3B-Math-Oct",
    "score": 0.16
  },
  {
    "model": "prithivMLmods/Llama-Deepsync-3B",
    "score": 0.16
  },
  {
    "model": "prithivMLmods/QwQ-LCoT-3B-Instruct",
    "score": 0.16
  },
  {
    "model": "rombodawg/Rombos-LLM-V2.5-Qwen-0.5b",
    "score": 0.16
  },
  {
    "model": "sabersaleh/Llama3",
    "score": 0.16
  },
  {
    "model": "sabersalehk/Llama3_001_200",
    "score": 0.16
  },
  {
    "model": "saishshinde15/TethysAI_Base_Reasoning",
    "score": 0.16
  },
  {
    "model": "siqi00/Mistral-7B-DFT",
    "score": 0.16
  },
  {
    "model": "speakleash/Bielik-11B-v2",
    "score": 0.16
  },
  {
    "model": "stabilityai/stablelm-2-1_6b-chat",
    "score": 0.16
  },
  {
    "model": "sumink/llamaft",
    "score": 0.16
  },
  {
    "model": "teknium/OpenHermes-2-Mistral-7B",
    "score": 0.16
  },
  {
    "model": "tiiuae/Falcon3-Mamba-7B-Instruct",
    "score": 0.16
  },
  {
    "model": "vhab10/Llama-3.2-Instruct-3B-TIES",
    "score": 0.16
  },
  {
    "model": "vicgalle/Humanish-RP-Llama-3.1-8B",
    "score": 0.16
  },
  {
    "model": "xinchen9/Mistral-7B-CoT",
    "score": 0.16
  },
  {
    "model": "yasserrmd/Coder-GRPO-3B",
    "score": 0.16
  },
  {
    "model": "ymcki/gemma-2-2b-jpn-it-abliterated-17",
    "score": 0.16
  },
  {
    "model": "1TuanPham/T-VisStar-v0.1",
    "score": 0.156
  },
  {
    "model": "1TuanPham/T-VisStar-7B-v0.1",
    "score": 0.156
  },
  {
    "model": "ArliAI/ArliAI-RPMax-12B-v1.1",
    "score": 0.156
  },
  {
    "model": "Azure99/Blossom-V6-7B",
    "score": 0.156
  },
  {
    "model": "Dans-DiscountModels/Dans-Instruct-Mix-8b-ChatML-V0.1.0",
    "score": 0.156
  },
  {
    "model": "Dans-DiscountModels/Mistral-7b-v0.3-Test-E0.7",
    "score": 0.156
  },
  {
    "model": "Dans-DiscountModels/Dans-Instruct-Mix-8b-ChatML-V0.1.1",
    "score": 0.156
  },
  {
    "model": "DavidAU/DeepThought-MOE-8X3B-R1-Llama-3.2-Reasoning-18B",
    "score": 0.156
  },
  {
    "model": "DeepMount00/Lexora-Medium-7B",
    "score": 0.156
  },
  {
    "model": "DeepMount00/Lexora-Lite-3B_v2",
    "score": 0.156
  },
  {
    "model": "DreadPoor/felix_dies-mistral-7B-model_stock",
    "score": 0.156
  },
  {
    "model": "EleutherAI/pythia-2.8b",
    "score": 0.156
  },
  {
    "model": "EpistemeAI/Reasoning-Llama-3.1-CoT-RE1-NMT",
    "score": 0.156
  },
  {
    "model": "EpistemeAI/ReasoningCore-3B-RE1-V2C",
    "score": 0.156
  },
  {
    "model": "EpistemeAI2/Fireball-Alpaca-Llama3.1.07-8B-Philos-Math",
    "score": 0.156
  },
  {
    "model": "EpistemeAI2/Fireball-Alpaca-Llama3.1.08-8B-Philos-C-R1",
    "score": 0.156
  },
  {
    "model": "EpistemeAI2/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.005-128K-code-COT",
    "score": 0.156
  },
  {
    "model": "Etherll/Qwen2.5-7B-della-test",
    "score": 0.156
  },
  {
    "model": "FuseAI/FuseChat-Qwen-2.5-7B-Instruct",
    "score": 0.156
  },
  {
    "model": "GenVRadmin/AryaBhatta-GemmaOrca-2-Merged",
    "score": 0.156
  },
  {
    "model": "HPAI-BSC/Llama3.1-Aloe-Beta-8B",
    "score": 0.156
  },
  {
    "model": "Intel/neural-chat-7b-v3-1",
    "score": 0.156
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPOP_3e-7-3ep_0alp_5lam",
    "score": 0.156
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPOP_5e-7-3ep_0alp_5lam",
    "score": 0.156
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_2e-6-1ep_0alp_0lam",
    "score": 0.156
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_5e-7_2ep_0alp_0lam",
    "score": 0.156
  },
  {
    "model": "JayHyeon/Qwen_0.5-DPOP_3e-7-3ep_0alp_5lam",
    "score": 0.156
  },
  {
    "model": "JayHyeon/Qwen_0.5-DPOP_5e-7-2ep_0alp_5lam",
    "score": 0.156
  },
  {
    "model": "JayHyeon/Qwen_0.5-VDPO_3e-6-1ep_3vpo_const",
    "score": 0.156
  },
  {
    "model": "JayHyeon/Qwen_0.5-MDPO_0.9_5e-7-3ep_0alp_0lam",
    "score": 0.156
  },
  {
    "model": "JayHyeon/Qwen_0.5-VDPO_5e-7-1ep_3vpo_const",
    "score": 0.156
  },
  {
    "model": "JayHyeon/Qwen_0.5-VIPO_5e-7-1ep_0alp_0lam",
    "score": 0.156
  },
  {
    "model": "JayHyeon/Qwen_0.5-VIPO_5e-7-1ep_1vpo_const",
    "score": 0.156
  },
  {
    "model": "JayHyeon/Qwen_0.5-cDPO_5e-7-3ep_0vpo_const_0.1",
    "score": 0.156
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_MasterCoder",
    "score": 0.156
  },
  {
    "model": "Marsouuu/lareneg3B-ECE-PRYMMAL-Martial",
    "score": 0.156
  },
  {
    "model": "MaziyarPanahi/calme-2.1-qwen2-7b",
    "score": 0.156
  },
  {
    "model": "MaziyarPanahi/calme-3.1-llamaloi-3b",
    "score": 0.156
  },
  {
    "model": "Minami-su/test-7B-00",
    "score": 0.156
  },
  {
    "model": "MultivexAI/Gladiator-Mini-Exp-1211-3B",
    "score": 0.156
  },
  {
    "model": "Nexesenex/Nemotron_W_4b_MagLight_0.1",
    "score": 0.156
  },
  {
    "model": "NotASI/FineTome-Llama3.2-1B-0929",
    "score": 0.156
  },
  {
    "model": "NotASI/FineTome-v1.5-Llama3.2-1B-1007",
    "score": 0.156
  },
  {
    "model": "NousResearch/Yarn-Mistral-7b-64k",
    "score": 0.156
  },
  {
    "model": "Novaciano/LEWD-Mental-Cultist-3.2-1B",
    "score": 0.156
  },
  {
    "model": "PowerInfer/SmallThinker-3B-Preview",
    "score": 0.156
  },
  {
    "model": "Qwen/Qwen1.5-14B-Chat",
    "score": 0.156
  },
  {
    "model": "Qwen/Qwen1.5-7B-Chat",
    "score": 0.156
  },
  {
    "model": "Qwen/Qwen2.5-1.5B-Instruct",
    "score": 0.156
  },
  {
    "model": "Qwen/Qwen2.5-Math-1.5B-Instruct",
    "score": 0.156
  },
  {
    "model": "TTTXXX01/Mistral-7B-Base-SimPO2-5e-7",
    "score": 0.156
  },
  {
    "model": "TheHierophant/Underground-Cognitive-V0.3-test",
    "score": 0.156
  },
  {
    "model": "TheTsar1209/nemo-carpmuscle-v0.1",
    "score": 0.156
  },
  {
    "model": "Triangle104/DSR1-Distill-Qwen-7B-RP",
    "score": 0.156
  },
  {
    "model": "Triangle104/Minerva-8b",
    "score": 0.156
  },
  {
    "model": "ValiantLabs/Llama3.1-8B-ShiningValiant2",
    "score": 0.156
  },
  {
    "model": "ValiantLabs/Llama3.1-8B-ShiningValiant2",
    "score": 0.156
  },
  {
    "model": "Weyaxi/Einstein-v4-7B",
    "score": 0.156
  },
  {
    "model": "WizardLMTeam/WizardLM-13B-V1.2",
    "score": 0.156
  },
  {
    "model": "YOYO-AI/Qwen2.5-7B-it-restore",
    "score": 0.156
  },
  {
    "model": "Youlln/2PRYMMAL-Yi1.5-6B-SLERP",
    "score": 0.156
  },
  {
    "model": "adamo1139/Yi-34B-200K-AEZAKMI-v2",
    "score": 0.156
  },
  {
    "model": "agentlans/Llama-3.2-1B-Instruct-CrashCourse12K",
    "score": 0.156
  },
  {
    "model": "athirdpath/Llama-3.1-Instruct_NSFW-pretrained_e1-plus_reddit",
    "score": 0.156
  },
  {
    "model": "bamec66557/mergekit-model_stock-zdaysvi",
    "score": 0.156
  },
  {
    "model": "bunnycore/Llama-3.2-3B-All-Mix",
    "score": 0.156
  },
  {
    "model": "bunnycore/Llama-3.2-3B-Booval",
    "score": 0.156
  },
  {
    "model": "bunnycore/Llama-3.2-3B-Mix-Skill",
    "score": 0.156
  },
  {
    "model": "bunnycore/Qwen-2.5-7B-R1-Stock",
    "score": 0.156
  },
  {
    "model": "bunnycore/Qwen2.5-7B-MixStock-V0.1",
    "score": 0.156
  },
  {
    "model": "cloudyu/S1-Llama-3.2-3Bx4-MoE",
    "score": 0.156
  },
  {
    "model": "djuna/Q2.5-Partron-7B",
    "score": 0.156
  },
  {
    "model": "dustinwloring1988/Reflexis-8b-chat-v4",
    "score": 0.156
  },
  {
    "model": "failspy/Llama-3-8B-Instruct-MopeyMule",
    "score": 0.156
  },
  {
    "model": "freewheelin/free-solar-evo-v0.13",
    "score": 0.156
  },
  {
    "model": "godlikehhd/qwen_ins_ans_2500",
    "score": 0.156
  },
  {
    "model": "google/gemma-2-2b",
    "score": 0.156
  },
  {
    "model": "google/gemma-2-2b",
    "score": 0.156
  },
  {
    "model": "iFaz/llama32_1B_en_emo_v1",
    "score": 0.156
  },
  {
    "model": "iFaz/llama32_3B_en_emo_1000_stp",
    "score": 0.156
  },
  {
    "model": "ibm-granite/granite-3.1-8b-base",
    "score": 0.156
  },
  {
    "model": "ibm-granite/granite-7b-base",
    "score": 0.156
  },
  {
    "model": "icefog72/Ice0.17-03.10-RP",
    "score": 0.156
  },
  {
    "model": "icefog72/Ice0.57-17.01-RP",
    "score": 0.156
  },
  {
    "model": "jpacifico/Chocolatine-3B-Instruct-DPO-v1.2",
    "score": 0.156
  },
  {
    "model": "llnYou/ECE-PRYMMAL-YL-3B-SLERP-V3",
    "score": 0.156
  },
  {
    "model": "lordjia/Llama-3-Cantonese-8B-Instruct",
    "score": 0.156
  },
  {
    "model": "lordjia/Qwen2-Cantonese-7B-Instruct",
    "score": 0.156
  },
  {
    "model": "marcuscedricridia/Hush-Qwen2.5-7B-v1.3",
    "score": 0.156
  },
  {
    "model": "matouLeLoup/ECE-PRYMMAL-0.5B-FT-V4-MUSR-Mathis",
    "score": 0.156
  },
  {
    "model": "meditsolutions/MSH-Lite-7B-v1-Bielik-v2.3-Instruct-Llama-Prune",
    "score": 0.156
  },
  {
    "model": "meta-llama/Llama-2-13b-hf",
    "score": 0.156
  },
  {
    "model": "meta-llama/Llama-2-70b-hf",
    "score": 0.156
  },
  {
    "model": "microsoft/Orca-2-7b",
    "score": 0.156
  },
  {
    "model": "microsoft/Phi-3.5-mini-instruct",
    "score": 0.156
  },
  {
    "model": "mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated",
    "score": 0.156
  },
  {
    "model": "neopolita/jessi-v0.2-falcon3-7b-instruct",
    "score": 0.156
  },
  {
    "model": "netcat420/MFANN-llama3.1-Abliterated-SLERP",
    "score": 0.156
  },
  {
    "model": "netcat420/MFANN3b",
    "score": 0.156
  },
  {
    "model": "netcat420/MFANNv0.24",
    "score": 0.156
  },
  {
    "model": "netcat420/Qwen2.5-MFANN-7b",
    "score": 0.156
  },
  {
    "model": "nvidia/Mistral-NeMo-Minitron-8B-Base",
    "score": 0.156
  },
  {
    "model": "ozone-research/Chirp-01",
    "score": 0.156
  },
  {
    "model": "pankajmathur/orca_mini_v3_7b",
    "score": 0.156
  },
  {
    "model": "pankajmathur/orca_mini_v9_5_1B-Instruct",
    "score": 0.156
  },
  {
    "model": "pankajmathur/orca_mini_v9_6_1B-Instruct",
    "score": 0.156
  },
  {
    "model": "princeton-nlp/Llama-3-Base-8B-SFT-DPO",
    "score": 0.156
  },
  {
    "model": "princeton-nlp/Llama-3-Instruct-8B-ORPO-v0.2",
    "score": 0.156
  },
  {
    "model": "princeton-nlp/Mistral-7B-Instruct-RDPO",
    "score": 0.156
  },
  {
    "model": "prithivMLmods/Llama-8B-Distill-CoT",
    "score": 0.156
  },
  {
    "model": "prithivMLmods/Qwen-7B-Distill-Reasoner",
    "score": 0.156
  },
  {
    "model": "qingy2019/LLaMa_3.2_3B_Catalysts",
    "score": 0.156
  },
  {
    "model": "qingy2019/Oracle-14B",
    "score": 0.156
  },
  {
    "model": "qingy2019/Oracle-14B",
    "score": 0.156
  },
  {
    "model": "qingy2024/Qwarkstar-4B-Instruct-Preview",
    "score": 0.156
  },
  {
    "model": "sequelbox/Llama3.1-8B-PlumCode",
    "score": 0.156
  },
  {
    "model": "shivank21/mistral_dpo_self",
    "score": 0.156
  },
  {
    "model": "sumink/llftfl7",
    "score": 0.156
  },
  {
    "model": "sumink/solarmer3",
    "score": 0.156
  },
  {
    "model": "sumink/somer",
    "score": 0.156
  },
  {
    "model": "tensopolis/mistral-small-r1-tensopolis",
    "score": 0.156
  },
  {
    "model": "theprint/CleverBoi-Llama-3.1-8B-Instruct",
    "score": 0.156
  },
  {
    "model": "theprint/Llama-3.2-3B-VanRossum",
    "score": 0.156
  },
  {
    "model": "thomas-yanxin/XinYuan-Qwen2-7B-0917",
    "score": 0.156
  },
  {
    "model": "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1",
    "score": 0.156
  },
  {
    "model": "universalml/NepaliGPT-2.0",
    "score": 0.156
  },
  {
    "model": "wave-on-discord/qwent-7b",
    "score": 0.156
  },
  {
    "model": "weathermanj/Menda-3b-750",
    "score": 0.156
  },
  {
    "model": "win10/Llama-3.2-3B-Instruct-24-9-29",
    "score": 0.156
  },
  {
    "model": "xinchen9/Llama3.1_CoT_V1",
    "score": 0.156
  },
  {
    "model": "google/gemma-7b",
    "score": 0.152
  },
  {
    "model": "BAAI/Infinity-Instruct-7M-0729-Llama3_1-8B",
    "score": 0.152
  },
  {
    "model": "BAAI/Infinity-Instruct-7M-Gen-Llama3_1-8B",
    "score": 0.152
  },
  {
    "model": "BramVanroy/fietje-2",
    "score": 0.152
  },
  {
    "model": "CarrotAI/Llama-3.2-Rabbit-Ko-3B-Instruct",
    "score": 0.152
  },
  {
    "model": "ClaudioItaly/intelligence-cod-rag-7b-v3",
    "score": 0.152
  },
  {
    "model": "Daemontatox/RA2.0",
    "score": 0.152
  },
  {
    "model": "Danielbrdz/Barcenas-3b-GRPO",
    "score": 0.152
  },
  {
    "model": "Dans-DiscountModels/Dans-Instruct-CoreCurriculum-12b-ChatML",
    "score": 0.152
  },
  {
    "model": "DavidAU/DeepSeek-V2-Grand-Horror-SMB-R1-Distill-Llama-3.1-Uncensored-16.5B",
    "score": 0.152
  },
  {
    "model": "Enno-Ai/EnnoAi-Pro-Llama-3-8B",
    "score": 0.152
  },
  {
    "model": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.003-128K",
    "score": 0.152
  },
  {
    "model": "EpistemeAI/Fireball-Mistral-Nemo-Base-2407-v1-DPO2",
    "score": 0.152
  },
  {
    "model": "EpistemeAI/ReasoningCore-3B-RE1-V2B",
    "score": 0.152
  },
  {
    "model": "GenVRadmin/AryaBhatta-GemmaUltra-Merged",
    "score": 0.152
  },
  {
    "model": "HelpingAI/Dhanishtha-Large",
    "score": 0.152
  },
  {
    "model": "HelpingAI/Priya-3B",
    "score": 0.152
  },
  {
    "model": "J-LAB/Thynk_orpo",
    "score": 0.152
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_1e-6-3ep_0alp_0lam",
    "score": 0.152
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-DPO_5e-7_2ep_0alp_0lam",
    "score": 0.152
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-2ep-MDPO_7e-7_2ep_0alp_0lam",
    "score": 0.152
  },
  {
    "model": "JayHyeon/Qwen2.5-0.5B-SFT-2e-5-5ep",
    "score": 0.152
  },
  {
    "model": "JayHyeon/Qwen_0.5-DPOP_1e-6-3ep_0alp_5lam",
    "score": 0.152
  },
  {
    "model": "JayHyeon/Qwen_0.5-DPO_3e-7-3ep_0alp_0lam",
    "score": 0.152
  },
  {
    "model": "JayHyeon/Qwen_0.5-DPO_5e-7-2ep_0alp_0lam",
    "score": 0.152
  },
  {
    "model": "JayHyeon/Qwen_0.5-IRPO_1e-7-3ep_1alp_0lam",
    "score": 0.152
  },
  {
    "model": "JayHyeon/Qwen_0.5-IRPO_5e-7-3ep_1alp_0lam",
    "score": 0.152
  },
  {
    "model": "JayHyeon/Qwen_0.5-VDPO_5e-7-3ep_3vpo_const",
    "score": 0.152
  },
  {
    "model": "JayHyeon/Qwen_0.5-cDPO_5e-7-3ep_0vpo_const_0.3",
    "score": 0.152
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_MUSR",
    "score": 0.152
  },
  {
    "model": "LeroyDyer/_Spydaz_Web_AI_AGI_R1_OmG_002",
    "score": 0.152
  },
  {
    "model": "Marsouuu/MiniMathExpert-2_61B-ECE-PRYMMAL-Martial",
    "score": 0.152
  },
  {
    "model": "MaziyarPanahi/calme-2.1-phi3.5-4b",
    "score": 0.152
  },
  {
    "model": "MaziyarPanahi/calme-2.2-qwen2-7b",
    "score": 0.152
  },
  {
    "model": "MaziyarPanahi/calme-2.4-qwen2-7b",
    "score": 0.152
  },
  {
    "model": "MaziyarPanahi/calme-2.6-qwen2-7b",
    "score": 0.152
  },
  {
    "model": "MoonRide/Llama-3.2-3B-Khelavaster",
    "score": 0.152
  },
  {
    "model": "NAPS-ai/naps-llama-3_1-instruct-v0.5.0",
    "score": 0.152
  },
  {
    "model": "NeverSleep/Lumimaid-v0.2-12B",
    "score": 0.152
  },
  {
    "model": "Nexesenex/Nemotron_W_4b_Halo_0.1",
    "score": 0.152
  },
  {
    "model": "NousResearch/Nous-Hermes-llama-2-7b",
    "score": 0.152
  },
  {
    "model": "NousResearch/Yarn-Mistral-7b-128k",
    "score": 0.152
  },
  {
    "model": "OpenBuddy/openbuddy-zero-3b-v21.2-32k",
    "score": 0.152
  },
  {
    "model": "PJMixers-Dev/LLaMa-3.2-Instruct-JankMix-v0.2-SFT-HailMary-v0.1-KTO-3B",
    "score": 0.152
  },
  {
    "model": "Pinkstack/Superthoughts-lite-v1",
    "score": 0.152
  },
  {
    "model": "Qwen/Qwen2-7B",
    "score": 0.152
  },
  {
    "model": "RezVortex/Jajuka-3b",
    "score": 0.152
  },
  {
    "model": "Ro-xe/FMixIA-7B-TIES-1",
    "score": 0.152
  },
  {
    "model": "Sakalti/QwenTest-7",
    "score": 0.152
  },
  {
    "model": "Sakalti/SJT-0.5B",
    "score": 0.152
  },
  {
    "model": "Sakalti/SJT-8B-V1.1",
    "score": 0.152
  },
  {
    "model": "Sakalti/SJTPass-2",
    "score": 0.152
  },
  {
    "model": "Sakalti/Saba-Passthrough-2",
    "score": 0.152
  },
  {
    "model": "SeaLLMs/SeaLLM-7B-v2",
    "score": 0.152
  },
  {
    "model": "SicariusSicariiStuff/Eximius_Persona_5B",
    "score": 0.152
  },
  {
    "model": "SkyOrbis/SKY-Ko-Llama3.2-1B-lora-v2-epoch5",
    "score": 0.152
  },
  {
    "model": "TheDrummer/Ministrations-8B-v1",
    "score": 0.152
  },
  {
    "model": "Triangle104/Dolphin3-Llama3.2-Smart",
    "score": 0.152
  },
  {
    "model": "Triangle104/RomboHermes3-R1-Llama3.2-3b",
    "score": 0.152
  },
  {
    "model": "VAGOsolutions/SauerkrautLM-Mixtral-8x7B-Instruct",
    "score": 0.152
  },
  {
    "model": "ValiantLabs/Llama3.2-3B-ShiningValiant2",
    "score": 0.152
  },
  {
    "model": "allknowingroger/Gemma2Slerp2-2.6B",
    "score": 0.152
  },
  {
    "model": "allknowingroger/Ministral-8B-slerp",
    "score": 0.152
  },
  {
    "model": "amazon/MegaBeam-Mistral-7B-300k",
    "score": 0.152
  },
  {
    "model": "awnr/Mistral-7B-v0.1-signtensors-1-over-2",
    "score": 0.152
  },
  {
    "model": "awnr/Mistral-7B-v0.1-signtensors-3-over-8",
    "score": 0.152
  },
  {
    "model": "bunnycore/Llama-3.2-3B-ProdigyPlus",
    "score": 0.152
  },
  {
    "model": "bunnycore/Maestro-S1k-7B-Sce",
    "score": 0.152
  },
  {
    "model": "bunnycore/Qwen2.5-3B-RP-Thinker",
    "score": 0.152
  },
  {
    "model": "bunnycore/Qwen2.5-7B-RRP-1M",
    "score": 0.152
  },
  {
    "model": "bunnycore/Smol-Llama-3.2-3B",
    "score": 0.152
  },
  {
    "model": "cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b",
    "score": 0.152
  },
  {
    "model": "divyanshukunwar/SASTRI_1_9B",
    "score": 0.152
  },
  {
    "model": "dustinwloring1988/Reflexis-8b-chat-v2",
    "score": 0.152
  },
  {
    "model": "ehristoforu/fp4-14b-it-v1",
    "score": 0.152
  },
  {
    "model": "freewheelin/free-solar-evo-v0.11",
    "score": 0.152
  },
  {
    "model": "google/flan-t5-xxl",
    "score": 0.152
  },
  {
    "model": "gupta-tanish/llama-7b-dpo-baseline",
    "score": 0.152
  },
  {
    "model": "huggyllama/llama-13b",
    "score": 0.152
  },
  {
    "model": "huihui-ai/Qwen2.5-7B-Instruct-abliterated",
    "score": 0.152
  },
  {
    "model": "iFaz/llama32_3B_en_emo_2000_stp",
    "score": 0.152
  },
  {
    "model": "ibm/PowerLM-3b",
    "score": 0.152
  },
  {
    "model": "ibm-granite/granite-3.0-1b-a400m-instruct",
    "score": 0.152
  },
  {
    "model": "icefog72/Ice0.16-02.10-RP",
    "score": 0.152
  },
  {
    "model": "icefog72/Ice0.15-02.10-RP",
    "score": 0.152
  },
  {
    "model": "icefog72/Ice0.50-16.01-RP",
    "score": 0.152
  },
  {
    "model": "icefog72/IceEspressoRPv2-7b",
    "score": 0.152
  },
  {
    "model": "icefog72/IceTea21EnergyDrinkRPV13-DPOv3",
    "score": 0.152
  },
  {
    "model": "jebish7/Nemotron-4-Mini-Hindi-4B-Instruct",
    "score": 0.152
  },
  {
    "model": "jeffmeloy/Qwen2.5-7B-olm-v1.2",
    "score": 0.152
  },
  {
    "model": "kno10/ende-chat-0.0.5",
    "score": 0.152
  },
  {
    "model": "lightblue/suzume-llama-3-8B-multilingual-orpo-borda-top25",
    "score": 0.152
  },
  {
    "model": "lightblue/suzume-llama-3-8B-multilingual-orpo-borda-top75",
    "score": 0.152
  },
  {
    "model": "lmsys/vicuna-13b-v1.3",
    "score": 0.152
  },
  {
    "model": "lmsys/vicuna-7b-v1.5",
    "score": 0.152
  },
  {
    "model": "macadeliccc/Samantha-Qwen-2-7B",
    "score": 0.152
  },
  {
    "model": "meta-llama/Llama-3.2-3B-Instruct",
    "score": 0.152
  },
  {
    "model": "neopolita/jessi-v0.3-falcon3-7b-instruct",
    "score": 0.152
  },
  {
    "model": "noname0202/Llama-3.2-4x3B-Instruct",
    "score": 0.152
  },
  {
    "model": "openchat/openchat_v3.2",
    "score": 0.152
  },
  {
    "model": "openchat/openchat_v3.2_super",
    "score": 0.152
  },
  {
    "model": "pankajmathur/Al_Dente_v1_8b",
    "score": 0.152
  },
  {
    "model": "piotr25691/thea-c-3b-25r",
    "score": 0.152
  },
  {
    "model": "princeton-nlp/Llama-3-Base-8B-SFT-RRHF",
    "score": 0.152
  },
  {
    "model": "princeton-nlp/Mistral-7B-Base-SFT-SLiC-HF",
    "score": 0.152
  },
  {
    "model": "prithivMLmods/Llama-3.2-6B-AlgoCode",
    "score": 0.152
  },
  {
    "model": "ruizhe1217/sft-s1-qwen-0.5b",
    "score": 0.152
  },
  {
    "model": "suayptalha/DeepSeek-R1-Distill-Llama-3B",
    "score": 0.152
  },
  {
    "model": "thomas-yanxin/XinYuan-Qwen2.5-7B-0917",
    "score": 0.152
  },
  {
    "model": "tinycompany/BiBo-v0.7",
    "score": 0.152
  },
  {
    "model": "tugstugi/Qwen2.5-7B-Instruct-QwQ-v0.1",
    "score": 0.152
  },
  {
    "model": "uukuguy/speechless-instruct-mistral-7b-v0.2",
    "score": 0.152
  },
  {
    "model": "viettelsecurity-ai/security-llama3.2-3b",
    "score": 0.152
  },
  {
    "model": "xMaulana/FinMatcha-3B-Instruct",
    "score": 0.152
  },
  {
    "model": "x0000001/Deepseek-Lumen-R1-Qwen2.5-14B",
    "score": 0.152
  },
  {
    "model": "ymcki/gemma-2-2b-jpn-it-abliterated-24",
    "score": 0.152
  }
]